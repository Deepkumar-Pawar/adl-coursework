digraph {
	graph [size="19.95,19.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140582772563296 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	140579420273536 [label=AddmmBackward0]
	140579420269264 -> 140579420273536
	140582772561456 [label="fc3.bias
 (1)" fillcolor=lightblue]
	140582772561456 -> 140579420269264
	140579420269264 [label=AccumulateGrad]
	140579420273152 -> 140579420273536
	140579420273152 [label=MulBackward0]
	140579420274400 -> 140579420273152
	140579420274400 [label=ReluBackward0]
	140579420259712 -> 140579420274400
	140579420259712 [label=AddmmBackward0]
	140579420268976 -> 140579420259712
	140582772560816 [label="fc2.bias
 (512)" fillcolor=lightblue]
	140582772560816 -> 140579420268976
	140579420268976 [label=AccumulateGrad]
	140579420265568 -> 140579420259712
	140579420265568 [label=ViewBackward0]
	140579420274208 -> 140579420265568
	140579420274208 [label=NativeBatchNormBackward0]
	140579420259856 -> 140579420274208
	140579420259856 [label=MulBackward0]
	140579420263648 -> 140579420259856
	140579420263648 [label=ReluBackward0]
	140579420271856 -> 140579420263648
	140579420271856 [label=AddmmBackward0]
	140579420266432 -> 140579420271856
	140582772560176 [label="fc1.bias
 (512)" fillcolor=lightblue]
	140582772560176 -> 140579420266432
	140579420266432 [label=AccumulateGrad]
	140579420262640 -> 140579420271856
	140579420262640 [label=ViewBackward0]
	140579420272528 -> 140579420262640
	140579420272528 [label=NativeBatchNormBackward0]
	140579420266528 -> 140579420272528
	140579420266528 [label=MulBackward0]
	140579420268928 -> 140579420266528
	140579420268928 [label=MaxPool2DWithIndicesBackward0]
	140579420270176 -> 140579420268928
	140579420270176 [label=ReluBackward0]
	140579420264992 -> 140579420270176
	140579420264992 [label=ConvolutionBackward0]
	140579420263456 -> 140579420264992
	140579420263456 [label=NativeBatchNormBackward0]
	140579420369248 -> 140579420263456
	140579420369248 [label=MaxPool2DWithIndicesBackward0]
	140579420362576 -> 140579420369248
	140579420362576 [label=ReluBackward0]
	140579420357920 -> 140579420362576
	140579420357920 [label=ConvolutionBackward0]
	140579420367184 -> 140579420357920
	140579420367184 [label=NativeBatchNormBackward0]
	140579420360464 -> 140579420367184
	140579420360464 [label=MaxPool2DWithIndicesBackward0]
	140579517420048 -> 140579420360464
	140579517420048 [label=ReluBackward0]
	140579517421200 -> 140579517420048
	140579517421200 [label=ConvolutionBackward0]
	140579517424320 -> 140579517421200
	140582772558096 [label="conv1.weight
 (96, 3, 7, 7)" fillcolor=lightblue]
	140582772558096 -> 140579517424320
	140579517424320 [label=AccumulateGrad]
	140579517422352 -> 140579517421200
	140582772558176 [label="conv1.bias
 (96)" fillcolor=lightblue]
	140582772558176 -> 140579517422352
	140579517422352 [label=AccumulateGrad]
	140579517417792 -> 140579420367184
	140582772558336 [label="batchnorm1.weight
 (96)" fillcolor=lightblue]
	140582772558336 -> 140579517417792
	140579517417792 [label=AccumulateGrad]
	140579517417648 -> 140579420367184
	140582772558416 [label="batchnorm1.bias
 (96)" fillcolor=lightblue]
	140582772558416 -> 140579517417648
	140579517417648 [label=AccumulateGrad]
	140579420362624 -> 140579420357920
	140582772558816 [label="conv2.weight
 (160, 96, 3, 3)" fillcolor=lightblue]
	140582772558816 -> 140579420362624
	140579420362624 [label=AccumulateGrad]
	140579420369872 -> 140579420357920
	140582772558896 [label="conv2.bias
 (160)" fillcolor=lightblue]
	140582772558896 -> 140579420369872
	140579420369872 [label=AccumulateGrad]
	140579420368528 -> 140579420263456
	140582772558976 [label="batchnorm2.weight
 (160)" fillcolor=lightblue]
	140582772558976 -> 140579420368528
	140579420368528 [label=AccumulateGrad]
	140579420358976 -> 140579420263456
	140582772559056 [label="batchnorm2.bias
 (160)" fillcolor=lightblue]
	140582772559056 -> 140579420358976
	140579420358976 [label=AccumulateGrad]
	140579420259952 -> 140579420264992
	140582772559456 [label="conv3.weight
 (288, 160, 3, 3)" fillcolor=lightblue]
	140582772559456 -> 140579420259952
	140579420259952 [label=AccumulateGrad]
	140579420270032 -> 140579420264992
	140582772559536 [label="conv3.bias
 (288)" fillcolor=lightblue]
	140582772559536 -> 140579420270032
	140579420270032 [label=AccumulateGrad]
	140579420264224 -> 140579420272528
	140582772559616 [label="batchnorm3.weight
 (288)" fillcolor=lightblue]
	140582772559616 -> 140579420264224
	140579420264224 [label=AccumulateGrad]
	140579420261680 -> 140579420272528
	140582772559696 [label="batchnorm3.bias
 (288)" fillcolor=lightblue]
	140582772559696 -> 140579420261680
	140579420261680 [label=AccumulateGrad]
	140579420272912 -> 140579420271856
	140579420272912 [label=TBackward0]
	140579420266000 -> 140579420272912
	140582772560096 [label="fc1.weight
 (512, 2592)" fillcolor=lightblue]
	140582772560096 -> 140579420266000
	140579420266000 [label=AccumulateGrad]
	140579420260960 -> 140579420274208
	140582772556176 [label="batchnorm4.weight
 (512)" fillcolor=lightblue]
	140582772556176 -> 140579420260960
	140579420260960 [label=AccumulateGrad]
	140579420262784 -> 140579420274208
	140582772560336 [label="batchnorm4.bias
 (512)" fillcolor=lightblue]
	140582772560336 -> 140579420262784
	140579420262784 [label=AccumulateGrad]
	140579420270368 -> 140579420259712
	140579420270368 [label=TBackward0]
	140579420267824 -> 140579420270368
	140582772560736 [label="fc2.weight
 (512, 1536)" fillcolor=lightblue]
	140582772560736 -> 140579420267824
	140579420267824 [label=AccumulateGrad]
	140579420262688 -> 140579420273536
	140579420262688 [label=TBackward0]
	140579420262304 -> 140579420262688
	140582772561376 [label="fc3.weight
 (1, 512)" fillcolor=lightblue]
	140582772561376 -> 140579420262304
	140579420262304 [label=AccumulateGrad]
	140579420273536 -> 140582772563296
}
