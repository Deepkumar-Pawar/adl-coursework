{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d51dbc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_14\n",
      "About to train...\n",
      "\n",
      "Exitting this train since accuracy too low: 0.484375\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_15\n",
      "About to train...\n",
      "epoch: [0], step: [9/377], batch loss: 0.76749, batch accuracy: 61.72, data load time: 0.00251, step time: 0.04568\n",
      "epoch: [0], step: [19/377], batch loss: 0.76374, batch accuracy: 60.94, data load time: 0.00200, step time: 0.04506\n",
      "epoch: [0], step: [29/377], batch loss: 0.82803, batch accuracy: 54.69, data load time: 0.00171, step time: 0.04340\n",
      "epoch: [0], step: [39/377], batch loss: 0.75308, batch accuracy: 68.75, data load time: 0.00213, step time: 0.04529\n",
      "epoch: [0], step: [49/377], batch loss: 0.73791, batch accuracy: 55.47, data load time: 0.00225, step time: 0.04475\n",
      "epoch: [0], step: [59/377], batch loss: 0.71843, batch accuracy: 60.94, data load time: 0.00181, step time: 0.04320\n",
      "epoch: [0], step: [69/377], batch loss: 0.75244, batch accuracy: 59.38, data load time: 0.00210, step time: 0.04418\n",
      "epoch: [0], step: [79/377], batch loss: 0.80070, batch accuracy: 60.16, data load time: 0.00181, step time: 0.04491\n",
      "epoch: [0], step: [89/377], batch loss: 0.81004, batch accuracy: 58.59, data load time: 0.00182, step time: 0.04347\n",
      "epoch: [0], step: [99/377], batch loss: 0.76550, batch accuracy: 57.03, data load time: 0.00188, step time: 0.04452\n",
      "epoch: [0], step: [109/377], batch loss: 0.71792, batch accuracy: 69.53, data load time: 0.00228, step time: 0.04454\n",
      "epoch: [0], step: [119/377], batch loss: 0.77491, batch accuracy: 60.94, data load time: 0.00217, step time: 0.04335\n",
      "epoch: [0], step: [129/377], batch loss: 0.79937, batch accuracy: 57.81, data load time: 0.00220, step time: 0.04379\n",
      "epoch: [0], step: [139/377], batch loss: 0.86699, batch accuracy: 53.91, data load time: 0.00238, step time: 0.04513\n",
      "epoch: [0], step: [149/377], batch loss: 0.69632, batch accuracy: 63.28, data load time: 0.00168, step time: 0.04363\n",
      "epoch: [0], step: [159/377], batch loss: 0.80256, batch accuracy: 57.03, data load time: 0.00234, step time: 0.04373\n",
      "epoch: [0], step: [169/377], batch loss: 0.82484, batch accuracy: 54.69, data load time: 0.00227, step time: 0.04510\n",
      "epoch: [0], step: [179/377], batch loss: 0.81917, batch accuracy: 52.34, data load time: 0.00211, step time: 0.04484\n",
      "epoch: [0], step: [189/377], batch loss: 0.75271, batch accuracy: 57.03, data load time: 0.00223, step time: 0.04257\n",
      "epoch: [0], step: [199/377], batch loss: 0.74579, batch accuracy: 60.16, data load time: 0.00162, step time: 0.04525\n",
      "epoch: [0], step: [209/377], batch loss: 0.78428, batch accuracy: 57.03, data load time: 0.00227, step time: 0.04512\n",
      "epoch: [0], step: [219/377], batch loss: 0.76751, batch accuracy: 59.38, data load time: 0.00163, step time: 0.04321\n",
      "epoch: [0], step: [229/377], batch loss: 0.79228, batch accuracy: 57.81, data load time: 0.00221, step time: 0.04501\n",
      "\n",
      "Exitting this train since accuracy too low: 0.46875\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_16\n",
      "About to train...\n",
      "\n",
      "Exitting this train since accuracy too low: 0.390625\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_17\n",
      "About to train...\n",
      "epoch: [0], step: [9/377], batch loss: 0.76576, batch accuracy: 64.06, data load time: 0.00232, step time: 0.04451\n",
      "epoch: [0], step: [19/377], batch loss: 0.71242, batch accuracy: 69.53, data load time: 0.00217, step time: 0.04527\n",
      "epoch: [0], step: [29/377], batch loss: 0.73932, batch accuracy: 65.62, data load time: 0.00162, step time: 0.04435\n",
      "epoch: [0], step: [39/377], batch loss: 0.83337, batch accuracy: 58.59, data load time: 0.00217, step time: 0.04464\n",
      "epoch: [0], step: [49/377], batch loss: 0.74500, batch accuracy: 61.72, data load time: 0.00222, step time: 0.04326\n",
      "epoch: [0], step: [59/377], batch loss: 0.84845, batch accuracy: 60.16, data load time: 0.00176, step time: 0.04357\n",
      "epoch: [0], step: [69/377], batch loss: 0.74871, batch accuracy: 66.41, data load time: 0.00189, step time: 0.04292\n",
      "epoch: [0], step: [79/377], batch loss: 0.78988, batch accuracy: 64.84, data load time: 0.00224, step time: 0.04400\n",
      "epoch: [0], step: [89/377], batch loss: 0.69372, batch accuracy: 67.19, data load time: 0.00216, step time: 0.04510\n",
      "\n",
      "Exitting this train since accuracy too low: 0.4921875\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_18\n",
      "About to train...\n",
      "\n",
      "Exitting this train since accuracy too low: 0.4140625\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_19\n",
      "About to train...\n",
      "\n",
      "Exitting this train since accuracy too low: 0.3671875\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_20\n",
      "About to train...\n",
      "\n",
      "Exitting this train since accuracy too low: 0.359375\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_21\n",
      "About to train...\n",
      "epoch: [0], step: [9/377], batch loss: 0.88993, batch accuracy: 62.50, data load time: 0.00172, step time: 0.04429\n",
      "epoch: [0], step: [19/377], batch loss: 0.97852, batch accuracy: 64.06, data load time: 0.00225, step time: 0.04355\n",
      "epoch: [0], step: [29/377], batch loss: 0.86737, batch accuracy: 67.19, data load time: 0.00246, step time: 0.04382\n",
      "epoch: [0], step: [39/377], batch loss: 0.90191, batch accuracy: 64.84, data load time: 0.00232, step time: 0.04522\n",
      "epoch: [0], step: [49/377], batch loss: 0.89034, batch accuracy: 64.84, data load time: 0.00212, step time: 0.04550\n",
      "epoch: [0], step: [59/377], batch loss: 0.75150, batch accuracy: 72.66, data load time: 0.00221, step time: 0.04450\n",
      "epoch: [0], step: [69/377], batch loss: 0.78016, batch accuracy: 71.88, data load time: 0.00229, step time: 0.04417\n",
      "epoch: [0], step: [79/377], batch loss: 0.94346, batch accuracy: 64.06, data load time: 0.00175, step time: 0.04543\n",
      "epoch: [0], step: [89/377], batch loss: 0.75348, batch accuracy: 72.66, data load time: 0.00217, step time: 0.04443\n",
      "epoch: [0], step: [99/377], batch loss: 0.83128, batch accuracy: 63.28, data load time: 0.00218, step time: 0.04517\n",
      "epoch: [0], step: [109/377], batch loss: 0.77227, batch accuracy: 68.75, data load time: 0.00218, step time: 0.04379\n",
      "epoch: [0], step: [119/377], batch loss: 0.82442, batch accuracy: 67.97, data load time: 0.00232, step time: 0.04362\n",
      "epoch: [0], step: [129/377], batch loss: 0.97302, batch accuracy: 60.94, data load time: 0.00235, step time: 0.04517\n",
      "epoch: [0], step: [139/377], batch loss: 0.89182, batch accuracy: 66.41, data load time: 0.00229, step time: 0.04554\n",
      "epoch: [0], step: [149/377], batch loss: 0.90188, batch accuracy: 62.50, data load time: 0.00257, step time: 0.04441\n",
      "epoch: [0], step: [159/377], batch loss: 0.89099, batch accuracy: 64.06, data load time: 0.00161, step time: 0.04448\n",
      "epoch: [0], step: [169/377], batch loss: 0.79265, batch accuracy: 65.62, data load time: 0.00233, step time: 0.04470\n",
      "epoch: [0], step: [179/377], batch loss: 0.72569, batch accuracy: 71.09, data load time: 0.00222, step time: 0.04551\n",
      "epoch: [0], step: [189/377], batch loss: 0.77407, batch accuracy: 67.97, data load time: 0.00232, step time: 0.04528\n",
      "epoch: [0], step: [199/377], batch loss: 0.76805, batch accuracy: 71.09, data load time: 0.00188, step time: 0.04499\n",
      "epoch: [0], step: [209/377], batch loss: 0.96301, batch accuracy: 60.94, data load time: 0.00213, step time: 0.04377\n",
      "epoch: [0], step: [219/377], batch loss: 0.79039, batch accuracy: 67.19, data load time: 0.00233, step time: 0.04353\n",
      "epoch: [0], step: [229/377], batch loss: 1.08648, batch accuracy: 56.25, data load time: 0.00211, step time: 0.04350\n",
      "epoch: [0], step: [239/377], batch loss: 0.97679, batch accuracy: 57.81, data load time: 0.00226, step time: 0.04381\n",
      "epoch: [0], step: [249/377], batch loss: 0.84772, batch accuracy: 69.53, data load time: 0.00223, step time: 0.04429\n",
      "epoch: [0], step: [259/377], batch loss: 0.99808, batch accuracy: 59.38, data load time: 0.00219, step time: 0.04354\n",
      "epoch: [0], step: [269/377], batch loss: 0.77151, batch accuracy: 69.53, data load time: 0.00229, step time: 0.04395\n",
      "epoch: [0], step: [279/377], batch loss: 0.76140, batch accuracy: 71.09, data load time: 0.00216, step time: 0.04425\n",
      "epoch: [0], step: [289/377], batch loss: 0.96015, batch accuracy: 62.50, data load time: 0.00167, step time: 0.04481\n",
      "epoch: [0], step: [299/377], batch loss: 0.85235, batch accuracy: 66.41, data load time: 0.00218, step time: 0.04411\n",
      "epoch: [0], step: [309/377], batch loss: 0.76194, batch accuracy: 71.09, data load time: 0.00214, step time: 0.04488\n",
      "epoch: [0], step: [319/377], batch loss: 0.89523, batch accuracy: 66.41, data load time: 0.00226, step time: 0.04532\n",
      "epoch: [0], step: [329/377], batch loss: 0.72491, batch accuracy: 71.88, data load time: 0.00178, step time: 0.04542\n",
      "epoch: [0], step: [339/377], batch loss: 0.82781, batch accuracy: 68.75, data load time: 0.00215, step time: 0.04458\n",
      "epoch: [0], step: [349/377], batch loss: 0.82408, batch accuracy: 66.41, data load time: 0.00167, step time: 0.04513\n",
      "epoch: [0], step: [359/377], batch loss: 0.90552, batch accuracy: 61.72, data load time: 0.00237, step time: 0.04537\n",
      "epoch: [0], step: [369/377], batch loss: 0.96119, batch accuracy: 62.50, data load time: 0.00221, step time: 0.04510\n",
      "epoch: [1], step: [2/377], batch loss: 0.85564, batch accuracy: 62.50, data load time: 0.00164, step time: 0.04483\n",
      "epoch: [1], step: [12/377], batch loss: 0.85795, batch accuracy: 67.19, data load time: 0.00174, step time: 0.04362\n",
      "epoch: [1], step: [22/377], batch loss: 0.75741, batch accuracy: 71.09, data load time: 0.00182, step time: 0.04390\n",
      "epoch: [1], step: [32/377], batch loss: 0.78236, batch accuracy: 71.88, data load time: 0.00158, step time: 0.04322\n",
      "epoch: [1], step: [42/377], batch loss: 0.85235, batch accuracy: 64.84, data load time: 0.00177, step time: 0.04356\n",
      "epoch: [1], step: [52/377], batch loss: 0.74825, batch accuracy: 74.22, data load time: 0.00177, step time: 0.04443\n",
      "epoch: [1], step: [62/377], batch loss: 0.74735, batch accuracy: 70.31, data load time: 0.00165, step time: 0.04493\n",
      "epoch: [1], step: [72/377], batch loss: 0.96235, batch accuracy: 58.59, data load time: 0.00167, step time: 0.04425\n",
      "epoch: [1], step: [82/377], batch loss: 0.95894, batch accuracy: 63.28, data load time: 0.00228, step time: 0.04443\n",
      "epoch: [1], step: [92/377], batch loss: 0.85903, batch accuracy: 66.41, data load time: 0.00175, step time: 0.04320\n",
      "epoch: [1], step: [102/377], batch loss: 0.95110, batch accuracy: 57.81, data load time: 0.00194, step time: 0.04401\n",
      "epoch: [1], step: [112/377], batch loss: 0.94201, batch accuracy: 62.50, data load time: 0.00189, step time: 0.04379\n",
      "epoch: [1], step: [122/377], batch loss: 0.90789, batch accuracy: 63.28, data load time: 0.00219, step time: 0.04459\n",
      "epoch: [1], step: [132/377], batch loss: 0.87463, batch accuracy: 62.50, data load time: 0.00161, step time: 0.04351\n",
      "epoch: [1], step: [142/377], batch loss: 0.82947, batch accuracy: 70.31, data load time: 0.00177, step time: 0.04388\n",
      "epoch: [1], step: [152/377], batch loss: 0.82858, batch accuracy: 69.53, data load time: 0.00176, step time: 0.04327\n",
      "epoch: [1], step: [162/377], batch loss: 0.83454, batch accuracy: 64.06, data load time: 0.00222, step time: 0.04379\n",
      "epoch: [1], step: [172/377], batch loss: 0.76308, batch accuracy: 67.97, data load time: 0.00218, step time: 0.04366\n",
      "epoch: [1], step: [182/377], batch loss: 0.76785, batch accuracy: 67.97, data load time: 0.00172, step time: 0.04389\n",
      "epoch: [1], step: [192/377], batch loss: 0.76025, batch accuracy: 74.22, data load time: 0.00225, step time: 0.04466\n",
      "epoch: [1], step: [202/377], batch loss: 0.89905, batch accuracy: 63.28, data load time: 0.00226, step time: 0.04543\n",
      "epoch: [1], step: [212/377], batch loss: 0.73486, batch accuracy: 71.09, data load time: 0.00211, step time: 0.04576\n",
      "epoch: [1], step: [222/377], batch loss: 0.95228, batch accuracy: 60.16, data load time: 0.00166, step time: 0.04583\n",
      "epoch: [1], step: [232/377], batch loss: 0.83440, batch accuracy: 67.97, data load time: 0.00208, step time: 0.04601\n",
      "epoch: [1], step: [242/377], batch loss: 0.83827, batch accuracy: 67.97, data load time: 0.00252, step time: 0.04492\n",
      "epoch: [1], step: [252/377], batch loss: 0.90569, batch accuracy: 64.06, data load time: 0.00199, step time: 0.04435\n",
      "epoch: [1], step: [262/377], batch loss: 0.91391, batch accuracy: 60.94, data load time: 0.00192, step time: 0.04501\n",
      "epoch: [1], step: [272/377], batch loss: 0.80073, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04401\n",
      "epoch: [1], step: [282/377], batch loss: 0.93007, batch accuracy: 65.62, data load time: 0.00184, step time: 0.04486\n",
      "epoch: [1], step: [292/377], batch loss: 0.98511, batch accuracy: 63.28, data load time: 0.00178, step time: 0.04587\n",
      "epoch: [1], step: [302/377], batch loss: 0.97963, batch accuracy: 64.06, data load time: 0.00169, step time: 0.04593\n",
      "epoch: [1], step: [312/377], batch loss: 0.83282, batch accuracy: 68.75, data load time: 0.00223, step time: 0.04551\n",
      "epoch: [1], step: [322/377], batch loss: 0.80481, batch accuracy: 70.31, data load time: 0.00219, step time: 0.04531\n",
      "epoch: [1], step: [332/377], batch loss: 0.79511, batch accuracy: 70.31, data load time: 0.00250, step time: 0.04583\n",
      "epoch: [1], step: [342/377], batch loss: 0.93498, batch accuracy: 64.06, data load time: 0.00173, step time: 0.04389\n",
      "epoch: [1], step: [352/377], batch loss: 0.88395, batch accuracy: 67.19, data load time: 0.00179, step time: 0.04462\n",
      "epoch: [1], step: [362/377], batch loss: 0.82646, batch accuracy: 66.41, data load time: 0.00167, step time: 0.04489\n",
      "epoch: [1], step: [372/377], batch loss: 0.77353, batch accuracy: 68.75, data load time: 0.00169, step time: 0.04599\n",
      "epoch: [2], step: [5/377], batch loss: 0.95755, batch accuracy: 61.72, data load time: 0.00171, step time: 0.04487\n",
      "epoch: [2], step: [15/377], batch loss: 0.90994, batch accuracy: 67.97, data load time: 0.00173, step time: 0.04588\n",
      "epoch: [2], step: [25/377], batch loss: 0.83491, batch accuracy: 64.84, data load time: 0.00171, step time: 0.04605\n",
      "epoch: [2], step: [35/377], batch loss: 0.95818, batch accuracy: 64.84, data load time: 0.00185, step time: 0.04559\n",
      "epoch: [2], step: [45/377], batch loss: 0.84635, batch accuracy: 67.97, data load time: 0.00171, step time: 0.04465\n",
      "epoch: [2], step: [55/377], batch loss: 0.80734, batch accuracy: 67.19, data load time: 0.00172, step time: 0.04535\n",
      "epoch: [2], step: [65/377], batch loss: 0.87162, batch accuracy: 67.97, data load time: 0.00172, step time: 0.04495\n",
      "epoch: [2], step: [75/377], batch loss: 1.08752, batch accuracy: 53.91, data load time: 0.00173, step time: 0.04602\n",
      "epoch: [2], step: [85/377], batch loss: 0.86020, batch accuracy: 65.62, data load time: 0.00181, step time: 0.04541\n",
      "epoch: [2], step: [95/377], batch loss: 0.68698, batch accuracy: 75.00, data load time: 0.00171, step time: 0.04441\n",
      "epoch: [2], step: [105/377], batch loss: 0.84854, batch accuracy: 64.84, data load time: 0.00169, step time: 0.04492\n",
      "epoch: [2], step: [115/377], batch loss: 0.79490, batch accuracy: 65.62, data load time: 0.00175, step time: 0.04488\n",
      "epoch: [2], step: [125/377], batch loss: 0.84631, batch accuracy: 64.84, data load time: 0.00178, step time: 0.04621\n",
      "\n",
      "Exitting this train since accuracy too low: 0.46875\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_22\n",
      "About to train...\n",
      "epoch: [0], step: [9/377], batch loss: 0.86173, batch accuracy: 60.94, data load time: 0.00186, step time: 0.04419\n",
      "epoch: [0], step: [19/377], batch loss: 0.85636, batch accuracy: 64.84, data load time: 0.00171, step time: 0.04530\n",
      "epoch: [0], step: [29/377], batch loss: 0.89596, batch accuracy: 61.72, data load time: 0.00192, step time: 0.04432\n",
      "epoch: [0], step: [39/377], batch loss: 0.84684, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04528\n",
      "epoch: [0], step: [49/377], batch loss: 0.65895, batch accuracy: 73.44, data load time: 0.00176, step time: 0.04516\n",
      "epoch: [0], step: [59/377], batch loss: 0.88225, batch accuracy: 64.06, data load time: 0.00208, step time: 0.04486\n",
      "epoch: [0], step: [69/377], batch loss: 0.80316, batch accuracy: 65.62, data load time: 0.00180, step time: 0.04328\n",
      "epoch: [0], step: [79/377], batch loss: 0.86629, batch accuracy: 60.94, data load time: 0.00170, step time: 0.04592\n",
      "epoch: [0], step: [89/377], batch loss: 0.92094, batch accuracy: 62.50, data load time: 0.00178, step time: 0.04632\n",
      "epoch: [0], step: [99/377], batch loss: 0.80934, batch accuracy: 67.19, data load time: 0.00192, step time: 0.04428\n",
      "epoch: [0], step: [109/377], batch loss: 0.95054, batch accuracy: 57.81, data load time: 0.00179, step time: 0.04564\n",
      "epoch: [0], step: [119/377], batch loss: 0.81011, batch accuracy: 67.19, data load time: 0.00202, step time: 0.04517\n",
      "epoch: [0], step: [129/377], batch loss: 0.79661, batch accuracy: 64.84, data load time: 0.00190, step time: 0.04460\n",
      "epoch: [0], step: [139/377], batch loss: 0.77726, batch accuracy: 66.41, data load time: 0.00184, step time: 0.04538\n",
      "epoch: [0], step: [149/377], batch loss: 0.87159, batch accuracy: 63.28, data load time: 0.00167, step time: 0.04638\n",
      "epoch: [0], step: [159/377], batch loss: 0.74479, batch accuracy: 69.53, data load time: 0.00159, step time: 0.04476\n",
      "epoch: [0], step: [169/377], batch loss: 0.76328, batch accuracy: 67.97, data load time: 0.00171, step time: 0.04506\n",
      "epoch: [0], step: [179/377], batch loss: 0.65799, batch accuracy: 75.00, data load time: 0.00166, step time: 0.04627\n",
      "epoch: [0], step: [189/377], batch loss: 0.69914, batch accuracy: 71.09, data load time: 0.00177, step time: 0.04582\n",
      "epoch: [0], step: [199/377], batch loss: 0.68480, batch accuracy: 74.22, data load time: 0.00183, step time: 0.04585\n",
      "epoch: [0], step: [209/377], batch loss: 0.86392, batch accuracy: 64.06, data load time: 0.00170, step time: 0.04531\n",
      "epoch: [0], step: [219/377], batch loss: 0.78226, batch accuracy: 64.84, data load time: 0.00190, step time: 0.04459\n",
      "epoch: [0], step: [229/377], batch loss: 0.83791, batch accuracy: 60.16, data load time: 0.00175, step time: 0.04485\n",
      "epoch: [0], step: [239/377], batch loss: 0.72489, batch accuracy: 70.31, data load time: 0.00161, step time: 0.04652\n",
      "epoch: [0], step: [249/377], batch loss: 0.71442, batch accuracy: 71.09, data load time: 0.00240, step time: 0.04448\n",
      "epoch: [0], step: [259/377], batch loss: 0.79091, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04521\n",
      "epoch: [0], step: [269/377], batch loss: 0.66853, batch accuracy: 71.09, data load time: 0.00169, step time: 0.04658\n",
      "epoch: [0], step: [279/377], batch loss: 0.78147, batch accuracy: 67.97, data load time: 0.00226, step time: 0.04504\n",
      "epoch: [0], step: [289/377], batch loss: 0.66830, batch accuracy: 71.09, data load time: 0.00172, step time: 0.04575\n",
      "epoch: [0], step: [299/377], batch loss: 0.93390, batch accuracy: 62.50, data load time: 0.00184, step time: 0.04412\n",
      "epoch: [0], step: [309/377], batch loss: 0.79816, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04618\n",
      "epoch: [0], step: [319/377], batch loss: 0.93470, batch accuracy: 58.59, data load time: 0.00163, step time: 0.04645\n",
      "epoch: [0], step: [329/377], batch loss: 0.79521, batch accuracy: 63.28, data load time: 0.00172, step time: 0.04515\n",
      "epoch: [0], step: [339/377], batch loss: 0.71807, batch accuracy: 70.31, data load time: 0.00220, step time: 0.04555\n",
      "epoch: [0], step: [349/377], batch loss: 0.83958, batch accuracy: 64.06, data load time: 0.00171, step time: 0.04659\n",
      "epoch: [0], step: [359/377], batch loss: 0.87962, batch accuracy: 62.50, data load time: 0.00225, step time: 0.04481\n",
      "epoch: [0], step: [369/377], batch loss: 0.69280, batch accuracy: 71.09, data load time: 0.00171, step time: 0.04650\n",
      "epoch: [1], step: [2/377], batch loss: 0.83153, batch accuracy: 60.94, data load time: 0.00171, step time: 0.04651\n",
      "epoch: [1], step: [12/377], batch loss: 0.78748, batch accuracy: 67.19, data load time: 0.00184, step time: 0.04370\n",
      "epoch: [1], step: [22/377], batch loss: 0.91136, batch accuracy: 58.59, data load time: 0.00162, step time: 0.04591\n",
      "epoch: [1], step: [32/377], batch loss: 0.77011, batch accuracy: 73.44, data load time: 0.00200, step time: 0.04629\n",
      "epoch: [1], step: [42/377], batch loss: 0.71707, batch accuracy: 71.88, data load time: 0.00183, step time: 0.04635\n",
      "epoch: [1], step: [52/377], batch loss: 1.00188, batch accuracy: 57.81, data load time: 0.00190, step time: 0.04388\n",
      "epoch: [1], step: [62/377], batch loss: 0.86317, batch accuracy: 60.16, data load time: 0.00173, step time: 0.04582\n",
      "epoch: [1], step: [72/377], batch loss: 0.88894, batch accuracy: 64.84, data load time: 0.00174, step time: 0.04575\n",
      "epoch: [1], step: [82/377], batch loss: 0.84593, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04576\n",
      "epoch: [1], step: [92/377], batch loss: 0.79484, batch accuracy: 68.75, data load time: 0.00199, step time: 0.04596\n",
      "epoch: [1], step: [102/377], batch loss: 0.79517, batch accuracy: 61.72, data load time: 0.00170, step time: 0.04588\n",
      "epoch: [1], step: [112/377], batch loss: 0.66257, batch accuracy: 71.09, data load time: 0.00192, step time: 0.04531\n",
      "epoch: [1], step: [122/377], batch loss: 0.80260, batch accuracy: 65.62, data load time: 0.00183, step time: 0.04505\n",
      "epoch: [1], step: [132/377], batch loss: 0.68560, batch accuracy: 69.53, data load time: 0.00163, step time: 0.04388\n",
      "epoch: [1], step: [142/377], batch loss: 0.72246, batch accuracy: 70.31, data load time: 0.00168, step time: 0.04497\n",
      "epoch: [1], step: [152/377], batch loss: 0.85100, batch accuracy: 63.28, data load time: 0.00168, step time: 0.04632\n",
      "epoch: [1], step: [162/377], batch loss: 0.83465, batch accuracy: 59.38, data load time: 0.00180, step time: 0.04549\n",
      "epoch: [1], step: [172/377], batch loss: 0.88667, batch accuracy: 66.41, data load time: 0.00175, step time: 0.04442\n",
      "epoch: [1], step: [182/377], batch loss: 0.82250, batch accuracy: 66.41, data load time: 0.00192, step time: 0.04661\n",
      "epoch: [1], step: [192/377], batch loss: 0.77717, batch accuracy: 68.75, data load time: 0.00180, step time: 0.04559\n",
      "epoch: [1], step: [202/377], batch loss: 0.71137, batch accuracy: 71.09, data load time: 0.00180, step time: 0.04475\n",
      "epoch: [1], step: [212/377], batch loss: 0.79067, batch accuracy: 68.75, data load time: 0.00194, step time: 0.04465\n",
      "epoch: [1], step: [222/377], batch loss: 0.84213, batch accuracy: 64.06, data load time: 0.00196, step time: 0.04584\n",
      "epoch: [1], step: [232/377], batch loss: 0.71950, batch accuracy: 70.31, data load time: 0.00175, step time: 0.04567\n",
      "epoch: [1], step: [242/377], batch loss: 0.79787, batch accuracy: 67.97, data load time: 0.00184, step time: 0.04410\n",
      "epoch: [1], step: [252/377], batch loss: 0.84486, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04442\n",
      "epoch: [1], step: [262/377], batch loss: 0.93164, batch accuracy: 63.28, data load time: 0.00178, step time: 0.04684\n",
      "epoch: [1], step: [272/377], batch loss: 0.88837, batch accuracy: 59.38, data load time: 0.00187, step time: 0.04471\n",
      "epoch: [1], step: [282/377], batch loss: 1.00037, batch accuracy: 59.38, data load time: 0.00175, step time: 0.04406\n",
      "epoch: [1], step: [292/377], batch loss: 0.80494, batch accuracy: 65.62, data load time: 0.00175, step time: 0.04657\n",
      "epoch: [1], step: [302/377], batch loss: 0.92007, batch accuracy: 64.84, data load time: 0.00190, step time: 0.04595\n",
      "epoch: [1], step: [312/377], batch loss: 0.65903, batch accuracy: 75.00, data load time: 0.00178, step time: 0.04574\n",
      "epoch: [1], step: [322/377], batch loss: 0.77225, batch accuracy: 64.06, data load time: 0.00188, step time: 0.04374\n",
      "epoch: [1], step: [332/377], batch loss: 0.72760, batch accuracy: 71.88, data load time: 0.00180, step time: 0.04664\n",
      "epoch: [1], step: [342/377], batch loss: 0.70264, batch accuracy: 71.88, data load time: 0.00193, step time: 0.04549\n",
      "epoch: [1], step: [352/377], batch loss: 0.71823, batch accuracy: 69.53, data load time: 0.00185, step time: 0.04402\n",
      "epoch: [1], step: [362/377], batch loss: 0.74753, batch accuracy: 72.66, data load time: 0.00190, step time: 0.04505\n",
      "epoch: [1], step: [372/377], batch loss: 0.67435, batch accuracy: 73.44, data load time: 0.00178, step time: 0.04505\n",
      "epoch: [2], step: [5/377], batch loss: 0.92432, batch accuracy: 59.38, data load time: 0.00171, step time: 0.04395\n",
      "epoch: [2], step: [15/377], batch loss: 0.73389, batch accuracy: 70.31, data load time: 0.00183, step time: 0.04456\n",
      "epoch: [2], step: [25/377], batch loss: 0.95868, batch accuracy: 63.28, data load time: 0.00185, step time: 0.04484\n",
      "epoch: [2], step: [35/377], batch loss: 0.78715, batch accuracy: 71.09, data load time: 0.00173, step time: 0.04676\n",
      "epoch: [2], step: [45/377], batch loss: 0.75679, batch accuracy: 64.84, data load time: 0.00178, step time: 0.04490\n",
      "epoch: [2], step: [55/377], batch loss: 0.76654, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04540\n",
      "epoch: [2], step: [65/377], batch loss: 0.84753, batch accuracy: 66.41, data load time: 0.00165, step time: 0.04698\n",
      "epoch: [2], step: [75/377], batch loss: 0.81588, batch accuracy: 64.84, data load time: 0.00158, step time: 0.04541\n",
      "epoch: [2], step: [85/377], batch loss: 0.82309, batch accuracy: 64.84, data load time: 0.00184, step time: 0.04534\n",
      "epoch: [2], step: [95/377], batch loss: 0.85533, batch accuracy: 63.28, data load time: 0.00172, step time: 0.04604\n",
      "epoch: [2], step: [105/377], batch loss: 0.85947, batch accuracy: 64.84, data load time: 0.00180, step time: 0.04550\n",
      "epoch: [2], step: [115/377], batch loss: 0.77904, batch accuracy: 67.19, data load time: 0.00170, step time: 0.04516\n",
      "epoch: [2], step: [125/377], batch loss: 0.77108, batch accuracy: 68.75, data load time: 0.00181, step time: 0.04462\n",
      "epoch: [2], step: [135/377], batch loss: 0.72222, batch accuracy: 71.88, data load time: 0.00163, step time: 0.04602\n",
      "epoch: [2], step: [145/377], batch loss: 0.74430, batch accuracy: 71.09, data load time: 0.00189, step time: 0.04574\n",
      "epoch: [2], step: [155/377], batch loss: 0.78323, batch accuracy: 66.41, data load time: 0.00161, step time: 0.04525\n",
      "epoch: [2], step: [165/377], batch loss: 0.83421, batch accuracy: 62.50, data load time: 0.00175, step time: 0.04525\n",
      "epoch: [2], step: [175/377], batch loss: 0.79523, batch accuracy: 67.19, data load time: 0.00237, step time: 0.04512\n",
      "epoch: [2], step: [185/377], batch loss: 0.83524, batch accuracy: 65.62, data load time: 0.00171, step time: 0.04678\n",
      "epoch: [2], step: [195/377], batch loss: 0.84525, batch accuracy: 68.75, data load time: 0.00186, step time: 0.04379\n",
      "epoch: [2], step: [205/377], batch loss: 0.94790, batch accuracy: 57.03, data load time: 0.00225, step time: 0.04492\n",
      "epoch: [2], step: [215/377], batch loss: 0.73941, batch accuracy: 70.31, data load time: 0.00185, step time: 0.04540\n",
      "epoch: [2], step: [225/377], batch loss: 0.78043, batch accuracy: 68.75, data load time: 0.00218, step time: 0.04687\n",
      "epoch: [2], step: [235/377], batch loss: 0.76680, batch accuracy: 65.62, data load time: 0.00196, step time: 0.04368\n",
      "epoch: [2], step: [245/377], batch loss: 0.84598, batch accuracy: 62.50, data load time: 0.00167, step time: 0.04479\n",
      "epoch: [2], step: [255/377], batch loss: 0.86459, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04600\n",
      "epoch: [2], step: [265/377], batch loss: 0.82688, batch accuracy: 64.84, data load time: 0.00176, step time: 0.04608\n",
      "epoch: [2], step: [275/377], batch loss: 0.82050, batch accuracy: 64.84, data load time: 0.00191, step time: 0.04495\n",
      "epoch: [2], step: [285/377], batch loss: 0.80834, batch accuracy: 65.62, data load time: 0.00193, step time: 0.04505\n",
      "epoch: [2], step: [295/377], batch loss: 0.76236, batch accuracy: 66.41, data load time: 0.00165, step time: 0.04598\n",
      "epoch: [2], step: [305/377], batch loss: 0.82667, batch accuracy: 63.28, data load time: 0.00181, step time: 0.04736\n",
      "epoch: [2], step: [315/377], batch loss: 0.71120, batch accuracy: 71.09, data load time: 0.00184, step time: 0.04551\n",
      "epoch: [2], step: [325/377], batch loss: 0.68397, batch accuracy: 72.66, data load time: 0.00200, step time: 0.04397\n",
      "epoch: [2], step: [335/377], batch loss: 0.92490, batch accuracy: 60.16, data load time: 0.00187, step time: 0.04584\n",
      "epoch: [2], step: [345/377], batch loss: 0.69314, batch accuracy: 71.09, data load time: 0.00216, step time: 0.04436\n",
      "epoch: [2], step: [355/377], batch loss: 0.76571, batch accuracy: 71.88, data load time: 0.00184, step time: 0.04604\n",
      "epoch: [2], step: [365/377], batch loss: 0.76975, batch accuracy: 66.41, data load time: 0.00188, step time: 0.04387\n",
      "epoch: [2], step: [375/377], batch loss: 0.81585, batch accuracy: 62.50, data load time: 0.00229, step time: 0.04601\n",
      "epoch: [3], step: [8/377], batch loss: 0.74088, batch accuracy: 71.09, data load time: 0.00198, step time: 0.04570\n",
      "epoch: [3], step: [18/377], batch loss: 0.81784, batch accuracy: 67.97, data load time: 0.00181, step time: 0.04634\n",
      "epoch: [3], step: [28/377], batch loss: 0.84584, batch accuracy: 63.28, data load time: 0.00179, step time: 0.04569\n",
      "epoch: [3], step: [38/377], batch loss: 0.76241, batch accuracy: 64.06, data load time: 0.00193, step time: 0.04607\n",
      "epoch: [3], step: [48/377], batch loss: 0.80168, batch accuracy: 66.41, data load time: 0.00203, step time: 0.04622\n",
      "epoch: [3], step: [58/377], batch loss: 0.82225, batch accuracy: 63.28, data load time: 0.00161, step time: 0.04625\n",
      "epoch: [3], step: [68/377], batch loss: 0.74984, batch accuracy: 67.19, data load time: 0.00165, step time: 0.04709\n",
      "epoch: [3], step: [78/377], batch loss: 0.70723, batch accuracy: 69.53, data load time: 0.00174, step time: 0.04542\n",
      "epoch: [3], step: [88/377], batch loss: 0.85347, batch accuracy: 64.06, data load time: 0.00196, step time: 0.04574\n",
      "epoch: [3], step: [98/377], batch loss: 0.74613, batch accuracy: 67.97, data load time: 0.00212, step time: 0.04589\n",
      "epoch: [3], step: [108/377], batch loss: 0.96332, batch accuracy: 59.38, data load time: 0.00177, step time: 0.04638\n",
      "epoch: [3], step: [118/377], batch loss: 0.75861, batch accuracy: 73.44, data load time: 0.00176, step time: 0.04632\n",
      "epoch: [3], step: [128/377], batch loss: 0.73020, batch accuracy: 69.53, data load time: 0.00182, step time: 0.04563\n",
      "epoch: [3], step: [138/377], batch loss: 0.82352, batch accuracy: 67.19, data load time: 0.00178, step time: 0.04626\n",
      "epoch: [3], step: [148/377], batch loss: 0.78606, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04650\n",
      "epoch: [3], step: [158/377], batch loss: 0.79221, batch accuracy: 66.41, data load time: 0.00174, step time: 0.04626\n",
      "epoch: [3], step: [168/377], batch loss: 0.85019, batch accuracy: 65.62, data load time: 0.00197, step time: 0.04635\n",
      "epoch: [3], step: [178/377], batch loss: 0.76084, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04634\n",
      "epoch: [3], step: [188/377], batch loss: 0.91800, batch accuracy: 64.06, data load time: 0.00194, step time: 0.04598\n",
      "epoch: [3], step: [198/377], batch loss: 0.94819, batch accuracy: 60.94, data load time: 0.00172, step time: 0.04678\n",
      "epoch: [3], step: [208/377], batch loss: 0.76117, batch accuracy: 71.09, data load time: 0.00183, step time: 0.04583\n",
      "epoch: [3], step: [218/377], batch loss: 0.72837, batch accuracy: 71.09, data load time: 0.00181, step time: 0.04612\n",
      "epoch: [3], step: [228/377], batch loss: 0.83994, batch accuracy: 60.94, data load time: 0.00180, step time: 0.04515\n",
      "epoch: [3], step: [238/377], batch loss: 0.86758, batch accuracy: 60.94, data load time: 0.00186, step time: 0.04565\n",
      "epoch: [3], step: [248/377], batch loss: 0.85331, batch accuracy: 65.62, data load time: 0.00179, step time: 0.04752\n",
      "epoch: [3], step: [258/377], batch loss: 0.73010, batch accuracy: 67.97, data load time: 0.00175, step time: 0.04484\n",
      "epoch: [3], step: [268/377], batch loss: 0.77794, batch accuracy: 67.97, data load time: 0.00175, step time: 0.04513\n",
      "epoch: [3], step: [278/377], batch loss: 0.94644, batch accuracy: 54.69, data load time: 0.00173, step time: 0.04681\n",
      "epoch: [3], step: [288/377], batch loss: 0.82870, batch accuracy: 69.53, data load time: 0.00183, step time: 0.04704\n",
      "epoch: [3], step: [298/377], batch loss: 0.89965, batch accuracy: 63.28, data load time: 0.00182, step time: 0.04569\n",
      "epoch: [3], step: [308/377], batch loss: 0.73240, batch accuracy: 75.00, data load time: 0.00180, step time: 0.04598\n",
      "epoch: [3], step: [318/377], batch loss: 0.75653, batch accuracy: 67.97, data load time: 0.00185, step time: 0.04578\n",
      "epoch: [3], step: [328/377], batch loss: 0.73660, batch accuracy: 72.66, data load time: 0.00187, step time: 0.04563\n",
      "epoch: [3], step: [338/377], batch loss: 0.89059, batch accuracy: 58.59, data load time: 0.00180, step time: 0.04651\n",
      "epoch: [3], step: [348/377], batch loss: 0.83530, batch accuracy: 60.94, data load time: 0.00187, step time: 0.04421\n",
      "epoch: [3], step: [358/377], batch loss: 0.95879, batch accuracy: 60.94, data load time: 0.00175, step time: 0.04526\n",
      "epoch: [3], step: [368/377], batch loss: 0.82635, batch accuracy: 63.28, data load time: 0.00170, step time: 0.04541\n",
      "epoch: [4], step: [1/377], batch loss: 0.79927, batch accuracy: 67.97, data load time: 0.00175, step time: 0.04533\n",
      "epoch: [4], step: [11/377], batch loss: 0.74026, batch accuracy: 65.62, data load time: 0.00179, step time: 0.04414\n",
      "epoch: [4], step: [21/377], batch loss: 0.80949, batch accuracy: 64.06, data load time: 0.00176, step time: 0.04667\n",
      "epoch: [4], step: [31/377], batch loss: 0.75702, batch accuracy: 68.75, data load time: 0.00182, step time: 0.04644\n",
      "epoch: [4], step: [41/377], batch loss: 0.76189, batch accuracy: 66.41, data load time: 0.00171, step time: 0.04551\n",
      "epoch: [4], step: [51/377], batch loss: 0.80593, batch accuracy: 65.62, data load time: 0.00173, step time: 0.04512\n",
      "epoch: [4], step: [61/377], batch loss: 0.70015, batch accuracy: 69.53, data load time: 0.00176, step time: 0.04572\n",
      "epoch: [4], step: [71/377], batch loss: 0.85670, batch accuracy: 63.28, data load time: 0.00173, step time: 0.04676\n",
      "epoch: [4], step: [81/377], batch loss: 0.80840, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04599\n",
      "epoch: [4], step: [91/377], batch loss: 0.81331, batch accuracy: 67.97, data load time: 0.00172, step time: 0.04526\n",
      "epoch: [4], step: [101/377], batch loss: 0.84719, batch accuracy: 61.72, data load time: 0.00170, step time: 0.04578\n",
      "epoch: [4], step: [111/377], batch loss: 0.76444, batch accuracy: 64.84, data load time: 0.00183, step time: 0.04653\n",
      "epoch: [4], step: [121/377], batch loss: 0.86262, batch accuracy: 63.28, data load time: 0.00182, step time: 0.04641\n",
      "epoch: [4], step: [131/377], batch loss: 0.77058, batch accuracy: 70.31, data load time: 0.00177, step time: 0.04588\n",
      "epoch: [4], step: [141/377], batch loss: 0.84895, batch accuracy: 63.28, data load time: 0.00184, step time: 0.04405\n",
      "epoch: [4], step: [151/377], batch loss: 0.73577, batch accuracy: 68.75, data load time: 0.00190, step time: 0.04681\n",
      "epoch: [4], step: [161/377], batch loss: 0.91327, batch accuracy: 62.50, data load time: 0.00193, step time: 0.04597\n",
      "epoch: [4], step: [171/377], batch loss: 0.86645, batch accuracy: 62.50, data load time: 0.00192, step time: 0.04564\n",
      "epoch: [4], step: [181/377], batch loss: 0.78627, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04563\n",
      "epoch: [4], step: [191/377], batch loss: 0.75670, batch accuracy: 68.75, data load time: 0.00185, step time: 0.04483\n",
      "epoch: [4], step: [201/377], batch loss: 0.77248, batch accuracy: 65.62, data load time: 0.00179, step time: 0.04659\n",
      "epoch: [4], step: [211/377], batch loss: 0.70313, batch accuracy: 70.31, data load time: 0.00173, step time: 0.04460\n",
      "epoch: [4], step: [221/377], batch loss: 0.71690, batch accuracy: 70.31, data load time: 0.00166, step time: 0.04550\n",
      "epoch: [4], step: [231/377], batch loss: 0.73798, batch accuracy: 68.75, data load time: 0.00164, step time: 0.04526\n",
      "epoch: [4], step: [241/377], batch loss: 0.80449, batch accuracy: 65.62, data load time: 0.00226, step time: 0.04672\n",
      "epoch: [4], step: [251/377], batch loss: 0.76061, batch accuracy: 66.41, data load time: 0.00228, step time: 0.04659\n",
      "epoch: [4], step: [261/377], batch loss: 0.74591, batch accuracy: 64.84, data load time: 0.00175, step time: 0.04523\n",
      "epoch: [4], step: [271/377], batch loss: 0.74802, batch accuracy: 69.53, data load time: 0.00239, step time: 0.04433\n",
      "epoch: [4], step: [281/377], batch loss: 0.69814, batch accuracy: 70.31, data load time: 0.00184, step time: 0.04603\n",
      "epoch: [4], step: [291/377], batch loss: 0.72686, batch accuracy: 65.62, data load time: 0.00221, step time: 0.04746\n",
      "epoch: [4], step: [301/377], batch loss: 0.80849, batch accuracy: 64.84, data load time: 0.00180, step time: 0.04538\n",
      "epoch: [4], step: [311/377], batch loss: 0.77924, batch accuracy: 69.53, data load time: 0.00172, step time: 0.04519\n",
      "epoch: [4], step: [321/377], batch loss: 0.86005, batch accuracy: 68.75, data load time: 0.00182, step time: 0.04540\n",
      "epoch: [4], step: [331/377], batch loss: 0.78321, batch accuracy: 67.97, data load time: 0.00184, step time: 0.04580\n",
      "epoch: [4], step: [341/377], batch loss: 0.88400, batch accuracy: 64.84, data load time: 0.00217, step time: 0.04601\n",
      "epoch: [4], step: [351/377], batch loss: 0.74085, batch accuracy: 69.53, data load time: 0.00176, step time: 0.04570\n",
      "epoch: [4], step: [361/377], batch loss: 0.95251, batch accuracy: 60.16, data load time: 0.00178, step time: 0.04529\n",
      "epoch: [4], step: [371/377], batch loss: 0.79532, batch accuracy: 65.62, data load time: 0.00233, step time: 0.04432\n",
      "epoch: [5], step: [4/377], batch loss: 0.88119, batch accuracy: 67.97, data load time: 0.00164, step time: 0.04563\n",
      "epoch: [5], step: [14/377], batch loss: 0.77289, batch accuracy: 71.88, data load time: 0.00194, step time: 0.04569\n",
      "epoch: [5], step: [24/377], batch loss: 0.74881, batch accuracy: 68.75, data load time: 0.00186, step time: 0.04589\n",
      "epoch: [5], step: [34/377], batch loss: 0.71933, batch accuracy: 67.97, data load time: 0.00168, step time: 0.04691\n",
      "epoch: [5], step: [44/377], batch loss: 0.78557, batch accuracy: 68.75, data load time: 0.00172, step time: 0.04623\n",
      "epoch: [5], step: [54/377], batch loss: 0.72112, batch accuracy: 71.09, data load time: 0.00164, step time: 0.04521\n",
      "epoch: [5], step: [64/377], batch loss: 0.76436, batch accuracy: 71.09, data load time: 0.00181, step time: 0.04558\n",
      "epoch: [5], step: [74/377], batch loss: 0.81434, batch accuracy: 67.19, data load time: 0.00189, step time: 0.04568\n",
      "epoch: [5], step: [84/377], batch loss: 0.87953, batch accuracy: 67.19, data load time: 0.00168, step time: 0.04646\n",
      "epoch: [5], step: [94/377], batch loss: 0.85445, batch accuracy: 62.50, data load time: 0.00166, step time: 0.04662\n",
      "epoch: [5], step: [104/377], batch loss: 0.78881, batch accuracy: 64.84, data load time: 0.00165, step time: 0.04563\n",
      "epoch: [5], step: [114/377], batch loss: 0.76652, batch accuracy: 69.53, data load time: 0.00180, step time: 0.04510\n",
      "epoch: [5], step: [124/377], batch loss: 0.85144, batch accuracy: 64.84, data load time: 0.00173, step time: 0.04613\n",
      "epoch: [5], step: [134/377], batch loss: 0.79377, batch accuracy: 64.06, data load time: 0.00184, step time: 0.04556\n",
      "epoch: [5], step: [144/377], batch loss: 0.62744, batch accuracy: 75.78, data load time: 0.00164, step time: 0.04624\n",
      "epoch: [5], step: [154/377], batch loss: 0.80035, batch accuracy: 67.19, data load time: 0.00169, step time: 0.04456\n",
      "epoch: [5], step: [164/377], batch loss: 0.77086, batch accuracy: 70.31, data load time: 0.00199, step time: 0.04581\n",
      "epoch: [5], step: [174/377], batch loss: 0.75894, batch accuracy: 66.41, data load time: 0.00166, step time: 0.04652\n",
      "epoch: [5], step: [184/377], batch loss: 0.74448, batch accuracy: 66.41, data load time: 0.00157, step time: 0.04616\n",
      "epoch: [5], step: [194/377], batch loss: 0.76607, batch accuracy: 67.97, data load time: 0.00182, step time: 0.04527\n",
      "epoch: [5], step: [204/377], batch loss: 0.71356, batch accuracy: 71.88, data load time: 0.00168, step time: 0.04576\n",
      "epoch: [5], step: [214/377], batch loss: 0.79112, batch accuracy: 63.28, data load time: 0.00165, step time: 0.04576\n",
      "epoch: [5], step: [224/377], batch loss: 0.85992, batch accuracy: 64.84, data load time: 0.00184, step time: 0.04677\n",
      "epoch: [5], step: [234/377], batch loss: 0.74206, batch accuracy: 70.31, data load time: 0.00168, step time: 0.04661\n",
      "epoch: [5], step: [244/377], batch loss: 0.84402, batch accuracy: 66.41, data load time: 0.00165, step time: 0.04510\n",
      "epoch: [5], step: [254/377], batch loss: 0.81916, batch accuracy: 64.06, data load time: 0.00174, step time: 0.04496\n",
      "epoch: [5], step: [264/377], batch loss: 0.68377, batch accuracy: 69.53, data load time: 0.00167, step time: 0.04618\n",
      "epoch: [5], step: [274/377], batch loss: 0.73045, batch accuracy: 68.75, data load time: 0.00162, step time: 0.04638\n",
      "epoch: [5], step: [284/377], batch loss: 0.71883, batch accuracy: 75.00, data load time: 0.00166, step time: 0.04468\n",
      "epoch: [5], step: [294/377], batch loss: 0.81554, batch accuracy: 66.41, data load time: 0.00173, step time: 0.04540\n",
      "epoch: [5], step: [304/377], batch loss: 0.78406, batch accuracy: 64.06, data load time: 0.00178, step time: 0.04729\n",
      "epoch: [5], step: [314/377], batch loss: 0.88470, batch accuracy: 63.28, data load time: 0.00172, step time: 0.04541\n",
      "epoch: [5], step: [324/377], batch loss: 0.79985, batch accuracy: 67.97, data load time: 0.00165, step time: 0.04560\n",
      "epoch: [5], step: [334/377], batch loss: 0.81031, batch accuracy: 67.97, data load time: 0.00165, step time: 0.04398\n",
      "epoch: [5], step: [344/377], batch loss: 0.74511, batch accuracy: 68.75, data load time: 0.00163, step time: 0.04605\n",
      "epoch: [5], step: [354/377], batch loss: 0.70223, batch accuracy: 72.66, data load time: 0.00173, step time: 0.04623\n",
      "epoch: [5], step: [364/377], batch loss: 0.75646, batch accuracy: 69.53, data load time: 0.00164, step time: 0.04669\n",
      "epoch: [5], step: [374/377], batch loss: 0.76587, batch accuracy: 67.97, data load time: 0.00174, step time: 0.04559\n",
      "epoch: [6], step: [7/377], batch loss: 0.74152, batch accuracy: 72.66, data load time: 0.00163, step time: 0.04552\n",
      "epoch: [6], step: [17/377], batch loss: 0.77320, batch accuracy: 69.53, data load time: 0.00168, step time: 0.04512\n",
      "epoch: [6], step: [27/377], batch loss: 0.85803, batch accuracy: 67.19, data load time: 0.00187, step time: 0.04454\n",
      "epoch: [6], step: [37/377], batch loss: 0.74962, batch accuracy: 66.41, data load time: 0.00165, step time: 0.04644\n",
      "epoch: [6], step: [47/377], batch loss: 0.68892, batch accuracy: 70.31, data load time: 0.00168, step time: 0.04586\n",
      "epoch: [6], step: [57/377], batch loss: 0.80874, batch accuracy: 65.62, data load time: 0.00178, step time: 0.04588\n",
      "epoch: [6], step: [67/377], batch loss: 0.73480, batch accuracy: 69.53, data load time: 0.00178, step time: 0.04597\n",
      "epoch: [6], step: [77/377], batch loss: 0.72391, batch accuracy: 68.75, data load time: 0.00168, step time: 0.04712\n",
      "epoch: [6], step: [87/377], batch loss: 0.83156, batch accuracy: 62.50, data load time: 0.00169, step time: 0.04680\n",
      "epoch: [6], step: [97/377], batch loss: 0.78621, batch accuracy: 69.53, data load time: 0.00168, step time: 0.04598\n",
      "epoch: [6], step: [107/377], batch loss: 0.80247, batch accuracy: 62.50, data load time: 0.00165, step time: 0.04599\n",
      "epoch: [6], step: [117/377], batch loss: 0.66092, batch accuracy: 75.00, data load time: 0.00174, step time: 0.04603\n",
      "epoch: [6], step: [127/377], batch loss: 0.95805, batch accuracy: 60.94, data load time: 0.00168, step time: 0.04632\n",
      "epoch: [6], step: [137/377], batch loss: 0.84677, batch accuracy: 65.62, data load time: 0.00163, step time: 0.04661\n",
      "epoch: [6], step: [147/377], batch loss: 0.73598, batch accuracy: 70.31, data load time: 0.00163, step time: 0.04723\n",
      "epoch: [6], step: [157/377], batch loss: 0.81523, batch accuracy: 63.28, data load time: 0.00164, step time: 0.04599\n",
      "epoch: [6], step: [167/377], batch loss: 0.85500, batch accuracy: 65.62, data load time: 0.00172, step time: 0.04516\n",
      "epoch: [6], step: [177/377], batch loss: 0.73806, batch accuracy: 71.09, data load time: 0.00192, step time: 0.04534\n",
      "epoch: [6], step: [187/377], batch loss: 0.81937, batch accuracy: 59.38, data load time: 0.00166, step time: 0.04630\n",
      "epoch: [6], step: [197/377], batch loss: 0.87169, batch accuracy: 62.50, data load time: 0.00163, step time: 0.04667\n",
      "epoch: [6], step: [207/377], batch loss: 0.79224, batch accuracy: 67.19, data load time: 0.00164, step time: 0.04670\n",
      "epoch: [6], step: [217/377], batch loss: 0.73305, batch accuracy: 71.88, data load time: 0.00171, step time: 0.04581\n",
      "epoch: [6], step: [227/377], batch loss: 0.76999, batch accuracy: 68.75, data load time: 0.00180, step time: 0.04617\n",
      "epoch: [6], step: [237/377], batch loss: 0.77890, batch accuracy: 62.50, data load time: 0.00174, step time: 0.04622\n",
      "epoch: [6], step: [247/377], batch loss: 0.83205, batch accuracy: 64.84, data load time: 0.00158, step time: 0.04610\n",
      "epoch: [6], step: [257/377], batch loss: 0.67572, batch accuracy: 73.44, data load time: 0.00163, step time: 0.04650\n",
      "epoch: [6], step: [267/377], batch loss: 0.68525, batch accuracy: 75.00, data load time: 0.00163, step time: 0.04587\n",
      "epoch: [6], step: [277/377], batch loss: 0.76865, batch accuracy: 62.50, data load time: 0.00163, step time: 0.04663\n",
      "epoch: [6], step: [287/377], batch loss: 0.78430, batch accuracy: 67.19, data load time: 0.00163, step time: 0.04674\n",
      "epoch: [6], step: [297/377], batch loss: 0.82513, batch accuracy: 67.97, data load time: 0.00179, step time: 0.04677\n",
      "epoch: [6], step: [307/377], batch loss: 0.69461, batch accuracy: 72.66, data load time: 0.00207, step time: 0.04718\n",
      "epoch: [6], step: [317/377], batch loss: 0.93588, batch accuracy: 64.84, data load time: 0.00144, step time: 0.04697\n",
      "epoch: [6], step: [327/377], batch loss: 0.76678, batch accuracy: 65.62, data load time: 0.00158, step time: 0.04638\n",
      "epoch: [6], step: [337/377], batch loss: 0.72776, batch accuracy: 66.41, data load time: 0.00174, step time: 0.04518\n",
      "epoch: [6], step: [347/377], batch loss: 0.81049, batch accuracy: 67.97, data load time: 0.00173, step time: 0.04532\n",
      "epoch: [6], step: [357/377], batch loss: 0.85956, batch accuracy: 61.72, data load time: 0.00220, step time: 0.04688\n",
      "epoch: [6], step: [367/377], batch loss: 0.81830, batch accuracy: 66.41, data load time: 0.00169, step time: 0.04594\n",
      "epoch: [7], step: [0/377], batch loss: 0.84268, batch accuracy: 62.50, data load time: 0.00429, step time: 0.04696\n",
      "epoch: [7], step: [10/377], batch loss: 0.74071, batch accuracy: 69.53, data load time: 0.00162, step time: 0.04670\n",
      "epoch: [7], step: [20/377], batch loss: 0.73346, batch accuracy: 68.75, data load time: 0.00165, step time: 0.04608\n",
      "epoch: [7], step: [30/377], batch loss: 0.85495, batch accuracy: 64.84, data load time: 0.00167, step time: 0.04515\n",
      "epoch: [7], step: [40/377], batch loss: 0.85763, batch accuracy: 62.50, data load time: 0.00167, step time: 0.04639\n",
      "epoch: [7], step: [50/377], batch loss: 0.73000, batch accuracy: 68.75, data load time: 0.00164, step time: 0.04735\n",
      "epoch: [7], step: [60/377], batch loss: 0.67816, batch accuracy: 69.53, data load time: 0.00166, step time: 0.04634\n",
      "epoch: [7], step: [70/377], batch loss: 0.67148, batch accuracy: 71.88, data load time: 0.00166, step time: 0.04721\n",
      "epoch: [7], step: [80/377], batch loss: 0.75669, batch accuracy: 72.66, data load time: 0.00160, step time: 0.04617\n",
      "epoch: [7], step: [90/377], batch loss: 0.76762, batch accuracy: 70.31, data load time: 0.00157, step time: 0.04643\n",
      "epoch: [7], step: [100/377], batch loss: 0.79851, batch accuracy: 64.84, data load time: 0.00173, step time: 0.04634\n",
      "epoch: [7], step: [110/377], batch loss: 0.80107, batch accuracy: 61.72, data load time: 0.00171, step time: 0.04616\n",
      "epoch: [7], step: [120/377], batch loss: 0.77515, batch accuracy: 73.44, data load time: 0.00170, step time: 0.04433\n",
      "epoch: [7], step: [130/377], batch loss: 0.78881, batch accuracy: 67.97, data load time: 0.00179, step time: 0.04554\n",
      "epoch: [7], step: [140/377], batch loss: 0.69287, batch accuracy: 72.66, data load time: 0.00171, step time: 0.04628\n",
      "epoch: [7], step: [150/377], batch loss: 0.76204, batch accuracy: 73.44, data load time: 0.00166, step time: 0.04553\n",
      "epoch: [7], step: [160/377], batch loss: 0.94520, batch accuracy: 57.81, data load time: 0.00183, step time: 0.04596\n",
      "epoch: [7], step: [170/377], batch loss: 0.89791, batch accuracy: 60.94, data load time: 0.00200, step time: 0.04636\n",
      "epoch: [7], step: [180/377], batch loss: 0.84939, batch accuracy: 58.59, data load time: 0.00172, step time: 0.04574\n",
      "epoch: [7], step: [190/377], batch loss: 0.81574, batch accuracy: 68.75, data load time: 0.00168, step time: 0.04629\n",
      "epoch: [7], step: [200/377], batch loss: 0.73470, batch accuracy: 67.19, data load time: 0.00169, step time: 0.04663\n",
      "epoch: [7], step: [210/377], batch loss: 0.77950, batch accuracy: 64.06, data load time: 0.00150, step time: 0.04674\n",
      "epoch: [7], step: [220/377], batch loss: 0.87077, batch accuracy: 62.50, data load time: 0.00160, step time: 0.04596\n",
      "epoch: [7], step: [230/377], batch loss: 0.75370, batch accuracy: 69.53, data load time: 0.00164, step time: 0.04476\n",
      "epoch: [7], step: [240/377], batch loss: 0.87296, batch accuracy: 58.59, data load time: 0.00168, step time: 0.04676\n",
      "epoch: [7], step: [250/377], batch loss: 0.74458, batch accuracy: 71.09, data load time: 0.00174, step time: 0.04544\n",
      "epoch: [7], step: [260/377], batch loss: 0.85879, batch accuracy: 64.84, data load time: 0.00191, step time: 0.04619\n",
      "epoch: [7], step: [270/377], batch loss: 0.80755, batch accuracy: 60.94, data load time: 0.00177, step time: 0.04640\n",
      "epoch: [7], step: [280/377], batch loss: 0.66545, batch accuracy: 74.22, data load time: 0.00162, step time: 0.04735\n",
      "epoch: [7], step: [290/377], batch loss: 0.98301, batch accuracy: 59.38, data load time: 0.00173, step time: 0.04627\n",
      "epoch: [7], step: [300/377], batch loss: 0.80228, batch accuracy: 64.84, data load time: 0.00164, step time: 0.04527\n",
      "epoch: [7], step: [310/377], batch loss: 0.79446, batch accuracy: 66.41, data load time: 0.00162, step time: 0.04621\n",
      "epoch: [7], step: [320/377], batch loss: 0.80303, batch accuracy: 68.75, data load time: 0.00187, step time: 0.04598\n",
      "epoch: [7], step: [330/377], batch loss: 0.77206, batch accuracy: 67.19, data load time: 0.00172, step time: 0.04451\n",
      "epoch: [7], step: [340/377], batch loss: 0.77577, batch accuracy: 69.53, data load time: 0.00185, step time: 0.04699\n",
      "epoch: [7], step: [350/377], batch loss: 0.75167, batch accuracy: 60.94, data load time: 0.00162, step time: 0.04681\n",
      "epoch: [7], step: [360/377], batch loss: 0.89233, batch accuracy: 61.72, data load time: 0.00168, step time: 0.04645\n",
      "epoch: [7], step: [370/377], batch loss: 0.87688, batch accuracy: 61.72, data load time: 0.00182, step time: 0.04658\n",
      "epoch: [8], step: [3/377], batch loss: 0.75682, batch accuracy: 69.53, data load time: 0.00181, step time: 0.04632\n",
      "epoch: [8], step: [13/377], batch loss: 0.80793, batch accuracy: 67.97, data load time: 0.00172, step time: 0.04598\n",
      "epoch: [8], step: [23/377], batch loss: 0.86568, batch accuracy: 64.06, data load time: 0.00168, step time: 0.04700\n",
      "epoch: [8], step: [33/377], batch loss: 0.90640, batch accuracy: 62.50, data load time: 0.00188, step time: 0.04616\n",
      "epoch: [8], step: [43/377], batch loss: 0.79110, batch accuracy: 64.84, data load time: 0.00175, step time: 0.04712\n",
      "epoch: [8], step: [53/377], batch loss: 0.73843, batch accuracy: 71.09, data load time: 0.00182, step time: 0.04617\n",
      "epoch: [8], step: [63/377], batch loss: 0.85298, batch accuracy: 62.50, data load time: 0.00168, step time: 0.04608\n",
      "epoch: [8], step: [73/377], batch loss: 0.84650, batch accuracy: 67.97, data load time: 0.00162, step time: 0.04568\n",
      "epoch: [8], step: [83/377], batch loss: 0.70184, batch accuracy: 70.31, data load time: 0.00181, step time: 0.04578\n",
      "epoch: [8], step: [93/377], batch loss: 0.82979, batch accuracy: 64.84, data load time: 0.00187, step time: 0.04586\n",
      "epoch: [8], step: [103/377], batch loss: 0.71824, batch accuracy: 71.09, data load time: 0.00168, step time: 0.04631\n",
      "epoch: [8], step: [113/377], batch loss: 0.70753, batch accuracy: 67.97, data load time: 0.00170, step time: 0.04713\n",
      "epoch: [8], step: [123/377], batch loss: 0.87135, batch accuracy: 63.28, data load time: 0.00176, step time: 0.04718\n",
      "epoch: [8], step: [133/377], batch loss: 0.83609, batch accuracy: 64.84, data load time: 0.00165, step time: 0.04653\n",
      "epoch: [8], step: [143/377], batch loss: 0.84187, batch accuracy: 60.16, data load time: 0.00167, step time: 0.04746\n",
      "epoch: [8], step: [153/377], batch loss: 0.79038, batch accuracy: 65.62, data load time: 0.00170, step time: 0.04622\n",
      "epoch: [8], step: [163/377], batch loss: 0.88902, batch accuracy: 63.28, data load time: 0.00162, step time: 0.04556\n",
      "epoch: [8], step: [173/377], batch loss: 0.81853, batch accuracy: 64.06, data load time: 0.00179, step time: 0.04645\n",
      "epoch: [8], step: [183/377], batch loss: 0.63396, batch accuracy: 77.34, data load time: 0.00170, step time: 0.04621\n",
      "epoch: [8], step: [193/377], batch loss: 0.83516, batch accuracy: 58.59, data load time: 0.00161, step time: 0.04670\n",
      "epoch: [8], step: [203/377], batch loss: 0.82529, batch accuracy: 67.19, data load time: 0.00173, step time: 0.04496\n",
      "epoch: [8], step: [213/377], batch loss: 0.68626, batch accuracy: 72.66, data load time: 0.00167, step time: 0.04620\n",
      "epoch: [8], step: [223/377], batch loss: 0.81072, batch accuracy: 69.53, data load time: 0.00174, step time: 0.04552\n",
      "epoch: [8], step: [233/377], batch loss: 0.82654, batch accuracy: 66.41, data load time: 0.00176, step time: 0.04465\n",
      "epoch: [8], step: [243/377], batch loss: 0.86570, batch accuracy: 64.06, data load time: 0.00183, step time: 0.04595\n",
      "epoch: [8], step: [253/377], batch loss: 0.79786, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04701\n",
      "epoch: [8], step: [263/377], batch loss: 0.71137, batch accuracy: 68.75, data load time: 0.00173, step time: 0.04642\n",
      "epoch: [8], step: [273/377], batch loss: 0.77688, batch accuracy: 71.09, data load time: 0.00188, step time: 0.04647\n",
      "epoch: [8], step: [283/377], batch loss: 0.88869, batch accuracy: 63.28, data load time: 0.00181, step time: 0.04704\n",
      "epoch: [8], step: [293/377], batch loss: 0.77548, batch accuracy: 64.84, data load time: 0.00179, step time: 0.04713\n",
      "epoch: [8], step: [303/377], batch loss: 1.05082, batch accuracy: 60.16, data load time: 0.00230, step time: 0.04735\n",
      "epoch: [8], step: [313/377], batch loss: 0.80965, batch accuracy: 65.62, data load time: 0.00172, step time: 0.04629\n",
      "epoch: [8], step: [323/377], batch loss: 0.73383, batch accuracy: 67.97, data load time: 0.00225, step time: 0.04634\n",
      "epoch: [8], step: [333/377], batch loss: 0.79391, batch accuracy: 65.62, data load time: 0.00207, step time: 0.04715\n",
      "epoch: [8], step: [343/377], batch loss: 0.72688, batch accuracy: 74.22, data load time: 0.00245, step time: 0.04785\n",
      "epoch: [8], step: [353/377], batch loss: 0.66708, batch accuracy: 71.88, data load time: 0.00177, step time: 0.04714\n",
      "epoch: [8], step: [363/377], batch loss: 0.88509, batch accuracy: 60.94, data load time: 0.00194, step time: 0.04706\n",
      "epoch: [8], step: [373/377], batch loss: 0.78888, batch accuracy: 69.53, data load time: 0.00163, step time: 0.04722\n",
      "epoch: [9], step: [6/377], batch loss: 0.73453, batch accuracy: 68.75, data load time: 0.00167, step time: 0.04743\n",
      "epoch: [9], step: [16/377], batch loss: 0.73301, batch accuracy: 67.19, data load time: 0.00167, step time: 0.04760\n",
      "epoch: [9], step: [26/377], batch loss: 0.78754, batch accuracy: 66.41, data load time: 0.00172, step time: 0.04625\n",
      "epoch: [9], step: [36/377], batch loss: 0.84474, batch accuracy: 62.50, data load time: 0.00173, step time: 0.04662\n",
      "epoch: [9], step: [46/377], batch loss: 0.94233, batch accuracy: 55.47, data load time: 0.00166, step time: 0.04592\n",
      "epoch: [9], step: [56/377], batch loss: 0.78317, batch accuracy: 65.62, data load time: 0.00177, step time: 0.04583\n",
      "epoch: [9], step: [66/377], batch loss: 0.75793, batch accuracy: 67.97, data load time: 0.00181, step time: 0.04604\n",
      "epoch: [9], step: [76/377], batch loss: 0.74340, batch accuracy: 65.62, data load time: 0.00210, step time: 0.04559\n",
      "epoch: [9], step: [86/377], batch loss: 0.77081, batch accuracy: 64.84, data load time: 0.00181, step time: 0.04707\n",
      "epoch: [9], step: [96/377], batch loss: 0.68769, batch accuracy: 70.31, data load time: 0.00160, step time: 0.04627\n",
      "epoch: [9], step: [106/377], batch loss: 0.85630, batch accuracy: 65.62, data load time: 0.00184, step time: 0.04718\n",
      "epoch: [9], step: [116/377], batch loss: 0.71043, batch accuracy: 71.88, data load time: 0.00163, step time: 0.04672\n",
      "epoch: [9], step: [126/377], batch loss: 0.80899, batch accuracy: 60.94, data load time: 0.00170, step time: 0.04650\n",
      "epoch: [9], step: [136/377], batch loss: 0.82252, batch accuracy: 61.72, data load time: 0.00172, step time: 0.04682\n",
      "epoch: [9], step: [146/377], batch loss: 0.78939, batch accuracy: 68.75, data load time: 0.00161, step time: 0.04710\n",
      "epoch: [9], step: [156/377], batch loss: 0.86984, batch accuracy: 64.06, data load time: 0.00166, step time: 0.04565\n",
      "epoch: [9], step: [166/377], batch loss: 0.82389, batch accuracy: 64.06, data load time: 0.00180, step time: 0.04634\n",
      "epoch: [9], step: [176/377], batch loss: 0.80564, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04643\n",
      "epoch: [9], step: [186/377], batch loss: 0.84211, batch accuracy: 67.97, data load time: 0.00175, step time: 0.04629\n",
      "epoch: [9], step: [196/377], batch loss: 0.85055, batch accuracy: 65.62, data load time: 0.00177, step time: 0.04639\n",
      "epoch: [9], step: [206/377], batch loss: 0.94239, batch accuracy: 66.41, data load time: 0.00181, step time: 0.04537\n",
      "epoch: [9], step: [216/377], batch loss: 0.89888, batch accuracy: 60.94, data load time: 0.00168, step time: 0.04566\n",
      "epoch: [9], step: [226/377], batch loss: 0.74953, batch accuracy: 65.62, data load time: 0.00187, step time: 0.04603\n",
      "epoch: [9], step: [236/377], batch loss: 0.74310, batch accuracy: 68.75, data load time: 0.00183, step time: 0.04502\n",
      "epoch: [9], step: [246/377], batch loss: 0.71145, batch accuracy: 68.75, data load time: 0.00197, step time: 0.04600\n",
      "epoch: [9], step: [256/377], batch loss: 0.73897, batch accuracy: 73.44, data load time: 0.00196, step time: 0.04619\n",
      "epoch: [9], step: [266/377], batch loss: 0.90685, batch accuracy: 64.06, data load time: 0.00182, step time: 0.04656\n",
      "epoch: [9], step: [276/377], batch loss: 0.89976, batch accuracy: 65.62, data load time: 0.00169, step time: 0.04659\n",
      "epoch: [9], step: [286/377], batch loss: 0.89013, batch accuracy: 63.28, data load time: 0.00174, step time: 0.04719\n",
      "epoch: [9], step: [296/377], batch loss: 0.81574, batch accuracy: 65.62, data load time: 0.00175, step time: 0.04683\n",
      "epoch: [9], step: [306/377], batch loss: 0.73133, batch accuracy: 71.09, data load time: 0.00172, step time: 0.04664\n",
      "epoch: [9], step: [316/377], batch loss: 0.80324, batch accuracy: 62.50, data load time: 0.00165, step time: 0.04623\n",
      "epoch: [9], step: [326/377], batch loss: 0.71654, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04721\n",
      "epoch: [9], step: [336/377], batch loss: 0.76344, batch accuracy: 68.75, data load time: 0.00175, step time: 0.04653\n",
      "epoch: [9], step: [346/377], batch loss: 0.81802, batch accuracy: 67.19, data load time: 0.00175, step time: 0.04743\n",
      "epoch: [9], step: [356/377], batch loss: 0.73571, batch accuracy: 69.53, data load time: 0.00178, step time: 0.04719\n",
      "epoch: [9], step: [366/377], batch loss: 0.80468, batch accuracy: 62.50, data load time: 0.00181, step time: 0.04682\n",
      "epoch: [9], step: [376/377], batch loss: 0.73304, batch accuracy: 75.00, data load time: 0.00185, step time: 0.01964\n",
      "epoch: [10], step: [9/377], batch loss: 0.69291, batch accuracy: 71.88, data load time: 0.00182, step time: 0.04538\n",
      "epoch: [10], step: [19/377], batch loss: 0.78100, batch accuracy: 64.06, data load time: 0.00189, step time: 0.04518\n",
      "epoch: [10], step: [29/377], batch loss: 0.84766, batch accuracy: 67.19, data load time: 0.00193, step time: 0.04628\n",
      "epoch: [10], step: [39/377], batch loss: 0.88826, batch accuracy: 60.16, data load time: 0.00163, step time: 0.04519\n",
      "epoch: [10], step: [49/377], batch loss: 0.81220, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04633\n",
      "epoch: [10], step: [59/377], batch loss: 0.92761, batch accuracy: 64.06, data load time: 0.00192, step time: 0.04645\n",
      "epoch: [10], step: [69/377], batch loss: 0.67322, batch accuracy: 69.53, data load time: 0.00175, step time: 0.04576\n",
      "epoch: [10], step: [79/377], batch loss: 0.72426, batch accuracy: 65.62, data load time: 0.00184, step time: 0.04592\n",
      "epoch: [10], step: [89/377], batch loss: 0.79828, batch accuracy: 64.06, data load time: 0.00194, step time: 0.04623\n",
      "epoch: [10], step: [99/377], batch loss: 0.70041, batch accuracy: 70.31, data load time: 0.00183, step time: 0.04654\n",
      "epoch: [10], step: [109/377], batch loss: 0.75096, batch accuracy: 67.97, data load time: 0.00176, step time: 0.04667\n",
      "epoch: [10], step: [119/377], batch loss: 0.76005, batch accuracy: 69.53, data load time: 0.00183, step time: 0.04726\n",
      "epoch: [10], step: [129/377], batch loss: 0.73401, batch accuracy: 67.97, data load time: 0.00182, step time: 0.04744\n",
      "epoch: [10], step: [139/377], batch loss: 0.71736, batch accuracy: 67.97, data load time: 0.00171, step time: 0.04637\n",
      "epoch: [10], step: [149/377], batch loss: 0.95321, batch accuracy: 60.94, data load time: 0.00197, step time: 0.04620\n",
      "epoch: [10], step: [159/377], batch loss: 0.81832, batch accuracy: 64.84, data load time: 0.00184, step time: 0.04568\n",
      "epoch: [10], step: [169/377], batch loss: 0.81218, batch accuracy: 67.97, data load time: 0.00179, step time: 0.04574\n",
      "epoch: [10], step: [179/377], batch loss: 0.66316, batch accuracy: 71.09, data load time: 0.00165, step time: 0.04644\n",
      "epoch: [10], step: [189/377], batch loss: 0.91783, batch accuracy: 64.84, data load time: 0.00173, step time: 0.04720\n",
      "epoch: [10], step: [199/377], batch loss: 0.69451, batch accuracy: 71.88, data load time: 0.00181, step time: 0.04659\n",
      "epoch: [10], step: [209/377], batch loss: 0.85008, batch accuracy: 64.84, data load time: 0.00174, step time: 0.04690\n",
      "epoch: [10], step: [219/377], batch loss: 0.69690, batch accuracy: 73.44, data load time: 0.00179, step time: 0.04684\n",
      "epoch: [10], step: [229/377], batch loss: 0.89585, batch accuracy: 60.94, data load time: 0.00162, step time: 0.04688\n",
      "epoch: [10], step: [239/377], batch loss: 0.83013, batch accuracy: 62.50, data load time: 0.00217, step time: 0.04646\n",
      "epoch: [10], step: [249/377], batch loss: 0.76095, batch accuracy: 68.75, data load time: 0.00177, step time: 0.04746\n",
      "epoch: [10], step: [259/377], batch loss: 0.67681, batch accuracy: 73.44, data load time: 0.00233, step time: 0.04634\n",
      "epoch: [10], step: [269/377], batch loss: 0.91930, batch accuracy: 60.16, data load time: 0.00181, step time: 0.04726\n",
      "epoch: [10], step: [279/377], batch loss: 0.70341, batch accuracy: 68.75, data load time: 0.00225, step time: 0.04621\n",
      "epoch: [10], step: [289/377], batch loss: 0.83200, batch accuracy: 67.19, data load time: 0.00204, step time: 0.04740\n",
      "epoch: [10], step: [299/377], batch loss: 0.73780, batch accuracy: 66.41, data load time: 0.00178, step time: 0.04662\n",
      "epoch: [10], step: [309/377], batch loss: 0.97086, batch accuracy: 56.25, data load time: 0.00168, step time: 0.04732\n",
      "epoch: [10], step: [319/377], batch loss: 0.79041, batch accuracy: 64.84, data load time: 0.00176, step time: 0.04692\n",
      "epoch: [10], step: [329/377], batch loss: 0.80931, batch accuracy: 65.62, data load time: 0.00225, step time: 0.04728\n",
      "epoch: [10], step: [339/377], batch loss: 0.68906, batch accuracy: 72.66, data load time: 0.00193, step time: 0.04602\n",
      "epoch: [10], step: [349/377], batch loss: 0.70265, batch accuracy: 70.31, data load time: 0.00196, step time: 0.04595\n",
      "epoch: [10], step: [359/377], batch loss: 0.79770, batch accuracy: 67.19, data load time: 0.00189, step time: 0.04480\n",
      "epoch: [10], step: [369/377], batch loss: 0.76618, batch accuracy: 67.19, data load time: 0.00204, step time: 0.04571\n",
      "epoch: [11], step: [2/377], batch loss: 0.74348, batch accuracy: 65.62, data load time: 0.00170, step time: 0.04691\n",
      "epoch: [11], step: [12/377], batch loss: 0.92377, batch accuracy: 58.59, data load time: 0.00173, step time: 0.04662\n",
      "epoch: [11], step: [22/377], batch loss: 0.79475, batch accuracy: 67.19, data load time: 0.00172, step time: 0.04655\n",
      "epoch: [11], step: [32/377], batch loss: 0.68899, batch accuracy: 72.66, data load time: 0.00190, step time: 0.04607\n",
      "epoch: [11], step: [42/377], batch loss: 0.81570, batch accuracy: 60.94, data load time: 0.00167, step time: 0.04615\n",
      "epoch: [11], step: [52/377], batch loss: 0.82908, batch accuracy: 64.06, data load time: 0.00190, step time: 0.04642\n",
      "epoch: [11], step: [62/377], batch loss: 0.74380, batch accuracy: 69.53, data load time: 0.00183, step time: 0.04611\n",
      "epoch: [11], step: [72/377], batch loss: 0.72180, batch accuracy: 74.22, data load time: 0.00175, step time: 0.04615\n",
      "epoch: [11], step: [82/377], batch loss: 0.96258, batch accuracy: 57.03, data load time: 0.00182, step time: 0.04618\n",
      "epoch: [11], step: [92/377], batch loss: 0.78399, batch accuracy: 71.09, data load time: 0.00202, step time: 0.04580\n",
      "epoch: [11], step: [102/377], batch loss: 0.82253, batch accuracy: 65.62, data load time: 0.00185, step time: 0.04488\n",
      "epoch: [11], step: [112/377], batch loss: 0.96684, batch accuracy: 57.81, data load time: 0.00174, step time: 0.04557\n",
      "epoch: [11], step: [122/377], batch loss: 0.73744, batch accuracy: 69.53, data load time: 0.00206, step time: 0.04621\n",
      "epoch: [11], step: [132/377], batch loss: 0.85518, batch accuracy: 60.94, data load time: 0.00184, step time: 0.04596\n",
      "epoch: [11], step: [142/377], batch loss: 0.85506, batch accuracy: 64.84, data load time: 0.00225, step time: 0.04649\n",
      "epoch: [11], step: [152/377], batch loss: 0.80733, batch accuracy: 62.50, data load time: 0.00168, step time: 0.04725\n",
      "epoch: [11], step: [162/377], batch loss: 0.67452, batch accuracy: 68.75, data load time: 0.00175, step time: 0.04626\n",
      "epoch: [11], step: [172/377], batch loss: 0.79965, batch accuracy: 64.84, data load time: 0.00179, step time: 0.04754\n",
      "epoch: [11], step: [182/377], batch loss: 0.96856, batch accuracy: 56.25, data load time: 0.00164, step time: 0.04605\n",
      "epoch: [11], step: [192/377], batch loss: 0.90623, batch accuracy: 63.28, data load time: 0.00181, step time: 0.04700\n",
      "epoch: [11], step: [202/377], batch loss: 0.85850, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04696\n",
      "epoch: [11], step: [212/377], batch loss: 0.76461, batch accuracy: 68.75, data load time: 0.00176, step time: 0.04636\n",
      "epoch: [11], step: [222/377], batch loss: 0.86928, batch accuracy: 57.03, data load time: 0.00175, step time: 0.04655\n",
      "epoch: [11], step: [232/377], batch loss: 0.77921, batch accuracy: 67.19, data load time: 0.00177, step time: 0.04548\n",
      "epoch: [11], step: [242/377], batch loss: 0.82430, batch accuracy: 69.53, data load time: 0.00176, step time: 0.04547\n",
      "epoch: [11], step: [252/377], batch loss: 0.91697, batch accuracy: 64.06, data load time: 0.00187, step time: 0.04591\n",
      "epoch: [11], step: [262/377], batch loss: 0.78104, batch accuracy: 64.84, data load time: 0.00170, step time: 0.04572\n",
      "epoch: [11], step: [272/377], batch loss: 0.78444, batch accuracy: 71.88, data load time: 0.00205, step time: 0.04619\n",
      "epoch: [11], step: [282/377], batch loss: 0.76416, batch accuracy: 67.19, data load time: 0.00191, step time: 0.04684\n",
      "epoch: [11], step: [292/377], batch loss: 0.69729, batch accuracy: 67.97, data load time: 0.00187, step time: 0.04503\n",
      "epoch: [11], step: [302/377], batch loss: 0.94857, batch accuracy: 60.94, data load time: 0.00174, step time: 0.04569\n",
      "epoch: [11], step: [312/377], batch loss: 0.84599, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04629\n",
      "epoch: [11], step: [322/377], batch loss: 0.87805, batch accuracy: 64.06, data load time: 0.00171, step time: 0.04725\n",
      "epoch: [11], step: [332/377], batch loss: 0.74456, batch accuracy: 72.66, data load time: 0.00162, step time: 0.04746\n",
      "epoch: [11], step: [342/377], batch loss: 0.75068, batch accuracy: 71.88, data load time: 0.00180, step time: 0.04644\n",
      "epoch: [11], step: [352/377], batch loss: 0.82854, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04656\n",
      "epoch: [11], step: [362/377], batch loss: 0.73859, batch accuracy: 73.44, data load time: 0.00183, step time: 0.04611\n",
      "epoch: [11], step: [372/377], batch loss: 0.69117, batch accuracy: 71.09, data load time: 0.00182, step time: 0.04535\n",
      "epoch: [12], step: [5/377], batch loss: 0.70803, batch accuracy: 70.31, data load time: 0.00169, step time: 0.04670\n",
      "epoch: [12], step: [15/377], batch loss: 0.87684, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04729\n",
      "epoch: [12], step: [25/377], batch loss: 0.77715, batch accuracy: 67.19, data load time: 0.00174, step time: 0.04741\n",
      "epoch: [12], step: [35/377], batch loss: 0.83656, batch accuracy: 57.03, data load time: 0.00166, step time: 0.04671\n",
      "epoch: [12], step: [45/377], batch loss: 0.65124, batch accuracy: 75.78, data load time: 0.00181, step time: 0.04685\n",
      "epoch: [12], step: [55/377], batch loss: 0.90039, batch accuracy: 61.72, data load time: 0.00171, step time: 0.04637\n",
      "epoch: [12], step: [65/377], batch loss: 0.68813, batch accuracy: 70.31, data load time: 0.00188, step time: 0.04564\n",
      "epoch: [12], step: [75/377], batch loss: 0.82054, batch accuracy: 64.06, data load time: 0.00180, step time: 0.04558\n",
      "epoch: [12], step: [85/377], batch loss: 0.63414, batch accuracy: 75.78, data load time: 0.00176, step time: 0.04627\n",
      "epoch: [12], step: [95/377], batch loss: 0.77992, batch accuracy: 67.97, data load time: 0.00173, step time: 0.04625\n",
      "epoch: [12], step: [105/377], batch loss: 0.69336, batch accuracy: 74.22, data load time: 0.00174, step time: 0.04714\n",
      "epoch: [12], step: [115/377], batch loss: 0.84189, batch accuracy: 64.84, data load time: 0.00162, step time: 0.04628\n",
      "epoch: [12], step: [125/377], batch loss: 0.79983, batch accuracy: 68.75, data load time: 0.00171, step time: 0.04629\n",
      "epoch: [12], step: [135/377], batch loss: 0.75168, batch accuracy: 64.84, data load time: 0.00176, step time: 0.04577\n",
      "epoch: [12], step: [145/377], batch loss: 0.84142, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04581\n",
      "epoch: [12], step: [155/377], batch loss: 0.90375, batch accuracy: 62.50, data load time: 0.00166, step time: 0.04599\n",
      "epoch: [12], step: [165/377], batch loss: 0.76142, batch accuracy: 68.75, data load time: 0.00174, step time: 0.04501\n",
      "epoch: [12], step: [175/377], batch loss: 0.74618, batch accuracy: 68.75, data load time: 0.00182, step time: 0.04546\n",
      "epoch: [12], step: [185/377], batch loss: 0.80282, batch accuracy: 67.97, data load time: 0.00172, step time: 0.04668\n",
      "epoch: [12], step: [195/377], batch loss: 0.82632, batch accuracy: 66.41, data load time: 0.00212, step time: 0.04642\n",
      "epoch: [12], step: [205/377], batch loss: 0.94401, batch accuracy: 57.81, data load time: 0.00219, step time: 0.04606\n",
      "epoch: [12], step: [215/377], batch loss: 0.73691, batch accuracy: 71.88, data load time: 0.00165, step time: 0.04686\n",
      "epoch: [12], step: [225/377], batch loss: 0.69272, batch accuracy: 67.97, data load time: 0.00210, step time: 0.04710\n",
      "epoch: [12], step: [235/377], batch loss: 0.77021, batch accuracy: 67.97, data load time: 0.00204, step time: 0.04662\n",
      "epoch: [12], step: [245/377], batch loss: 0.74143, batch accuracy: 68.75, data load time: 0.00186, step time: 0.04626\n",
      "epoch: [12], step: [255/377], batch loss: 0.74759, batch accuracy: 68.75, data load time: 0.00169, step time: 0.04637\n",
      "epoch: [12], step: [265/377], batch loss: 0.83142, batch accuracy: 58.59, data load time: 0.00183, step time: 0.04748\n",
      "epoch: [12], step: [275/377], batch loss: 0.78747, batch accuracy: 67.97, data load time: 0.00176, step time: 0.04644\n",
      "epoch: [12], step: [285/377], batch loss: 0.85852, batch accuracy: 67.19, data load time: 0.00164, step time: 0.04661\n",
      "epoch: [12], step: [295/377], batch loss: 0.71045, batch accuracy: 71.09, data load time: 0.00176, step time: 0.04729\n",
      "epoch: [12], step: [305/377], batch loss: 0.75359, batch accuracy: 67.97, data load time: 0.00217, step time: 0.04594\n",
      "epoch: [12], step: [315/377], batch loss: 0.81684, batch accuracy: 64.06, data load time: 0.00186, step time: 0.04482\n",
      "epoch: [12], step: [325/377], batch loss: 0.76480, batch accuracy: 67.97, data load time: 0.00179, step time: 0.04683\n",
      "epoch: [12], step: [335/377], batch loss: 0.88408, batch accuracy: 67.19, data load time: 0.00185, step time: 0.04624\n",
      "epoch: [12], step: [345/377], batch loss: 0.86930, batch accuracy: 64.84, data load time: 0.00167, step time: 0.04590\n",
      "epoch: [12], step: [355/377], batch loss: 0.78478, batch accuracy: 71.88, data load time: 0.00179, step time: 0.04548\n",
      "epoch: [12], step: [365/377], batch loss: 0.89373, batch accuracy: 61.72, data load time: 0.00174, step time: 0.04590\n",
      "epoch: [12], step: [375/377], batch loss: 0.67414, batch accuracy: 71.88, data load time: 0.00166, step time: 0.04667\n",
      "epoch: [13], step: [8/377], batch loss: 0.82154, batch accuracy: 65.62, data load time: 0.00164, step time: 0.04651\n",
      "epoch: [13], step: [18/377], batch loss: 0.81274, batch accuracy: 64.84, data load time: 0.00172, step time: 0.04652\n",
      "epoch: [13], step: [28/377], batch loss: 0.77854, batch accuracy: 65.62, data load time: 0.00167, step time: 0.04775\n",
      "epoch: [13], step: [38/377], batch loss: 0.91996, batch accuracy: 60.16, data load time: 0.00184, step time: 0.04651\n",
      "epoch: [13], step: [48/377], batch loss: 0.67422, batch accuracy: 69.53, data load time: 0.00178, step time: 0.04676\n",
      "epoch: [13], step: [58/377], batch loss: 0.81227, batch accuracy: 64.84, data load time: 0.00173, step time: 0.04640\n",
      "epoch: [13], step: [68/377], batch loss: 0.80022, batch accuracy: 63.28, data load time: 0.00168, step time: 0.04685\n",
      "epoch: [13], step: [78/377], batch loss: 0.70328, batch accuracy: 71.88, data load time: 0.00160, step time: 0.04649\n",
      "epoch: [13], step: [88/377], batch loss: 0.78225, batch accuracy: 67.97, data load time: 0.00184, step time: 0.04560\n",
      "epoch: [13], step: [98/377], batch loss: 0.80234, batch accuracy: 68.75, data load time: 0.00172, step time: 0.04575\n",
      "epoch: [13], step: [108/377], batch loss: 0.98136, batch accuracy: 53.91, data load time: 0.00182, step time: 0.04695\n",
      "epoch: [13], step: [118/377], batch loss: 0.84146, batch accuracy: 64.06, data load time: 0.00165, step time: 0.04735\n",
      "epoch: [13], step: [128/377], batch loss: 0.72426, batch accuracy: 70.31, data load time: 0.00182, step time: 0.04721\n",
      "epoch: [13], step: [138/377], batch loss: 0.69413, batch accuracy: 72.66, data load time: 0.00189, step time: 0.04648\n",
      "epoch: [13], step: [148/377], batch loss: 0.83702, batch accuracy: 63.28, data load time: 0.00165, step time: 0.04728\n",
      "epoch: [13], step: [158/377], batch loss: 0.79435, batch accuracy: 65.62, data load time: 0.00177, step time: 0.04752\n",
      "epoch: [13], step: [168/377], batch loss: 0.87939, batch accuracy: 60.16, data load time: 0.00181, step time: 0.04662\n",
      "epoch: [13], step: [178/377], batch loss: 0.71250, batch accuracy: 70.31, data load time: 0.00181, step time: 0.04738\n",
      "epoch: [13], step: [188/377], batch loss: 0.74813, batch accuracy: 68.75, data load time: 0.00178, step time: 0.04709\n",
      "epoch: [13], step: [198/377], batch loss: 0.78629, batch accuracy: 70.31, data load time: 0.00170, step time: 0.04766\n",
      "epoch: [13], step: [208/377], batch loss: 0.81776, batch accuracy: 63.28, data load time: 0.00191, step time: 0.04678\n",
      "epoch: [13], step: [218/377], batch loss: 0.85635, batch accuracy: 63.28, data load time: 0.00163, step time: 0.04720\n",
      "epoch: [13], step: [228/377], batch loss: 0.71677, batch accuracy: 73.44, data load time: 0.00174, step time: 0.04674\n",
      "epoch: [13], step: [238/377], batch loss: 0.80201, batch accuracy: 64.06, data load time: 0.00194, step time: 0.04737\n",
      "epoch: [13], step: [248/377], batch loss: 0.89266, batch accuracy: 65.62, data load time: 0.00194, step time: 0.04641\n",
      "epoch: [13], step: [258/377], batch loss: 0.72150, batch accuracy: 70.31, data load time: 0.00168, step time: 0.04714\n",
      "epoch: [13], step: [268/377], batch loss: 0.90994, batch accuracy: 68.75, data load time: 0.00172, step time: 0.04714\n",
      "epoch: [13], step: [278/377], batch loss: 0.75181, batch accuracy: 64.84, data load time: 0.00176, step time: 0.04735\n",
      "epoch: [13], step: [288/377], batch loss: 0.71009, batch accuracy: 71.09, data load time: 0.00182, step time: 0.04653\n",
      "epoch: [13], step: [298/377], batch loss: 0.74572, batch accuracy: 67.97, data load time: 0.00186, step time: 0.04675\n",
      "epoch: [13], step: [308/377], batch loss: 0.80723, batch accuracy: 67.97, data load time: 0.00166, step time: 0.04626\n",
      "epoch: [13], step: [318/377], batch loss: 0.77511, batch accuracy: 64.06, data load time: 0.00185, step time: 0.04239\n",
      "epoch: [13], step: [328/377], batch loss: 0.78328, batch accuracy: 64.84, data load time: 0.00170, step time: 0.04248\n",
      "epoch: [13], step: [338/377], batch loss: 0.79105, batch accuracy: 65.62, data load time: 0.00175, step time: 0.04241\n",
      "epoch: [13], step: [348/377], batch loss: 0.86437, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04254\n",
      "epoch: [13], step: [358/377], batch loss: 0.77618, batch accuracy: 63.28, data load time: 0.00173, step time: 0.04278\n",
      "epoch: [13], step: [368/377], batch loss: 0.85095, batch accuracy: 66.41, data load time: 0.00171, step time: 0.04307\n",
      "epoch: [14], step: [1/377], batch loss: 0.72132, batch accuracy: 70.31, data load time: 0.00169, step time: 0.04348\n",
      "epoch: [14], step: [11/377], batch loss: 0.80319, batch accuracy: 66.41, data load time: 0.00171, step time: 0.04281\n",
      "epoch: [14], step: [21/377], batch loss: 0.84424, batch accuracy: 71.09, data load time: 0.00172, step time: 0.04259\n",
      "epoch: [14], step: [31/377], batch loss: 0.79434, batch accuracy: 66.41, data load time: 0.00159, step time: 0.04288\n",
      "epoch: [14], step: [41/377], batch loss: 0.76900, batch accuracy: 72.66, data load time: 0.00178, step time: 0.04255\n",
      "epoch: [14], step: [51/377], batch loss: 0.85383, batch accuracy: 67.19, data load time: 0.00163, step time: 0.04229\n",
      "epoch: [14], step: [61/377], batch loss: 0.69384, batch accuracy: 72.66, data load time: 0.00169, step time: 0.04254\n",
      "epoch: [14], step: [71/377], batch loss: 0.81039, batch accuracy: 64.06, data load time: 0.00184, step time: 0.04256\n",
      "epoch: [14], step: [81/377], batch loss: 0.78227, batch accuracy: 65.62, data load time: 0.00170, step time: 0.04265\n",
      "epoch: [14], step: [91/377], batch loss: 0.84426, batch accuracy: 61.72, data load time: 0.00167, step time: 0.04244\n",
      "epoch: [14], step: [101/377], batch loss: 0.79476, batch accuracy: 64.06, data load time: 0.00178, step time: 0.04228\n",
      "epoch: [14], step: [111/377], batch loss: 0.81859, batch accuracy: 68.75, data load time: 0.00172, step time: 0.04238\n",
      "epoch: [14], step: [121/377], batch loss: 0.93008, batch accuracy: 60.16, data load time: 0.00161, step time: 0.04268\n",
      "epoch: [14], step: [131/377], batch loss: 0.67218, batch accuracy: 72.66, data load time: 0.00177, step time: 0.04276\n",
      "epoch: [14], step: [141/377], batch loss: 0.87641, batch accuracy: 67.19, data load time: 0.00158, step time: 0.04236\n",
      "epoch: [14], step: [151/377], batch loss: 0.69792, batch accuracy: 64.06, data load time: 0.00217, step time: 0.04244\n",
      "epoch: [14], step: [161/377], batch loss: 0.87595, batch accuracy: 67.97, data load time: 0.00169, step time: 0.04262\n",
      "epoch: [14], step: [171/377], batch loss: 0.76091, batch accuracy: 67.19, data load time: 0.00152, step time: 0.04276\n",
      "epoch: [14], step: [181/377], batch loss: 0.89662, batch accuracy: 60.16, data load time: 0.00161, step time: 0.04251\n",
      "epoch: [14], step: [191/377], batch loss: 0.70650, batch accuracy: 68.75, data load time: 0.00176, step time: 0.04244\n",
      "epoch: [14], step: [201/377], batch loss: 0.82156, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04256\n",
      "epoch: [14], step: [211/377], batch loss: 0.79925, batch accuracy: 64.84, data load time: 0.00233, step time: 0.04255\n",
      "epoch: [14], step: [221/377], batch loss: 0.84868, batch accuracy: 67.19, data load time: 0.00182, step time: 0.04276\n",
      "epoch: [14], step: [231/377], batch loss: 0.78656, batch accuracy: 67.97, data load time: 0.00177, step time: 0.04236\n",
      "epoch: [14], step: [241/377], batch loss: 0.87760, batch accuracy: 62.50, data load time: 0.00173, step time: 0.04237\n",
      "epoch: [14], step: [251/377], batch loss: 0.73639, batch accuracy: 67.19, data load time: 0.00168, step time: 0.04264\n",
      "epoch: [14], step: [261/377], batch loss: 0.82318, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04264\n",
      "epoch: [14], step: [271/377], batch loss: 0.73227, batch accuracy: 73.44, data load time: 0.00160, step time: 0.04249\n",
      "epoch: [14], step: [281/377], batch loss: 0.78484, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04243\n",
      "epoch: [14], step: [291/377], batch loss: 0.81205, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04244\n",
      "epoch: [14], step: [301/377], batch loss: 0.78546, batch accuracy: 64.84, data load time: 0.00164, step time: 0.04262\n",
      "epoch: [14], step: [311/377], batch loss: 0.85921, batch accuracy: 63.28, data load time: 0.00218, step time: 0.04249\n",
      "epoch: [14], step: [321/377], batch loss: 0.70269, batch accuracy: 70.31, data load time: 0.00179, step time: 0.04261\n",
      "epoch: [14], step: [331/377], batch loss: 0.74996, batch accuracy: 69.53, data load time: 0.00180, step time: 0.04262\n",
      "epoch: [14], step: [341/377], batch loss: 0.69735, batch accuracy: 67.97, data load time: 0.00170, step time: 0.04253\n",
      "epoch: [14], step: [351/377], batch loss: 0.67946, batch accuracy: 71.88, data load time: 0.00232, step time: 0.04258\n",
      "epoch: [14], step: [361/377], batch loss: 0.80234, batch accuracy: 67.19, data load time: 0.00230, step time: 0.04284\n",
      "epoch: [14], step: [371/377], batch loss: 0.72095, batch accuracy: 70.31, data load time: 0.00166, step time: 0.04253\n",
      "epoch: [15], step: [4/377], batch loss: 0.72020, batch accuracy: 71.09, data load time: 0.00177, step time: 0.04258\n",
      "epoch: [15], step: [14/377], batch loss: 0.74521, batch accuracy: 68.75, data load time: 0.00175, step time: 0.04242\n",
      "epoch: [15], step: [24/377], batch loss: 0.77819, batch accuracy: 68.75, data load time: 0.00163, step time: 0.04256\n",
      "epoch: [15], step: [34/377], batch loss: 0.93316, batch accuracy: 61.72, data load time: 0.00173, step time: 0.04249\n",
      "epoch: [15], step: [44/377], batch loss: 0.66094, batch accuracy: 71.88, data load time: 0.00182, step time: 0.04253\n",
      "epoch: [15], step: [54/377], batch loss: 0.79298, batch accuracy: 64.06, data load time: 0.00176, step time: 0.04275\n",
      "epoch: [15], step: [64/377], batch loss: 0.88274, batch accuracy: 59.38, data load time: 0.00166, step time: 0.04260\n",
      "epoch: [15], step: [74/377], batch loss: 0.70453, batch accuracy: 69.53, data load time: 0.00178, step time: 0.04262\n",
      "epoch: [15], step: [84/377], batch loss: 0.80822, batch accuracy: 63.28, data load time: 0.00161, step time: 0.04275\n",
      "epoch: [15], step: [94/377], batch loss: 0.94139, batch accuracy: 59.38, data load time: 0.00165, step time: 0.04288\n",
      "epoch: [15], step: [104/377], batch loss: 0.69803, batch accuracy: 71.88, data load time: 0.00177, step time: 0.04265\n",
      "epoch: [15], step: [114/377], batch loss: 0.73663, batch accuracy: 68.75, data load time: 0.00163, step time: 0.04294\n",
      "epoch: [15], step: [124/377], batch loss: 0.79016, batch accuracy: 67.19, data load time: 0.00159, step time: 0.04224\n",
      "epoch: [15], step: [134/377], batch loss: 0.78763, batch accuracy: 67.97, data load time: 0.00172, step time: 0.04255\n",
      "epoch: [15], step: [144/377], batch loss: 0.64972, batch accuracy: 71.88, data load time: 0.00183, step time: 0.04232\n",
      "epoch: [15], step: [154/377], batch loss: 0.60532, batch accuracy: 73.44, data load time: 0.00179, step time: 0.04249\n",
      "epoch: [15], step: [164/377], batch loss: 0.70975, batch accuracy: 70.31, data load time: 0.00175, step time: 0.04249\n",
      "epoch: [15], step: [174/377], batch loss: 0.87566, batch accuracy: 63.28, data load time: 0.00173, step time: 0.04247\n",
      "epoch: [15], step: [184/377], batch loss: 0.77333, batch accuracy: 70.31, data load time: 0.00171, step time: 0.04255\n",
      "epoch: [15], step: [194/377], batch loss: 0.68342, batch accuracy: 76.56, data load time: 0.00170, step time: 0.04267\n",
      "epoch: [15], step: [204/377], batch loss: 0.81353, batch accuracy: 69.53, data load time: 0.00165, step time: 0.04249\n",
      "epoch: [15], step: [214/377], batch loss: 0.85152, batch accuracy: 64.06, data load time: 0.00167, step time: 0.04258\n",
      "epoch: [15], step: [224/377], batch loss: 0.84230, batch accuracy: 61.72, data load time: 0.00168, step time: 0.04281\n",
      "epoch: [15], step: [234/377], batch loss: 0.89585, batch accuracy: 61.72, data load time: 0.00180, step time: 0.04256\n",
      "epoch: [15], step: [244/377], batch loss: 0.82428, batch accuracy: 67.97, data load time: 0.00167, step time: 0.04255\n",
      "epoch: [15], step: [254/377], batch loss: 0.79302, batch accuracy: 67.97, data load time: 0.00173, step time: 0.04237\n",
      "epoch: [15], step: [264/377], batch loss: 0.80950, batch accuracy: 67.19, data load time: 0.00156, step time: 0.04252\n",
      "epoch: [15], step: [274/377], batch loss: 0.76652, batch accuracy: 65.62, data load time: 0.00167, step time: 0.04266\n",
      "epoch: [15], step: [284/377], batch loss: 0.74917, batch accuracy: 69.53, data load time: 0.00166, step time: 0.04265\n",
      "epoch: [15], step: [294/377], batch loss: 0.78552, batch accuracy: 67.19, data load time: 0.00157, step time: 0.04268\n",
      "epoch: [15], step: [304/377], batch loss: 0.77470, batch accuracy: 67.19, data load time: 0.00178, step time: 0.04254\n",
      "epoch: [15], step: [314/377], batch loss: 0.86331, batch accuracy: 67.97, data load time: 0.00173, step time: 0.04252\n",
      "epoch: [15], step: [324/377], batch loss: 0.68756, batch accuracy: 67.97, data load time: 0.00177, step time: 0.04256\n",
      "epoch: [15], step: [334/377], batch loss: 0.66514, batch accuracy: 70.31, data load time: 0.00173, step time: 0.04237\n",
      "epoch: [15], step: [344/377], batch loss: 0.83636, batch accuracy: 65.62, data load time: 0.00165, step time: 0.04265\n",
      "epoch: [15], step: [354/377], batch loss: 0.70291, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04255\n",
      "epoch: [15], step: [364/377], batch loss: 0.72794, batch accuracy: 74.22, data load time: 0.00167, step time: 0.04262\n",
      "epoch: [15], step: [374/377], batch loss: 0.84014, batch accuracy: 63.28, data load time: 0.00170, step time: 0.04264\n",
      "epoch: [16], step: [7/377], batch loss: 0.98568, batch accuracy: 64.84, data load time: 0.00170, step time: 0.04266\n",
      "epoch: [16], step: [17/377], batch loss: 0.85701, batch accuracy: 62.50, data load time: 0.00168, step time: 0.04275\n",
      "epoch: [16], step: [27/377], batch loss: 0.84129, batch accuracy: 68.75, data load time: 0.00195, step time: 0.04258\n",
      "epoch: [16], step: [37/377], batch loss: 0.86467, batch accuracy: 64.06, data load time: 0.00183, step time: 0.04267\n",
      "epoch: [16], step: [47/377], batch loss: 0.78407, batch accuracy: 71.09, data load time: 0.00174, step time: 0.04250\n",
      "epoch: [16], step: [57/377], batch loss: 0.72814, batch accuracy: 69.53, data load time: 0.00178, step time: 0.04224\n",
      "epoch: [16], step: [67/377], batch loss: 0.72446, batch accuracy: 75.00, data load time: 0.00163, step time: 0.04246\n",
      "epoch: [16], step: [77/377], batch loss: 0.96573, batch accuracy: 57.03, data load time: 0.00164, step time: 0.04251\n",
      "epoch: [16], step: [87/377], batch loss: 0.79398, batch accuracy: 65.62, data load time: 0.00157, step time: 0.04280\n",
      "epoch: [16], step: [97/377], batch loss: 0.65872, batch accuracy: 71.09, data load time: 0.00162, step time: 0.04253\n",
      "epoch: [16], step: [107/377], batch loss: 0.92786, batch accuracy: 60.16, data load time: 0.00166, step time: 0.04238\n",
      "epoch: [16], step: [117/377], batch loss: 0.84247, batch accuracy: 64.06, data load time: 0.00168, step time: 0.04238\n",
      "epoch: [16], step: [127/377], batch loss: 0.87848, batch accuracy: 63.28, data load time: 0.00178, step time: 0.04240\n",
      "epoch: [16], step: [137/377], batch loss: 0.75243, batch accuracy: 72.66, data load time: 0.00166, step time: 0.04252\n",
      "epoch: [16], step: [147/377], batch loss: 0.73638, batch accuracy: 69.53, data load time: 0.00170, step time: 0.04247\n",
      "epoch: [16], step: [157/377], batch loss: 0.80834, batch accuracy: 70.31, data load time: 0.00161, step time: 0.04257\n",
      "epoch: [16], step: [167/377], batch loss: 0.71773, batch accuracy: 70.31, data load time: 0.00176, step time: 0.04263\n",
      "epoch: [16], step: [177/377], batch loss: 0.95106, batch accuracy: 59.38, data load time: 0.00166, step time: 0.04232\n",
      "epoch: [16], step: [187/377], batch loss: 0.79259, batch accuracy: 68.75, data load time: 0.00179, step time: 0.04257\n",
      "epoch: [16], step: [197/377], batch loss: 0.74345, batch accuracy: 67.19, data load time: 0.00166, step time: 0.04263\n",
      "epoch: [16], step: [207/377], batch loss: 0.90829, batch accuracy: 57.81, data load time: 0.00162, step time: 0.04248\n",
      "epoch: [16], step: [217/377], batch loss: 0.71549, batch accuracy: 70.31, data load time: 0.00236, step time: 0.04237\n",
      "epoch: [16], step: [227/377], batch loss: 0.75792, batch accuracy: 70.31, data load time: 0.00223, step time: 0.04269\n",
      "epoch: [16], step: [237/377], batch loss: 0.75408, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04289\n",
      "epoch: [16], step: [247/377], batch loss: 0.86548, batch accuracy: 66.41, data load time: 0.00178, step time: 0.04260\n",
      "epoch: [16], step: [257/377], batch loss: 0.70620, batch accuracy: 73.44, data load time: 0.00164, step time: 0.04230\n",
      "epoch: [16], step: [267/377], batch loss: 0.73628, batch accuracy: 69.53, data load time: 0.00232, step time: 0.04251\n",
      "epoch: [16], step: [277/377], batch loss: 0.67799, batch accuracy: 70.31, data load time: 0.00206, step time: 0.04260\n",
      "epoch: [16], step: [287/377], batch loss: 0.96965, batch accuracy: 60.16, data load time: 0.00164, step time: 0.04250\n",
      "epoch: [16], step: [297/377], batch loss: 0.75455, batch accuracy: 68.75, data load time: 0.00169, step time: 0.04231\n",
      "epoch: [16], step: [307/377], batch loss: 0.76570, batch accuracy: 67.97, data load time: 0.00238, step time: 0.04257\n",
      "epoch: [16], step: [317/377], batch loss: 0.77411, batch accuracy: 71.09, data load time: 0.00212, step time: 0.04238\n",
      "epoch: [16], step: [327/377], batch loss: 0.73749, batch accuracy: 67.97, data load time: 0.00176, step time: 0.04284\n",
      "epoch: [16], step: [337/377], batch loss: 0.83738, batch accuracy: 61.72, data load time: 0.00237, step time: 0.04236\n",
      "epoch: [16], step: [347/377], batch loss: 0.97879, batch accuracy: 57.03, data load time: 0.00172, step time: 0.04250\n",
      "epoch: [16], step: [357/377], batch loss: 0.75512, batch accuracy: 70.31, data load time: 0.00162, step time: 0.04266\n",
      "epoch: [16], step: [367/377], batch loss: 0.84560, batch accuracy: 66.41, data load time: 0.00214, step time: 0.04260\n",
      "epoch: [17], step: [0/377], batch loss: 0.87107, batch accuracy: 65.62, data load time: 0.00547, step time: 0.04253\n",
      "epoch: [17], step: [10/377], batch loss: 0.77218, batch accuracy: 69.53, data load time: 0.00168, step time: 0.04277\n",
      "epoch: [17], step: [20/377], batch loss: 0.73830, batch accuracy: 67.19, data load time: 0.00160, step time: 0.04401\n",
      "epoch: [17], step: [30/377], batch loss: 0.81502, batch accuracy: 65.62, data load time: 0.00165, step time: 0.04243\n",
      "epoch: [17], step: [40/377], batch loss: 0.85773, batch accuracy: 66.41, data load time: 0.00174, step time: 0.04258\n",
      "epoch: [17], step: [50/377], batch loss: 0.75383, batch accuracy: 66.41, data load time: 0.00161, step time: 0.04262\n",
      "epoch: [17], step: [60/377], batch loss: 0.70954, batch accuracy: 72.66, data load time: 0.00175, step time: 0.04274\n",
      "epoch: [17], step: [70/377], batch loss: 0.77255, batch accuracy: 68.75, data load time: 0.00177, step time: 0.04216\n",
      "epoch: [17], step: [80/377], batch loss: 0.88282, batch accuracy: 60.94, data load time: 0.00168, step time: 0.04265\n",
      "epoch: [17], step: [90/377], batch loss: 0.71172, batch accuracy: 67.97, data load time: 0.00162, step time: 0.04256\n",
      "epoch: [17], step: [100/377], batch loss: 0.85851, batch accuracy: 61.72, data load time: 0.00179, step time: 0.04267\n",
      "epoch: [17], step: [110/377], batch loss: 0.77157, batch accuracy: 70.31, data load time: 0.00166, step time: 0.04372\n",
      "epoch: [17], step: [120/377], batch loss: 0.86449, batch accuracy: 63.28, data load time: 0.00169, step time: 0.04239\n",
      "epoch: [17], step: [130/377], batch loss: 0.79480, batch accuracy: 62.50, data load time: 0.00176, step time: 0.04237\n",
      "epoch: [17], step: [140/377], batch loss: 0.83063, batch accuracy: 65.62, data load time: 0.00177, step time: 0.04304\n",
      "epoch: [17], step: [150/377], batch loss: 0.69404, batch accuracy: 71.88, data load time: 0.00172, step time: 0.04279\n",
      "epoch: [17], step: [160/377], batch loss: 0.83961, batch accuracy: 65.62, data load time: 0.00182, step time: 0.04238\n",
      "epoch: [17], step: [170/377], batch loss: 0.76867, batch accuracy: 67.19, data load time: 0.00167, step time: 0.04237\n",
      "epoch: [17], step: [180/377], batch loss: 0.78976, batch accuracy: 63.28, data load time: 0.00177, step time: 0.04254\n",
      "epoch: [17], step: [190/377], batch loss: 0.84913, batch accuracy: 60.94, data load time: 0.00171, step time: 0.04264\n",
      "epoch: [17], step: [200/377], batch loss: 0.94926, batch accuracy: 60.94, data load time: 0.00158, step time: 0.04353\n",
      "epoch: [17], step: [210/377], batch loss: 0.81183, batch accuracy: 63.28, data load time: 0.00174, step time: 0.04251\n",
      "epoch: [17], step: [220/377], batch loss: 0.83621, batch accuracy: 60.94, data load time: 0.00183, step time: 0.04263\n",
      "epoch: [17], step: [230/377], batch loss: 0.79991, batch accuracy: 68.75, data load time: 0.00162, step time: 0.04274\n",
      "epoch: [17], step: [240/377], batch loss: 0.83654, batch accuracy: 65.62, data load time: 0.00159, step time: 0.04259\n",
      "epoch: [17], step: [250/377], batch loss: 0.81431, batch accuracy: 65.62, data load time: 0.00153, step time: 0.04242\n",
      "epoch: [17], step: [260/377], batch loss: 0.74076, batch accuracy: 66.41, data load time: 0.00171, step time: 0.04252\n",
      "epoch: [17], step: [270/377], batch loss: 0.80525, batch accuracy: 63.28, data load time: 0.00166, step time: 0.04266\n",
      "epoch: [17], step: [280/377], batch loss: 0.72323, batch accuracy: 68.75, data load time: 0.00160, step time: 0.04300\n",
      "epoch: [17], step: [290/377], batch loss: 0.79763, batch accuracy: 67.97, data load time: 0.00181, step time: 0.04508\n",
      "epoch: [17], step: [300/377], batch loss: 0.88642, batch accuracy: 64.84, data load time: 0.00176, step time: 0.04277\n",
      "epoch: [17], step: [310/377], batch loss: 0.85334, batch accuracy: 67.19, data load time: 0.00166, step time: 0.04265\n",
      "epoch: [17], step: [320/377], batch loss: 0.94945, batch accuracy: 60.16, data load time: 0.00168, step time: 0.04318\n",
      "epoch: [17], step: [330/377], batch loss: 0.82347, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04271\n",
      "epoch: [17], step: [340/377], batch loss: 0.81253, batch accuracy: 64.06, data load time: 0.00164, step time: 0.04248\n",
      "epoch: [17], step: [350/377], batch loss: 0.66441, batch accuracy: 73.44, data load time: 0.00170, step time: 0.04249\n",
      "epoch: [17], step: [360/377], batch loss: 0.72767, batch accuracy: 70.31, data load time: 0.00166, step time: 0.04268\n",
      "epoch: [17], step: [370/377], batch loss: 0.67869, batch accuracy: 74.22, data load time: 0.00175, step time: 0.04279\n",
      "epoch: [18], step: [3/377], batch loss: 0.89674, batch accuracy: 61.72, data load time: 0.00173, step time: 0.04373\n",
      "epoch: [18], step: [13/377], batch loss: 0.81773, batch accuracy: 65.62, data load time: 0.00167, step time: 0.04281\n",
      "epoch: [18], step: [23/377], batch loss: 0.68607, batch accuracy: 72.66, data load time: 0.00188, step time: 0.04266\n",
      "epoch: [18], step: [33/377], batch loss: 0.78288, batch accuracy: 67.19, data load time: 0.00175, step time: 0.04248\n",
      "epoch: [18], step: [43/377], batch loss: 0.68926, batch accuracy: 73.44, data load time: 0.00173, step time: 0.04248\n",
      "epoch: [18], step: [53/377], batch loss: 0.74988, batch accuracy: 71.88, data load time: 0.00161, step time: 0.04238\n",
      "epoch: [18], step: [63/377], batch loss: 0.77232, batch accuracy: 63.28, data load time: 0.00207, step time: 0.04266\n",
      "epoch: [18], step: [73/377], batch loss: 0.78042, batch accuracy: 64.06, data load time: 0.00168, step time: 0.04268\n",
      "epoch: [18], step: [83/377], batch loss: 0.78999, batch accuracy: 69.53, data load time: 0.00175, step time: 0.04268\n",
      "epoch: [18], step: [93/377], batch loss: 0.76977, batch accuracy: 66.41, data load time: 0.00165, step time: 0.04367\n",
      "epoch: [18], step: [103/377], batch loss: 0.75551, batch accuracy: 67.97, data load time: 0.00168, step time: 0.04242\n",
      "epoch: [18], step: [113/377], batch loss: 0.80033, batch accuracy: 67.97, data load time: 0.00174, step time: 0.04249\n",
      "epoch: [18], step: [123/377], batch loss: 0.86712, batch accuracy: 60.16, data load time: 0.00185, step time: 0.04269\n",
      "epoch: [18], step: [133/377], batch loss: 0.82537, batch accuracy: 63.28, data load time: 0.00173, step time: 0.04253\n",
      "epoch: [18], step: [143/377], batch loss: 0.85816, batch accuracy: 70.31, data load time: 0.00172, step time: 0.04235\n",
      "epoch: [18], step: [153/377], batch loss: 0.71072, batch accuracy: 72.66, data load time: 0.00174, step time: 0.04251\n",
      "epoch: [18], step: [163/377], batch loss: 0.85597, batch accuracy: 65.62, data load time: 0.00172, step time: 0.04281\n",
      "epoch: [18], step: [173/377], batch loss: 0.90466, batch accuracy: 60.94, data load time: 0.00167, step time: 0.04248\n",
      "epoch: [18], step: [183/377], batch loss: 0.87466, batch accuracy: 62.50, data load time: 0.00236, step time: 0.04360\n",
      "epoch: [18], step: [193/377], batch loss: 0.69019, batch accuracy: 71.88, data load time: 0.00218, step time: 0.04238\n",
      "epoch: [18], step: [203/377], batch loss: 0.76255, batch accuracy: 65.62, data load time: 0.00178, step time: 0.04263\n",
      "epoch: [18], step: [213/377], batch loss: 0.85370, batch accuracy: 63.28, data load time: 0.00236, step time: 0.04240\n",
      "epoch: [18], step: [223/377], batch loss: 0.73714, batch accuracy: 67.19, data load time: 0.00162, step time: 0.04239\n",
      "epoch: [18], step: [233/377], batch loss: 0.74504, batch accuracy: 68.75, data load time: 0.00227, step time: 0.04268\n",
      "epoch: [18], step: [243/377], batch loss: 0.76420, batch accuracy: 66.41, data load time: 0.00186, step time: 0.04271\n",
      "epoch: [18], step: [253/377], batch loss: 0.69891, batch accuracy: 74.22, data load time: 0.00178, step time: 0.04232\n",
      "epoch: [18], step: [263/377], batch loss: 0.90656, batch accuracy: 59.38, data load time: 0.00187, step time: 0.04246\n",
      "epoch: [18], step: [273/377], batch loss: 0.77798, batch accuracy: 70.31, data load time: 0.00176, step time: 0.04349\n",
      "epoch: [18], step: [283/377], batch loss: 0.78844, batch accuracy: 65.62, data load time: 0.00158, step time: 0.04250\n",
      "epoch: [18], step: [293/377], batch loss: 0.75375, batch accuracy: 69.53, data load time: 0.00233, step time: 0.04241\n",
      "epoch: [18], step: [303/377], batch loss: 0.76337, batch accuracy: 68.75, data load time: 0.00171, step time: 0.04264\n",
      "epoch: [18], step: [313/377], batch loss: 0.77853, batch accuracy: 67.19, data load time: 0.00188, step time: 0.04252\n",
      "epoch: [18], step: [323/377], batch loss: 0.88195, batch accuracy: 63.28, data load time: 0.00172, step time: 0.04231\n",
      "epoch: [18], step: [333/377], batch loss: 0.79845, batch accuracy: 63.28, data load time: 0.00178, step time: 0.04228\n",
      "epoch: [18], step: [343/377], batch loss: 0.74202, batch accuracy: 72.66, data load time: 0.00172, step time: 0.04296\n",
      "epoch: [18], step: [353/377], batch loss: 0.73437, batch accuracy: 67.97, data load time: 0.00170, step time: 0.04258\n",
      "epoch: [18], step: [363/377], batch loss: 0.80223, batch accuracy: 65.62, data load time: 0.00167, step time: 0.04357\n",
      "epoch: [18], step: [373/377], batch loss: 0.80645, batch accuracy: 68.75, data load time: 0.00164, step time: 0.04233\n",
      "epoch: [19], step: [6/377], batch loss: 0.84758, batch accuracy: 65.62, data load time: 0.00170, step time: 0.04249\n",
      "epoch: [19], step: [16/377], batch loss: 0.82248, batch accuracy: 66.41, data load time: 0.00169, step time: 0.04261\n",
      "epoch: [19], step: [26/377], batch loss: 0.75834, batch accuracy: 64.84, data load time: 0.00176, step time: 0.04259\n",
      "epoch: [19], step: [36/377], batch loss: 0.84761, batch accuracy: 62.50, data load time: 0.00166, step time: 0.04226\n",
      "epoch: [19], step: [46/377], batch loss: 0.99694, batch accuracy: 60.16, data load time: 0.00173, step time: 0.04261\n",
      "epoch: [19], step: [56/377], batch loss: 0.79983, batch accuracy: 66.41, data load time: 0.00171, step time: 0.04266\n",
      "epoch: [19], step: [66/377], batch loss: 0.98254, batch accuracy: 58.59, data load time: 0.00172, step time: 0.04244\n",
      "epoch: [19], step: [76/377], batch loss: 0.79438, batch accuracy: 64.84, data load time: 0.00176, step time: 0.04369\n",
      "epoch: [19], step: [86/377], batch loss: 0.87081, batch accuracy: 63.28, data load time: 0.00173, step time: 0.04247\n",
      "epoch: [19], step: [96/377], batch loss: 0.80874, batch accuracy: 66.41, data load time: 0.00170, step time: 0.04278\n",
      "epoch: [19], step: [106/377], batch loss: 0.85584, batch accuracy: 65.62, data load time: 0.00179, step time: 0.04250\n",
      "epoch: [19], step: [116/377], batch loss: 0.75827, batch accuracy: 69.53, data load time: 0.00180, step time: 0.04256\n",
      "epoch: [19], step: [126/377], batch loss: 0.85201, batch accuracy: 64.84, data load time: 0.00181, step time: 0.04263\n",
      "epoch: [19], step: [136/377], batch loss: 0.83762, batch accuracy: 62.50, data load time: 0.00170, step time: 0.04348\n",
      "epoch: [19], step: [146/377], batch loss: 0.75513, batch accuracy: 66.41, data load time: 0.00173, step time: 0.04263\n",
      "epoch: [19], step: [156/377], batch loss: 0.82757, batch accuracy: 64.06, data load time: 0.00165, step time: 0.04237\n",
      "epoch: [19], step: [166/377], batch loss: 0.70789, batch accuracy: 72.66, data load time: 0.00176, step time: 0.04534\n",
      "epoch: [19], step: [176/377], batch loss: 0.77132, batch accuracy: 67.19, data load time: 0.00174, step time: 0.04245\n",
      "epoch: [19], step: [186/377], batch loss: 0.76800, batch accuracy: 70.31, data load time: 0.00159, step time: 0.04254\n",
      "epoch: [19], step: [196/377], batch loss: 0.76343, batch accuracy: 63.28, data load time: 0.00174, step time: 0.04282\n",
      "epoch: [19], step: [206/377], batch loss: 0.80106, batch accuracy: 66.41, data load time: 0.00179, step time: 0.04252\n",
      "epoch: [19], step: [216/377], batch loss: 0.72919, batch accuracy: 68.75, data load time: 0.00170, step time: 0.04246\n",
      "epoch: [19], step: [226/377], batch loss: 0.76987, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04251\n",
      "epoch: [19], step: [236/377], batch loss: 0.86547, batch accuracy: 67.19, data load time: 0.00167, step time: 0.04278\n",
      "epoch: [19], step: [246/377], batch loss: 0.86427, batch accuracy: 65.62, data load time: 0.00169, step time: 0.04286\n",
      "epoch: [19], step: [256/377], batch loss: 0.85878, batch accuracy: 64.84, data load time: 0.00172, step time: 0.04416\n",
      "epoch: [19], step: [266/377], batch loss: 0.79961, batch accuracy: 67.19, data load time: 0.00170, step time: 0.04249\n",
      "epoch: [19], step: [276/377], batch loss: 0.86484, batch accuracy: 61.72, data load time: 0.00177, step time: 0.04259\n",
      "epoch: [19], step: [286/377], batch loss: 0.73833, batch accuracy: 69.53, data load time: 0.00173, step time: 0.04249\n",
      "epoch: [19], step: [296/377], batch loss: 0.76852, batch accuracy: 70.31, data load time: 0.00156, step time: 0.04233\n",
      "epoch: [19], step: [306/377], batch loss: 0.78831, batch accuracy: 67.19, data load time: 0.00159, step time: 0.04243\n",
      "epoch: [19], step: [316/377], batch loss: 0.89095, batch accuracy: 60.16, data load time: 0.00182, step time: 0.04274\n",
      "epoch: [19], step: [326/377], batch loss: 0.69442, batch accuracy: 71.88, data load time: 0.00189, step time: 0.04269\n",
      "epoch: [19], step: [336/377], batch loss: 0.87204, batch accuracy: 61.72, data load time: 0.00175, step time: 0.04235\n",
      "epoch: [19], step: [346/377], batch loss: 0.79704, batch accuracy: 66.41, data load time: 0.00180, step time: 0.04370\n",
      "epoch: [19], step: [356/377], batch loss: 0.70557, batch accuracy: 70.31, data load time: 0.00160, step time: 0.04261\n",
      "epoch: [19], step: [366/377], batch loss: 0.60260, batch accuracy: 78.12, data load time: 0.00175, step time: 0.04241\n",
      "epoch: [19], step: [376/377], batch loss: 0.69745, batch accuracy: 76.92, data load time: 0.00210, step time: 0.01812\n",
      "Finished training.\n",
      "\n",
      "TESTING MODEL\n",
      "AUC: 0.6055226637463783 on test dataset\n",
      "\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_23\n",
      "About to train...\n",
      "epoch: [0], step: [9/377], batch loss: 0.73495, batch accuracy: 63.28, data load time: 0.00184, step time: 0.04448\n",
      "epoch: [0], step: [19/377], batch loss: 0.68894, batch accuracy: 68.75, data load time: 0.00171, step time: 0.04383\n",
      "epoch: [0], step: [29/377], batch loss: 0.74772, batch accuracy: 60.94, data load time: 0.00173, step time: 0.04310\n",
      "epoch: [0], step: [39/377], batch loss: 0.67667, batch accuracy: 64.06, data load time: 0.00161, step time: 0.04274\n",
      "epoch: [0], step: [49/377], batch loss: 0.70830, batch accuracy: 70.31, data load time: 0.00167, step time: 0.04345\n",
      "epoch: [0], step: [59/377], batch loss: 0.74838, batch accuracy: 64.84, data load time: 0.00224, step time: 0.04225\n",
      "epoch: [0], step: [69/377], batch loss: 0.68907, batch accuracy: 64.06, data load time: 0.00184, step time: 0.04231\n",
      "epoch: [0], step: [79/377], batch loss: 0.76233, batch accuracy: 60.94, data load time: 0.00181, step time: 0.04237\n",
      "epoch: [0], step: [89/377], batch loss: 0.78341, batch accuracy: 66.41, data load time: 0.00167, step time: 0.04218\n",
      "epoch: [0], step: [99/377], batch loss: 0.71942, batch accuracy: 67.97, data load time: 0.00180, step time: 0.04222\n",
      "epoch: [0], step: [109/377], batch loss: 0.74254, batch accuracy: 64.84, data load time: 0.00220, step time: 0.04206\n",
      "epoch: [0], step: [119/377], batch loss: 0.79260, batch accuracy: 55.47, data load time: 0.00178, step time: 0.04197\n",
      "epoch: [0], step: [129/377], batch loss: 0.70641, batch accuracy: 70.31, data load time: 0.00154, step time: 0.04199\n",
      "epoch: [0], step: [139/377], batch loss: 0.74259, batch accuracy: 63.28, data load time: 0.00179, step time: 0.04213\n",
      "epoch: [0], step: [149/377], batch loss: 0.77201, batch accuracy: 60.16, data load time: 0.00213, step time: 0.04242\n",
      "epoch: [0], step: [159/377], batch loss: 0.69850, batch accuracy: 61.72, data load time: 0.00175, step time: 0.04225\n",
      "epoch: [0], step: [169/377], batch loss: 0.69993, batch accuracy: 64.84, data load time: 0.00178, step time: 0.04237\n",
      "epoch: [0], step: [179/377], batch loss: 0.64479, batch accuracy: 70.31, data load time: 0.00178, step time: 0.04218\n",
      "epoch: [0], step: [189/377], batch loss: 0.67950, batch accuracy: 78.12, data load time: 0.00172, step time: 0.04210\n",
      "epoch: [0], step: [199/377], batch loss: 0.67017, batch accuracy: 71.09, data load time: 0.00232, step time: 0.04219\n",
      "epoch: [0], step: [209/377], batch loss: 0.64630, batch accuracy: 70.31, data load time: 0.00235, step time: 0.04219\n",
      "epoch: [0], step: [219/377], batch loss: 0.71055, batch accuracy: 67.97, data load time: 0.00158, step time: 0.04246\n",
      "epoch: [0], step: [229/377], batch loss: 0.77941, batch accuracy: 64.06, data load time: 0.00174, step time: 0.04240\n",
      "epoch: [0], step: [239/377], batch loss: 0.73070, batch accuracy: 67.19, data load time: 0.00153, step time: 0.04268\n",
      "epoch: [0], step: [249/377], batch loss: 0.69891, batch accuracy: 63.28, data load time: 0.00172, step time: 0.04202\n",
      "\n",
      "Exitting this train since accuracy too low: 0.4921875\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_24\n",
      "About to train...\n",
      "epoch: [0], step: [9/377], batch loss: 0.64671, batch accuracy: 75.78, data load time: 0.00187, step time: 0.04446\n",
      "epoch: [0], step: [19/377], batch loss: 0.70539, batch accuracy: 63.28, data load time: 0.00168, step time: 0.04394\n",
      "epoch: [0], step: [29/377], batch loss: 0.78708, batch accuracy: 55.47, data load time: 0.00160, step time: 0.04278\n",
      "epoch: [0], step: [39/377], batch loss: 0.67380, batch accuracy: 66.41, data load time: 0.00180, step time: 0.04226\n",
      "epoch: [0], step: [49/377], batch loss: 0.77355, batch accuracy: 60.94, data load time: 0.00188, step time: 0.04218\n",
      "epoch: [0], step: [59/377], batch loss: 0.65595, batch accuracy: 66.41, data load time: 0.00180, step time: 0.04229\n",
      "epoch: [0], step: [69/377], batch loss: 0.74025, batch accuracy: 66.41, data load time: 0.00180, step time: 0.04218\n",
      "epoch: [0], step: [79/377], batch loss: 0.69978, batch accuracy: 64.06, data load time: 0.00179, step time: 0.04226\n",
      "epoch: [0], step: [89/377], batch loss: 0.67360, batch accuracy: 67.97, data load time: 0.00181, step time: 0.04234\n",
      "epoch: [0], step: [99/377], batch loss: 0.80868, batch accuracy: 59.38, data load time: 0.00178, step time: 0.04220\n",
      "epoch: [0], step: [109/377], batch loss: 0.76023, batch accuracy: 63.28, data load time: 0.00169, step time: 0.04204\n",
      "epoch: [0], step: [119/377], batch loss: 0.66136, batch accuracy: 71.88, data load time: 0.00167, step time: 0.04236\n",
      "epoch: [0], step: [129/377], batch loss: 0.72918, batch accuracy: 62.50, data load time: 0.00197, step time: 0.04219\n",
      "epoch: [0], step: [139/377], batch loss: 0.68687, batch accuracy: 65.62, data load time: 0.00161, step time: 0.04226\n",
      "epoch: [0], step: [149/377], batch loss: 0.69033, batch accuracy: 68.75, data load time: 0.00189, step time: 0.04243\n",
      "epoch: [0], step: [159/377], batch loss: 0.68657, batch accuracy: 67.19, data load time: 0.00184, step time: 0.04237\n",
      "epoch: [0], step: [169/377], batch loss: 0.81088, batch accuracy: 58.59, data load time: 0.00189, step time: 0.04269\n",
      "epoch: [0], step: [179/377], batch loss: 0.74223, batch accuracy: 62.50, data load time: 0.00178, step time: 0.04295\n",
      "epoch: [0], step: [189/377], batch loss: 0.72027, batch accuracy: 67.97, data load time: 0.00182, step time: 0.04236\n",
      "epoch: [0], step: [199/377], batch loss: 0.69184, batch accuracy: 67.97, data load time: 0.00176, step time: 0.04206\n",
      "epoch: [0], step: [209/377], batch loss: 0.71538, batch accuracy: 63.28, data load time: 0.00162, step time: 0.04227\n",
      "epoch: [0], step: [219/377], batch loss: 0.76154, batch accuracy: 64.06, data load time: 0.00190, step time: 0.04218\n",
      "epoch: [0], step: [229/377], batch loss: 0.81095, batch accuracy: 57.03, data load time: 0.00166, step time: 0.04230\n",
      "epoch: [0], step: [239/377], batch loss: 0.76091, batch accuracy: 56.25, data load time: 0.00175, step time: 0.04254\n",
      "epoch: [0], step: [249/377], batch loss: 0.68260, batch accuracy: 66.41, data load time: 0.00172, step time: 0.04256\n",
      "epoch: [0], step: [259/377], batch loss: 0.80727, batch accuracy: 55.47, data load time: 0.00233, step time: 0.04234\n",
      "epoch: [0], step: [269/377], batch loss: 0.69477, batch accuracy: 63.28, data load time: 0.00177, step time: 0.04261\n",
      "epoch: [0], step: [279/377], batch loss: 0.72798, batch accuracy: 62.50, data load time: 0.00168, step time: 0.04223\n",
      "epoch: [0], step: [289/377], batch loss: 0.72165, batch accuracy: 71.09, data load time: 0.00169, step time: 0.04221\n",
      "epoch: [0], step: [299/377], batch loss: 0.76661, batch accuracy: 60.16, data load time: 0.00158, step time: 0.04222\n",
      "epoch: [0], step: [309/377], batch loss: 0.77410, batch accuracy: 58.59, data load time: 0.00218, step time: 0.04341\n",
      "epoch: [0], step: [319/377], batch loss: 0.71086, batch accuracy: 67.19, data load time: 0.00164, step time: 0.04228\n",
      "epoch: [0], step: [329/377], batch loss: 0.68551, batch accuracy: 62.50, data load time: 0.00169, step time: 0.04221\n",
      "epoch: [0], step: [339/377], batch loss: 0.63225, batch accuracy: 71.88, data load time: 0.00174, step time: 0.04252\n",
      "epoch: [0], step: [349/377], batch loss: 0.79831, batch accuracy: 60.94, data load time: 0.00167, step time: 0.04242\n",
      "epoch: [0], step: [359/377], batch loss: 0.78121, batch accuracy: 60.16, data load time: 0.00160, step time: 0.04228\n",
      "\n",
      "Exitting this train since accuracy too low: 0.46875\n",
      "Finished training.\n",
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_25\n",
      "About to train...\n",
      "epoch: [0], step: [9/377], batch loss: 1.43364, batch accuracy: 67.97, data load time: 0.00172, step time: 0.04445\n",
      "epoch: [0], step: [19/377], batch loss: 1.82694, batch accuracy: 67.97, data load time: 0.00189, step time: 0.04416\n",
      "epoch: [0], step: [29/377], batch loss: 1.67985, batch accuracy: 67.97, data load time: 0.00168, step time: 0.04296\n",
      "epoch: [0], step: [39/377], batch loss: 1.58147, batch accuracy: 70.31, data load time: 0.00177, step time: 0.04257\n",
      "epoch: [0], step: [49/377], batch loss: 1.95645, batch accuracy: 60.16, data load time: 0.00179, step time: 0.04240\n",
      "epoch: [0], step: [59/377], batch loss: 2.04778, batch accuracy: 59.38, data load time: 0.00174, step time: 0.04266\n",
      "epoch: [0], step: [69/377], batch loss: 1.94130, batch accuracy: 59.38, data load time: 0.00155, step time: 0.04235\n",
      "epoch: [0], step: [79/377], batch loss: 1.80088, batch accuracy: 67.19, data load time: 0.00166, step time: 0.04318\n",
      "epoch: [0], step: [89/377], batch loss: 1.27322, batch accuracy: 73.44, data load time: 0.00163, step time: 0.04223\n",
      "epoch: [0], step: [99/377], batch loss: 1.59872, batch accuracy: 69.53, data load time: 0.00149, step time: 0.04213\n",
      "epoch: [0], step: [109/377], batch loss: 1.74114, batch accuracy: 66.41, data load time: 0.00164, step time: 0.04225\n",
      "epoch: [0], step: [119/377], batch loss: 1.69804, batch accuracy: 67.97, data load time: 0.00181, step time: 0.04222\n",
      "epoch: [0], step: [129/377], batch loss: 1.60349, batch accuracy: 66.41, data load time: 0.00169, step time: 0.04230\n",
      "epoch: [0], step: [139/377], batch loss: 1.73817, batch accuracy: 64.84, data load time: 0.00179, step time: 0.04245\n",
      "epoch: [0], step: [149/377], batch loss: 1.40074, batch accuracy: 73.44, data load time: 0.00171, step time: 0.04250\n",
      "epoch: [0], step: [159/377], batch loss: 1.70470, batch accuracy: 64.06, data load time: 0.00159, step time: 0.04251\n",
      "epoch: [0], step: [169/377], batch loss: 2.32950, batch accuracy: 54.69, data load time: 0.00170, step time: 0.04252\n",
      "epoch: [0], step: [179/377], batch loss: 1.71263, batch accuracy: 65.62, data load time: 0.00165, step time: 0.04251\n",
      "epoch: [0], step: [189/377], batch loss: 1.31510, batch accuracy: 70.31, data load time: 0.00175, step time: 0.04249\n",
      "epoch: [0], step: [199/377], batch loss: 1.87805, batch accuracy: 63.28, data load time: 0.00180, step time: 0.04208\n",
      "epoch: [0], step: [209/377], batch loss: 1.35982, batch accuracy: 71.88, data load time: 0.00171, step time: 0.04225\n",
      "epoch: [0], step: [219/377], batch loss: 1.42196, batch accuracy: 73.44, data load time: 0.00161, step time: 0.04228\n",
      "epoch: [0], step: [229/377], batch loss: 1.64238, batch accuracy: 68.75, data load time: 0.00164, step time: 0.04256\n",
      "epoch: [0], step: [239/377], batch loss: 2.33761, batch accuracy: 54.69, data load time: 0.00170, step time: 0.04247\n",
      "epoch: [0], step: [249/377], batch loss: 1.42241, batch accuracy: 69.53, data load time: 0.00153, step time: 0.04258\n",
      "epoch: [0], step: [259/377], batch loss: 1.63901, batch accuracy: 65.62, data load time: 0.00179, step time: 0.04222\n",
      "epoch: [0], step: [269/377], batch loss: 1.41150, batch accuracy: 72.66, data load time: 0.00169, step time: 0.04224\n",
      "epoch: [0], step: [279/377], batch loss: 1.59385, batch accuracy: 67.97, data load time: 0.00170, step time: 0.04210\n",
      "epoch: [0], step: [289/377], batch loss: 1.92894, batch accuracy: 58.59, data load time: 0.00157, step time: 0.04229\n",
      "epoch: [0], step: [299/377], batch loss: 1.87036, batch accuracy: 66.41, data load time: 0.00160, step time: 0.04245\n",
      "epoch: [0], step: [309/377], batch loss: 1.11185, batch accuracy: 77.34, data load time: 0.00167, step time: 0.04218\n",
      "epoch: [0], step: [319/377], batch loss: 1.94018, batch accuracy: 64.84, data load time: 0.00172, step time: 0.04235\n",
      "epoch: [0], step: [329/377], batch loss: 1.40950, batch accuracy: 72.66, data load time: 0.00183, step time: 0.04225\n",
      "epoch: [0], step: [339/377], batch loss: 1.65477, batch accuracy: 67.19, data load time: 0.00167, step time: 0.04260\n",
      "epoch: [0], step: [349/377], batch loss: 1.79185, batch accuracy: 64.06, data load time: 0.00168, step time: 0.04267\n",
      "epoch: [0], step: [359/377], batch loss: 1.43252, batch accuracy: 70.31, data load time: 0.00154, step time: 0.04247\n",
      "epoch: [0], step: [369/377], batch loss: 1.98119, batch accuracy: 60.16, data load time: 0.00177, step time: 0.04243\n",
      "epoch: [1], step: [2/377], batch loss: 1.54264, batch accuracy: 69.53, data load time: 0.00173, step time: 0.04247\n",
      "epoch: [1], step: [12/377], batch loss: 1.47399, batch accuracy: 71.88, data load time: 0.00167, step time: 0.04257\n",
      "epoch: [1], step: [22/377], batch loss: 1.85695, batch accuracy: 66.41, data load time: 0.00170, step time: 0.04236\n",
      "epoch: [1], step: [32/377], batch loss: 1.50951, batch accuracy: 69.53, data load time: 0.00186, step time: 0.04260\n",
      "epoch: [1], step: [42/377], batch loss: 1.87854, batch accuracy: 63.28, data load time: 0.00178, step time: 0.04321\n",
      "epoch: [1], step: [52/377], batch loss: 1.89598, batch accuracy: 62.50, data load time: 0.00162, step time: 0.04238\n",
      "epoch: [1], step: [62/377], batch loss: 1.42674, batch accuracy: 72.66, data load time: 0.00173, step time: 0.04210\n",
      "epoch: [1], step: [72/377], batch loss: 1.53690, batch accuracy: 70.31, data load time: 0.00170, step time: 0.04230\n",
      "epoch: [1], step: [82/377], batch loss: 1.45840, batch accuracy: 67.97, data load time: 0.00175, step time: 0.04247\n",
      "epoch: [1], step: [92/377], batch loss: 1.64312, batch accuracy: 67.97, data load time: 0.00164, step time: 0.04252\n",
      "epoch: [1], step: [102/377], batch loss: 1.55523, batch accuracy: 67.97, data load time: 0.00170, step time: 0.04255\n",
      "epoch: [1], step: [112/377], batch loss: 2.13009, batch accuracy: 57.81, data load time: 0.00170, step time: 0.04270\n",
      "epoch: [1], step: [122/377], batch loss: 1.95805, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04248\n",
      "epoch: [1], step: [132/377], batch loss: 1.80477, batch accuracy: 64.84, data load time: 0.00185, step time: 0.04344\n",
      "epoch: [1], step: [142/377], batch loss: 1.70702, batch accuracy: 67.19, data load time: 0.00155, step time: 0.04237\n",
      "epoch: [1], step: [152/377], batch loss: 1.76956, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04248\n",
      "epoch: [1], step: [162/377], batch loss: 1.86587, batch accuracy: 61.72, data load time: 0.00162, step time: 0.04253\n",
      "epoch: [1], step: [172/377], batch loss: 1.69355, batch accuracy: 67.97, data load time: 0.00163, step time: 0.04238\n",
      "epoch: [1], step: [182/377], batch loss: 1.63267, batch accuracy: 66.41, data load time: 0.00182, step time: 0.04249\n",
      "epoch: [1], step: [192/377], batch loss: 1.70218, batch accuracy: 66.41, data load time: 0.00154, step time: 0.04234\n",
      "epoch: [1], step: [202/377], batch loss: 2.00132, batch accuracy: 60.16, data load time: 0.00175, step time: 0.04221\n",
      "epoch: [1], step: [212/377], batch loss: 1.95932, batch accuracy: 60.94, data load time: 0.00171, step time: 0.04272\n",
      "epoch: [1], step: [222/377], batch loss: 1.65045, batch accuracy: 66.41, data load time: 0.00182, step time: 0.04353\n",
      "epoch: [1], step: [232/377], batch loss: 1.93478, batch accuracy: 64.84, data load time: 0.00180, step time: 0.04234\n",
      "epoch: [1], step: [242/377], batch loss: 1.48386, batch accuracy: 71.88, data load time: 0.00233, step time: 0.04235\n",
      "epoch: [1], step: [252/377], batch loss: 1.64661, batch accuracy: 66.41, data load time: 0.00169, step time: 0.04255\n",
      "epoch: [1], step: [262/377], batch loss: 1.61870, batch accuracy: 67.97, data load time: 0.00188, step time: 0.04253\n",
      "epoch: [1], step: [272/377], batch loss: 1.19275, batch accuracy: 74.22, data load time: 0.00200, step time: 0.04255\n",
      "epoch: [1], step: [282/377], batch loss: 1.78256, batch accuracy: 65.62, data load time: 0.00164, step time: 0.04251\n",
      "epoch: [1], step: [292/377], batch loss: 1.39390, batch accuracy: 72.66, data load time: 0.00186, step time: 0.04263\n",
      "epoch: [1], step: [302/377], batch loss: 1.86301, batch accuracy: 62.50, data load time: 0.00177, step time: 0.04270\n",
      "epoch: [1], step: [312/377], batch loss: 1.44757, batch accuracy: 70.31, data load time: 0.00181, step time: 0.04378\n",
      "epoch: [1], step: [322/377], batch loss: 1.39288, batch accuracy: 71.09, data load time: 0.00165, step time: 0.04236\n",
      "epoch: [1], step: [332/377], batch loss: 1.83737, batch accuracy: 62.50, data load time: 0.00163, step time: 0.04221\n",
      "epoch: [1], step: [342/377], batch loss: 1.72391, batch accuracy: 65.62, data load time: 0.00170, step time: 0.04243\n",
      "epoch: [1], step: [352/377], batch loss: 1.77634, batch accuracy: 67.19, data load time: 0.00166, step time: 0.04253\n",
      "epoch: [1], step: [362/377], batch loss: 1.90330, batch accuracy: 61.72, data load time: 0.00169, step time: 0.04259\n",
      "epoch: [1], step: [372/377], batch loss: 1.20387, batch accuracy: 74.22, data load time: 0.00166, step time: 0.04240\n",
      "epoch: [2], step: [5/377], batch loss: 1.50267, batch accuracy: 67.97, data load time: 0.00168, step time: 0.04242\n",
      "epoch: [2], step: [15/377], batch loss: 1.28098, batch accuracy: 73.44, data load time: 0.00173, step time: 0.04224\n",
      "epoch: [2], step: [25/377], batch loss: 1.96276, batch accuracy: 61.72, data load time: 0.00185, step time: 0.04254\n",
      "epoch: [2], step: [35/377], batch loss: 1.51659, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04261\n",
      "epoch: [2], step: [45/377], batch loss: 1.76171, batch accuracy: 63.28, data load time: 0.00165, step time: 0.04266\n",
      "epoch: [2], step: [55/377], batch loss: 1.78969, batch accuracy: 64.06, data load time: 0.00171, step time: 0.04249\n",
      "epoch: [2], step: [65/377], batch loss: 1.37353, batch accuracy: 72.66, data load time: 0.00166, step time: 0.04248\n",
      "epoch: [2], step: [75/377], batch loss: 1.53089, batch accuracy: 65.62, data load time: 0.00177, step time: 0.04250\n",
      "epoch: [2], step: [85/377], batch loss: 2.02365, batch accuracy: 61.72, data load time: 0.00170, step time: 0.04227\n",
      "epoch: [2], step: [95/377], batch loss: 1.78400, batch accuracy: 65.62, data load time: 0.00180, step time: 0.04267\n",
      "epoch: [2], step: [105/377], batch loss: 1.61381, batch accuracy: 67.97, data load time: 0.00175, step time: 0.04267\n",
      "epoch: [2], step: [115/377], batch loss: 1.72641, batch accuracy: 67.19, data load time: 0.00162, step time: 0.04256\n",
      "epoch: [2], step: [125/377], batch loss: 1.56870, batch accuracy: 69.53, data load time: 0.00175, step time: 0.04231\n",
      "epoch: [2], step: [135/377], batch loss: 1.83156, batch accuracy: 65.62, data load time: 0.00177, step time: 0.04245\n",
      "epoch: [2], step: [145/377], batch loss: 1.65032, batch accuracy: 70.31, data load time: 0.00169, step time: 0.04254\n",
      "epoch: [2], step: [155/377], batch loss: 2.20507, batch accuracy: 57.81, data load time: 0.00167, step time: 0.04268\n",
      "epoch: [2], step: [165/377], batch loss: 1.58717, batch accuracy: 67.19, data load time: 0.00178, step time: 0.04249\n",
      "epoch: [2], step: [175/377], batch loss: 1.68151, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04231\n",
      "epoch: [2], step: [185/377], batch loss: 1.61217, batch accuracy: 69.53, data load time: 0.00178, step time: 0.04232\n",
      "epoch: [2], step: [195/377], batch loss: 1.27341, batch accuracy: 74.22, data load time: 0.00170, step time: 0.04255\n",
      "epoch: [2], step: [205/377], batch loss: 1.54310, batch accuracy: 68.75, data load time: 0.00169, step time: 0.04281\n",
      "epoch: [2], step: [215/377], batch loss: 1.73090, batch accuracy: 66.41, data load time: 0.00166, step time: 0.04256\n",
      "epoch: [2], step: [225/377], batch loss: 1.68249, batch accuracy: 67.97, data load time: 0.00168, step time: 0.04331\n",
      "epoch: [2], step: [235/377], batch loss: 1.78488, batch accuracy: 65.62, data load time: 0.00179, step time: 0.04242\n",
      "epoch: [2], step: [245/377], batch loss: 1.63425, batch accuracy: 66.41, data load time: 0.00164, step time: 0.04261\n",
      "epoch: [2], step: [255/377], batch loss: 1.61433, batch accuracy: 69.53, data load time: 0.00170, step time: 0.04251\n",
      "epoch: [2], step: [265/377], batch loss: 2.01047, batch accuracy: 58.59, data load time: 0.00172, step time: 0.04267\n",
      "epoch: [2], step: [275/377], batch loss: 1.37398, batch accuracy: 74.22, data load time: 0.00192, step time: 0.04244\n",
      "epoch: [2], step: [285/377], batch loss: 1.76074, batch accuracy: 64.84, data load time: 0.00165, step time: 0.04233\n",
      "epoch: [2], step: [295/377], batch loss: 1.57849, batch accuracy: 67.19, data load time: 0.00174, step time: 0.04229\n",
      "epoch: [2], step: [305/377], batch loss: 1.26246, batch accuracy: 72.66, data load time: 0.00177, step time: 0.04265\n",
      "epoch: [2], step: [315/377], batch loss: 1.75641, batch accuracy: 63.28, data load time: 0.00182, step time: 0.04260\n",
      "epoch: [2], step: [325/377], batch loss: 1.59047, batch accuracy: 68.75, data load time: 0.00163, step time: 0.04252\n",
      "epoch: [2], step: [335/377], batch loss: 1.44548, batch accuracy: 69.53, data load time: 0.00174, step time: 0.04249\n",
      "epoch: [2], step: [345/377], batch loss: 1.75654, batch accuracy: 67.19, data load time: 0.00231, step time: 0.04261\n",
      "epoch: [2], step: [355/377], batch loss: 1.82499, batch accuracy: 60.94, data load time: 0.00175, step time: 0.04277\n",
      "epoch: [2], step: [365/377], batch loss: 1.74816, batch accuracy: 64.84, data load time: 0.00252, step time: 0.04228\n",
      "epoch: [2], step: [375/377], batch loss: 2.07631, batch accuracy: 60.16, data load time: 0.00165, step time: 0.04245\n",
      "epoch: [3], step: [8/377], batch loss: 1.72649, batch accuracy: 64.84, data load time: 0.00188, step time: 0.04270\n",
      "epoch: [3], step: [18/377], batch loss: 1.64400, batch accuracy: 67.97, data load time: 0.00178, step time: 0.04271\n",
      "epoch: [3], step: [28/377], batch loss: 1.82330, batch accuracy: 61.72, data load time: 0.00151, step time: 0.04249\n",
      "epoch: [3], step: [38/377], batch loss: 1.54343, batch accuracy: 69.53, data load time: 0.00175, step time: 0.04270\n",
      "epoch: [3], step: [48/377], batch loss: 1.74545, batch accuracy: 62.50, data load time: 0.00171, step time: 0.04234\n",
      "epoch: [3], step: [58/377], batch loss: 1.41677, batch accuracy: 69.53, data load time: 0.00181, step time: 0.04255\n",
      "epoch: [3], step: [68/377], batch loss: 1.54681, batch accuracy: 68.75, data load time: 0.00169, step time: 0.04272\n",
      "epoch: [3], step: [78/377], batch loss: 1.74162, batch accuracy: 65.62, data load time: 0.00184, step time: 0.04270\n",
      "epoch: [3], step: [88/377], batch loss: 1.68323, batch accuracy: 66.41, data load time: 0.00164, step time: 0.04286\n",
      "epoch: [3], step: [98/377], batch loss: 1.84496, batch accuracy: 64.06, data load time: 0.00158, step time: 0.04244\n",
      "epoch: [3], step: [108/377], batch loss: 1.41933, batch accuracy: 72.66, data load time: 0.00161, step time: 0.04254\n",
      "epoch: [3], step: [118/377], batch loss: 1.75040, batch accuracy: 65.62, data load time: 0.00167, step time: 0.04251\n",
      "epoch: [3], step: [128/377], batch loss: 1.90304, batch accuracy: 61.72, data load time: 0.00165, step time: 0.04273\n",
      "epoch: [3], step: [138/377], batch loss: 1.89883, batch accuracy: 63.28, data load time: 0.00154, step time: 0.04264\n",
      "epoch: [3], step: [148/377], batch loss: 1.41643, batch accuracy: 71.88, data load time: 0.00173, step time: 0.04241\n",
      "epoch: [3], step: [158/377], batch loss: 1.39570, batch accuracy: 72.66, data load time: 0.00182, step time: 0.04230\n",
      "epoch: [3], step: [168/377], batch loss: 1.61438, batch accuracy: 69.53, data load time: 0.00178, step time: 0.04417\n",
      "epoch: [3], step: [178/377], batch loss: 1.85568, batch accuracy: 60.16, data load time: 0.00187, step time: 0.04263\n",
      "epoch: [3], step: [188/377], batch loss: 1.61458, batch accuracy: 67.97, data load time: 0.00158, step time: 0.04247\n",
      "epoch: [3], step: [198/377], batch loss: 1.47310, batch accuracy: 71.09, data load time: 0.00201, step time: 0.04239\n",
      "epoch: [3], step: [208/377], batch loss: 1.59837, batch accuracy: 68.75, data load time: 0.00169, step time: 0.04204\n",
      "epoch: [3], step: [218/377], batch loss: 1.59487, batch accuracy: 67.97, data load time: 0.00171, step time: 0.04253\n",
      "epoch: [3], step: [228/377], batch loss: 1.86302, batch accuracy: 62.50, data load time: 0.00160, step time: 0.04267\n",
      "epoch: [3], step: [238/377], batch loss: 1.93387, batch accuracy: 60.16, data load time: 0.00177, step time: 0.04261\n",
      "epoch: [3], step: [248/377], batch loss: 1.74853, batch accuracy: 64.84, data load time: 0.00168, step time: 0.04250\n",
      "epoch: [3], step: [258/377], batch loss: 1.48494, batch accuracy: 71.88, data load time: 0.00165, step time: 0.04379\n",
      "epoch: [3], step: [268/377], batch loss: 1.61580, batch accuracy: 65.62, data load time: 0.00171, step time: 0.04252\n",
      "epoch: [3], step: [278/377], batch loss: 2.02133, batch accuracy: 60.94, data load time: 0.00173, step time: 0.04275\n",
      "epoch: [3], step: [288/377], batch loss: 1.78135, batch accuracy: 67.19, data load time: 0.00174, step time: 0.04272\n",
      "epoch: [3], step: [298/377], batch loss: 1.54461, batch accuracy: 65.62, data load time: 0.00169, step time: 0.04251\n",
      "epoch: [3], step: [308/377], batch loss: 1.43192, batch accuracy: 71.88, data load time: 0.00171, step time: 0.04235\n",
      "epoch: [3], step: [318/377], batch loss: 1.60907, batch accuracy: 67.97, data load time: 0.00171, step time: 0.04231\n",
      "epoch: [3], step: [328/377], batch loss: 1.37396, batch accuracy: 71.88, data load time: 0.00169, step time: 0.04245\n",
      "epoch: [3], step: [338/377], batch loss: 1.67343, batch accuracy: 67.19, data load time: 0.00175, step time: 0.04268\n",
      "epoch: [3], step: [348/377], batch loss: 1.70662, batch accuracy: 67.19, data load time: 0.00162, step time: 0.04463\n",
      "epoch: [3], step: [358/377], batch loss: 1.49456, batch accuracy: 70.31, data load time: 0.00165, step time: 0.04241\n",
      "epoch: [3], step: [368/377], batch loss: 1.72638, batch accuracy: 64.84, data load time: 0.00163, step time: 0.04234\n",
      "epoch: [4], step: [1/377], batch loss: 2.00099, batch accuracy: 62.50, data load time: 0.00154, step time: 0.04262\n",
      "epoch: [4], step: [11/377], batch loss: 1.90378, batch accuracy: 62.50, data load time: 0.00175, step time: 0.04273\n",
      "epoch: [4], step: [21/377], batch loss: 1.86712, batch accuracy: 63.28, data load time: 0.00164, step time: 0.04235\n",
      "epoch: [4], step: [31/377], batch loss: 1.50175, batch accuracy: 70.31, data load time: 0.00167, step time: 0.04235\n",
      "epoch: [4], step: [41/377], batch loss: 1.56271, batch accuracy: 68.75, data load time: 0.00166, step time: 0.04255\n",
      "epoch: [4], step: [51/377], batch loss: 1.83136, batch accuracy: 62.50, data load time: 0.00167, step time: 0.04255\n",
      "epoch: [4], step: [61/377], batch loss: 1.74477, batch accuracy: 62.50, data load time: 0.00167, step time: 0.04265\n",
      "epoch: [4], step: [71/377], batch loss: 2.21428, batch accuracy: 57.03, data load time: 0.00168, step time: 0.04287\n",
      "epoch: [4], step: [81/377], batch loss: 1.59491, batch accuracy: 64.84, data load time: 0.00179, step time: 0.04249\n",
      "epoch: [4], step: [91/377], batch loss: 1.84747, batch accuracy: 63.28, data load time: 0.00174, step time: 0.04237\n",
      "epoch: [4], step: [101/377], batch loss: 1.74409, batch accuracy: 64.06, data load time: 0.00173, step time: 0.04253\n",
      "epoch: [4], step: [111/377], batch loss: 1.49924, batch accuracy: 67.97, data load time: 0.00172, step time: 0.04255\n",
      "epoch: [4], step: [121/377], batch loss: 2.09387, batch accuracy: 59.38, data load time: 0.00149, step time: 0.04271\n",
      "epoch: [4], step: [131/377], batch loss: 1.73387, batch accuracy: 63.28, data load time: 0.00171, step time: 0.04249\n",
      "epoch: [4], step: [141/377], batch loss: 1.56297, batch accuracy: 67.97, data load time: 0.00171, step time: 0.04235\n",
      "epoch: [4], step: [151/377], batch loss: 1.56839, batch accuracy: 67.97, data load time: 0.00172, step time: 0.04263\n",
      "epoch: [4], step: [161/377], batch loss: 1.75711, batch accuracy: 66.41, data load time: 0.00162, step time: 0.04252\n",
      "epoch: [4], step: [171/377], batch loss: 1.91939, batch accuracy: 64.06, data load time: 0.00197, step time: 0.04283\n",
      "epoch: [4], step: [181/377], batch loss: 1.52464, batch accuracy: 69.53, data load time: 0.00172, step time: 0.04249\n",
      "epoch: [4], step: [191/377], batch loss: 1.65293, batch accuracy: 66.41, data load time: 0.00166, step time: 0.04226\n",
      "epoch: [4], step: [201/377], batch loss: 2.11290, batch accuracy: 58.59, data load time: 0.00163, step time: 0.04232\n",
      "epoch: [4], step: [211/377], batch loss: 1.58931, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04263\n",
      "epoch: [4], step: [221/377], batch loss: 1.84759, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04263\n",
      "epoch: [4], step: [231/377], batch loss: 1.73178, batch accuracy: 64.84, data load time: 0.00187, step time: 0.04272\n",
      "epoch: [4], step: [241/377], batch loss: 2.02183, batch accuracy: 60.16, data load time: 0.00177, step time: 0.04245\n",
      "epoch: [4], step: [251/377], batch loss: 1.72235, batch accuracy: 67.19, data load time: 0.00181, step time: 0.04249\n",
      "epoch: [4], step: [261/377], batch loss: 1.62150, batch accuracy: 64.84, data load time: 0.00166, step time: 0.04250\n",
      "epoch: [4], step: [271/377], batch loss: 1.58133, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04260\n",
      "epoch: [4], step: [281/377], batch loss: 1.44380, batch accuracy: 69.53, data load time: 0.00173, step time: 0.04314\n",
      "epoch: [4], step: [291/377], batch loss: 1.64637, batch accuracy: 67.97, data load time: 0.00169, step time: 0.04241\n",
      "epoch: [4], step: [301/377], batch loss: 1.24108, batch accuracy: 75.78, data load time: 0.00168, step time: 0.04250\n",
      "epoch: [4], step: [311/377], batch loss: 1.91699, batch accuracy: 63.28, data load time: 0.00219, step time: 0.04264\n",
      "epoch: [4], step: [321/377], batch loss: 2.11953, batch accuracy: 58.59, data load time: 0.00169, step time: 0.04249\n",
      "epoch: [4], step: [331/377], batch loss: 1.71414, batch accuracy: 64.06, data load time: 0.00164, step time: 0.04241\n",
      "epoch: [4], step: [341/377], batch loss: 1.73151, batch accuracy: 66.41, data load time: 0.00172, step time: 0.04258\n",
      "epoch: [4], step: [351/377], batch loss: 1.51747, batch accuracy: 72.66, data load time: 0.00159, step time: 0.04253\n",
      "epoch: [4], step: [361/377], batch loss: 1.53314, batch accuracy: 67.97, data load time: 0.00219, step time: 0.04273\n",
      "epoch: [4], step: [371/377], batch loss: 1.67010, batch accuracy: 67.19, data load time: 0.00164, step time: 0.04248\n",
      "epoch: [5], step: [4/377], batch loss: 2.03305, batch accuracy: 61.72, data load time: 0.00169, step time: 0.04271\n",
      "epoch: [5], step: [14/377], batch loss: 1.41720, batch accuracy: 72.66, data load time: 0.00162, step time: 0.04262\n",
      "epoch: [5], step: [24/377], batch loss: 1.55532, batch accuracy: 68.75, data load time: 0.00186, step time: 0.04266\n",
      "epoch: [5], step: [34/377], batch loss: 1.63514, batch accuracy: 65.62, data load time: 0.00185, step time: 0.04272\n",
      "epoch: [5], step: [44/377], batch loss: 1.69380, batch accuracy: 60.94, data load time: 0.00169, step time: 0.04226\n",
      "epoch: [5], step: [54/377], batch loss: 1.50971, batch accuracy: 71.09, data load time: 0.00169, step time: 0.04257\n",
      "epoch: [5], step: [64/377], batch loss: 1.41515, batch accuracy: 69.53, data load time: 0.00174, step time: 0.04279\n",
      "epoch: [5], step: [74/377], batch loss: 1.60622, batch accuracy: 67.19, data load time: 0.00183, step time: 0.04242\n",
      "epoch: [5], step: [84/377], batch loss: 1.88103, batch accuracy: 63.28, data load time: 0.00176, step time: 0.04230\n",
      "epoch: [5], step: [94/377], batch loss: 1.94125, batch accuracy: 62.50, data load time: 0.00173, step time: 0.04270\n",
      "epoch: [5], step: [104/377], batch loss: 1.79503, batch accuracy: 63.28, data load time: 0.00164, step time: 0.04271\n",
      "epoch: [5], step: [114/377], batch loss: 2.25916, batch accuracy: 54.69, data load time: 0.00190, step time: 0.04242\n",
      "epoch: [5], step: [124/377], batch loss: 1.26044, batch accuracy: 72.66, data load time: 0.00171, step time: 0.04276\n",
      "epoch: [5], step: [134/377], batch loss: 1.54093, batch accuracy: 69.53, data load time: 0.00186, step time: 0.04245\n",
      "epoch: [5], step: [144/377], batch loss: 1.26892, batch accuracy: 75.78, data load time: 0.00184, step time: 0.04305\n",
      "epoch: [5], step: [154/377], batch loss: 1.78992, batch accuracy: 65.62, data load time: 0.00178, step time: 0.04247\n",
      "epoch: [5], step: [164/377], batch loss: 1.99852, batch accuracy: 63.28, data load time: 0.00179, step time: 0.04230\n",
      "epoch: [5], step: [174/377], batch loss: 1.84008, batch accuracy: 66.41, data load time: 0.00179, step time: 0.04257\n",
      "epoch: [5], step: [184/377], batch loss: 1.74233, batch accuracy: 67.19, data load time: 0.00175, step time: 0.04283\n",
      "epoch: [5], step: [194/377], batch loss: 1.61463, batch accuracy: 67.19, data load time: 0.00166, step time: 0.04281\n",
      "epoch: [5], step: [204/377], batch loss: 1.71193, batch accuracy: 67.97, data load time: 0.00184, step time: 0.04253\n",
      "epoch: [5], step: [214/377], batch loss: 1.74169, batch accuracy: 66.41, data load time: 0.00183, step time: 0.04257\n",
      "epoch: [5], step: [224/377], batch loss: 1.52988, batch accuracy: 65.62, data load time: 0.00202, step time: 0.04269\n",
      "epoch: [5], step: [234/377], batch loss: 1.51494, batch accuracy: 71.09, data load time: 0.00178, step time: 0.04252\n",
      "epoch: [5], step: [244/377], batch loss: 1.94285, batch accuracy: 62.50, data load time: 0.00173, step time: 0.04237\n",
      "epoch: [5], step: [254/377], batch loss: 1.71037, batch accuracy: 66.41, data load time: 0.00176, step time: 0.04258\n",
      "epoch: [5], step: [264/377], batch loss: 1.74038, batch accuracy: 65.62, data load time: 0.00179, step time: 0.04301\n",
      "epoch: [5], step: [274/377], batch loss: 1.63392, batch accuracy: 66.41, data load time: 0.00176, step time: 0.04243\n",
      "epoch: [5], step: [284/377], batch loss: 1.73581, batch accuracy: 67.19, data load time: 0.00164, step time: 0.04259\n",
      "epoch: [5], step: [294/377], batch loss: 1.72386, batch accuracy: 65.62, data load time: 0.00190, step time: 0.04260\n",
      "epoch: [5], step: [304/377], batch loss: 1.39989, batch accuracy: 71.09, data load time: 0.00178, step time: 0.04268\n",
      "epoch: [5], step: [314/377], batch loss: 1.79284, batch accuracy: 67.19, data load time: 0.00184, step time: 0.04269\n",
      "epoch: [5], step: [324/377], batch loss: 1.57604, batch accuracy: 69.53, data load time: 0.00178, step time: 0.04232\n",
      "epoch: [5], step: [334/377], batch loss: 1.71633, batch accuracy: 65.62, data load time: 0.00177, step time: 0.04264\n",
      "epoch: [5], step: [344/377], batch loss: 1.51413, batch accuracy: 68.75, data load time: 0.00160, step time: 0.04280\n",
      "epoch: [5], step: [354/377], batch loss: 1.91893, batch accuracy: 61.72, data load time: 0.00175, step time: 0.04241\n",
      "epoch: [5], step: [364/377], batch loss: 2.06246, batch accuracy: 57.81, data load time: 0.00168, step time: 0.04220\n",
      "epoch: [5], step: [374/377], batch loss: 1.56166, batch accuracy: 69.53, data load time: 0.00171, step time: 0.04228\n",
      "epoch: [6], step: [7/377], batch loss: 1.70230, batch accuracy: 68.75, data load time: 0.00189, step time: 0.04261\n",
      "epoch: [6], step: [17/377], batch loss: 1.56649, batch accuracy: 70.31, data load time: 0.00180, step time: 0.04277\n",
      "epoch: [6], step: [27/377], batch loss: 1.48056, batch accuracy: 68.75, data load time: 0.00187, step time: 0.04254\n",
      "epoch: [6], step: [37/377], batch loss: 1.45690, batch accuracy: 68.75, data load time: 0.00168, step time: 0.04243\n",
      "epoch: [6], step: [47/377], batch loss: 1.94966, batch accuracy: 60.94, data load time: 0.00166, step time: 0.04282\n",
      "epoch: [6], step: [57/377], batch loss: 1.26844, batch accuracy: 74.22, data load time: 0.00186, step time: 0.04287\n",
      "epoch: [6], step: [67/377], batch loss: 1.63307, batch accuracy: 67.97, data load time: 0.00184, step time: 0.04252\n",
      "epoch: [6], step: [77/377], batch loss: 1.70883, batch accuracy: 64.06, data load time: 0.00179, step time: 0.04260\n",
      "epoch: [6], step: [87/377], batch loss: 1.60144, batch accuracy: 68.75, data load time: 0.00178, step time: 0.04277\n",
      "epoch: [6], step: [97/377], batch loss: 1.38830, batch accuracy: 70.31, data load time: 0.00181, step time: 0.04258\n",
      "epoch: [6], step: [107/377], batch loss: 1.53946, batch accuracy: 66.41, data load time: 0.00171, step time: 0.04265\n",
      "epoch: [6], step: [117/377], batch loss: 1.71847, batch accuracy: 65.62, data load time: 0.00162, step time: 0.04244\n",
      "epoch: [6], step: [127/377], batch loss: 1.95049, batch accuracy: 61.72, data load time: 0.00171, step time: 0.04246\n",
      "epoch: [6], step: [137/377], batch loss: 1.69709, batch accuracy: 66.41, data load time: 0.00167, step time: 0.04263\n",
      "epoch: [6], step: [147/377], batch loss: 1.43493, batch accuracy: 71.88, data load time: 0.00175, step time: 0.04259\n",
      "epoch: [6], step: [157/377], batch loss: 1.96843, batch accuracy: 60.94, data load time: 0.00171, step time: 0.04251\n",
      "epoch: [6], step: [167/377], batch loss: 1.83758, batch accuracy: 64.84, data load time: 0.00172, step time: 0.04245\n",
      "epoch: [6], step: [177/377], batch loss: 1.43911, batch accuracy: 70.31, data load time: 0.00154, step time: 0.04271\n",
      "epoch: [6], step: [187/377], batch loss: 1.58861, batch accuracy: 67.19, data load time: 0.00191, step time: 0.04256\n",
      "epoch: [6], step: [197/377], batch loss: 1.18612, batch accuracy: 74.22, data load time: 0.00167, step time: 0.04269\n",
      "epoch: [6], step: [207/377], batch loss: 1.40939, batch accuracy: 71.88, data load time: 0.00174, step time: 0.04247\n",
      "epoch: [6], step: [217/377], batch loss: 1.86287, batch accuracy: 61.72, data load time: 0.00169, step time: 0.04263\n",
      "epoch: [6], step: [227/377], batch loss: 1.89305, batch accuracy: 62.50, data load time: 0.00184, step time: 0.04298\n",
      "epoch: [6], step: [237/377], batch loss: 1.74257, batch accuracy: 64.84, data load time: 0.00171, step time: 0.04241\n",
      "epoch: [6], step: [247/377], batch loss: 1.82453, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04253\n",
      "epoch: [6], step: [257/377], batch loss: 1.98485, batch accuracy: 61.72, data load time: 0.00166, step time: 0.04267\n",
      "epoch: [6], step: [267/377], batch loss: 1.87561, batch accuracy: 63.28, data load time: 0.00161, step time: 0.04297\n",
      "epoch: [6], step: [277/377], batch loss: 1.60339, batch accuracy: 68.75, data load time: 0.00181, step time: 0.04269\n",
      "epoch: [6], step: [287/377], batch loss: 2.06219, batch accuracy: 60.16, data load time: 0.00162, step time: 0.04256\n",
      "epoch: [6], step: [297/377], batch loss: 1.34793, batch accuracy: 71.88, data load time: 0.00176, step time: 0.04315\n",
      "epoch: [6], step: [307/377], batch loss: 1.64129, batch accuracy: 68.75, data load time: 0.00171, step time: 0.04327\n",
      "epoch: [6], step: [317/377], batch loss: 1.32403, batch accuracy: 73.44, data load time: 0.00179, step time: 0.04245\n",
      "epoch: [6], step: [327/377], batch loss: 1.54310, batch accuracy: 70.31, data load time: 0.00172, step time: 0.04268\n",
      "epoch: [6], step: [337/377], batch loss: 1.60180, batch accuracy: 69.53, data load time: 0.00232, step time: 0.04254\n",
      "epoch: [6], step: [347/377], batch loss: 1.76388, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04254\n",
      "epoch: [6], step: [357/377], batch loss: 1.62486, batch accuracy: 70.31, data load time: 0.00157, step time: 0.04250\n",
      "epoch: [6], step: [367/377], batch loss: 1.66396, batch accuracy: 67.19, data load time: 0.00199, step time: 0.04270\n",
      "epoch: [7], step: [0/377], batch loss: 1.65254, batch accuracy: 68.75, data load time: 0.00499, step time: 0.04236\n",
      "epoch: [7], step: [10/377], batch loss: 1.65998, batch accuracy: 67.19, data load time: 0.00176, step time: 0.04253\n",
      "epoch: [7], step: [20/377], batch loss: 1.66518, batch accuracy: 64.06, data load time: 0.00180, step time: 0.04251\n",
      "epoch: [7], step: [30/377], batch loss: 1.62674, batch accuracy: 68.75, data load time: 0.00182, step time: 0.04277\n",
      "epoch: [7], step: [40/377], batch loss: 1.95626, batch accuracy: 60.94, data load time: 0.00183, step time: 0.04288\n",
      "epoch: [7], step: [50/377], batch loss: 1.70730, batch accuracy: 67.19, data load time: 0.00168, step time: 0.04250\n",
      "epoch: [7], step: [60/377], batch loss: 1.41932, batch accuracy: 74.22, data load time: 0.00180, step time: 0.04257\n",
      "epoch: [7], step: [70/377], batch loss: 1.94784, batch accuracy: 60.94, data load time: 0.00178, step time: 0.04278\n",
      "epoch: [7], step: [80/377], batch loss: 1.89543, batch accuracy: 63.28, data load time: 0.00196, step time: 0.04241\n",
      "epoch: [7], step: [90/377], batch loss: 1.50935, batch accuracy: 71.88, data load time: 0.00156, step time: 0.04259\n",
      "epoch: [7], step: [100/377], batch loss: 1.56221, batch accuracy: 69.53, data load time: 0.00170, step time: 0.04266\n",
      "epoch: [7], step: [110/377], batch loss: 1.29671, batch accuracy: 71.88, data load time: 0.00171, step time: 0.04252\n",
      "epoch: [7], step: [120/377], batch loss: 1.59390, batch accuracy: 67.97, data load time: 0.00166, step time: 0.04251\n",
      "epoch: [7], step: [130/377], batch loss: 1.49126, batch accuracy: 71.09, data load time: 0.00176, step time: 0.04292\n",
      "epoch: [7], step: [140/377], batch loss: 1.61262, batch accuracy: 67.97, data load time: 0.00181, step time: 0.04305\n",
      "epoch: [7], step: [150/377], batch loss: 1.71775, batch accuracy: 64.84, data load time: 0.00178, step time: 0.04248\n",
      "epoch: [7], step: [160/377], batch loss: 1.70627, batch accuracy: 64.84, data load time: 0.00179, step time: 0.04259\n",
      "epoch: [7], step: [170/377], batch loss: 1.46304, batch accuracy: 69.53, data load time: 0.00188, step time: 0.04289\n",
      "epoch: [7], step: [180/377], batch loss: 1.80447, batch accuracy: 60.94, data load time: 0.00187, step time: 0.04245\n",
      "epoch: [7], step: [190/377], batch loss: 1.41360, batch accuracy: 72.66, data load time: 0.00172, step time: 0.04254\n",
      "epoch: [7], step: [200/377], batch loss: 1.58686, batch accuracy: 67.97, data load time: 0.00166, step time: 0.04282\n",
      "epoch: [7], step: [210/377], batch loss: 1.34837, batch accuracy: 71.88, data load time: 0.00157, step time: 0.04278\n",
      "epoch: [7], step: [220/377], batch loss: 1.86738, batch accuracy: 63.28, data load time: 0.00168, step time: 0.04246\n",
      "epoch: [7], step: [230/377], batch loss: 1.57239, batch accuracy: 68.75, data load time: 0.00160, step time: 0.04253\n",
      "epoch: [7], step: [240/377], batch loss: 1.48762, batch accuracy: 70.31, data load time: 0.00164, step time: 0.04320\n",
      "epoch: [7], step: [250/377], batch loss: 1.94270, batch accuracy: 62.50, data load time: 0.00177, step time: 0.04248\n",
      "epoch: [7], step: [260/377], batch loss: 1.65311, batch accuracy: 67.19, data load time: 0.00173, step time: 0.04286\n",
      "epoch: [7], step: [270/377], batch loss: 2.05453, batch accuracy: 57.03, data load time: 0.00164, step time: 0.04267\n",
      "epoch: [7], step: [280/377], batch loss: 1.87253, batch accuracy: 64.84, data load time: 0.00160, step time: 0.04298\n",
      "epoch: [7], step: [290/377], batch loss: 1.98000, batch accuracy: 59.38, data load time: 0.00165, step time: 0.04249\n",
      "epoch: [7], step: [300/377], batch loss: 1.61697, batch accuracy: 67.97, data load time: 0.00174, step time: 0.04255\n",
      "epoch: [7], step: [310/377], batch loss: 1.54635, batch accuracy: 68.75, data load time: 0.00182, step time: 0.04270\n",
      "epoch: [7], step: [320/377], batch loss: 2.06319, batch accuracy: 60.94, data load time: 0.00179, step time: 0.04280\n",
      "epoch: [7], step: [330/377], batch loss: 1.83702, batch accuracy: 62.50, data load time: 0.00165, step time: 0.04262\n",
      "epoch: [7], step: [340/377], batch loss: 2.02480, batch accuracy: 61.72, data load time: 0.00169, step time: 0.04241\n",
      "epoch: [7], step: [350/377], batch loss: 1.78024, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04255\n",
      "epoch: [7], step: [360/377], batch loss: 1.80909, batch accuracy: 64.06, data load time: 0.00174, step time: 0.04260\n",
      "epoch: [7], step: [370/377], batch loss: 1.80885, batch accuracy: 65.62, data load time: 0.00169, step time: 0.04315\n",
      "epoch: [8], step: [3/377], batch loss: 1.28267, batch accuracy: 75.78, data load time: 0.00174, step time: 0.04272\n",
      "epoch: [8], step: [13/377], batch loss: 1.53770, batch accuracy: 69.53, data load time: 0.00172, step time: 0.04255\n",
      "epoch: [8], step: [23/377], batch loss: 1.74300, batch accuracy: 64.84, data load time: 0.00182, step time: 0.04283\n",
      "epoch: [8], step: [33/377], batch loss: 1.37829, batch accuracy: 73.44, data load time: 0.00179, step time: 0.04262\n",
      "epoch: [8], step: [43/377], batch loss: 1.56172, batch accuracy: 67.19, data load time: 0.00175, step time: 0.04241\n",
      "epoch: [8], step: [53/377], batch loss: 1.54599, batch accuracy: 70.31, data load time: 0.00171, step time: 0.04257\n",
      "epoch: [8], step: [63/377], batch loss: 1.48442, batch accuracy: 71.09, data load time: 0.00195, step time: 0.04255\n",
      "epoch: [8], step: [73/377], batch loss: 1.82179, batch accuracy: 60.94, data load time: 0.00183, step time: 0.04265\n",
      "epoch: [8], step: [83/377], batch loss: 1.83451, batch accuracy: 61.72, data load time: 0.00170, step time: 0.04248\n",
      "epoch: [8], step: [93/377], batch loss: 1.28067, batch accuracy: 71.09, data load time: 0.00180, step time: 0.04300\n",
      "epoch: [8], step: [103/377], batch loss: 1.35604, batch accuracy: 73.44, data load time: 0.00160, step time: 0.04305\n",
      "epoch: [8], step: [113/377], batch loss: 1.60897, batch accuracy: 68.75, data load time: 0.00165, step time: 0.04266\n",
      "epoch: [8], step: [123/377], batch loss: 1.94191, batch accuracy: 59.38, data load time: 0.00170, step time: 0.04238\n",
      "epoch: [8], step: [133/377], batch loss: 1.56702, batch accuracy: 70.31, data load time: 0.00171, step time: 0.04252\n",
      "epoch: [8], step: [143/377], batch loss: 1.51701, batch accuracy: 69.53, data load time: 0.00171, step time: 0.04282\n",
      "epoch: [8], step: [153/377], batch loss: 2.03266, batch accuracy: 61.72, data load time: 0.00187, step time: 0.04267\n",
      "epoch: [8], step: [163/377], batch loss: 1.99720, batch accuracy: 61.72, data load time: 0.00174, step time: 0.04255\n",
      "epoch: [8], step: [173/377], batch loss: 2.35726, batch accuracy: 56.25, data load time: 0.00184, step time: 0.04309\n",
      "epoch: [8], step: [183/377], batch loss: 1.80537, batch accuracy: 67.19, data load time: 0.00183, step time: 0.04277\n",
      "epoch: [8], step: [193/377], batch loss: 1.53853, batch accuracy: 71.09, data load time: 0.00162, step time: 0.04246\n",
      "epoch: [8], step: [203/377], batch loss: 1.87545, batch accuracy: 62.50, data load time: 0.00178, step time: 0.04263\n",
      "epoch: [8], step: [213/377], batch loss: 1.68481, batch accuracy: 64.84, data load time: 0.00171, step time: 0.04258\n",
      "epoch: [8], step: [223/377], batch loss: 1.89064, batch accuracy: 61.72, data load time: 0.00164, step time: 0.04253\n",
      "epoch: [8], step: [233/377], batch loss: 1.85282, batch accuracy: 63.28, data load time: 0.00171, step time: 0.04238\n",
      "epoch: [8], step: [243/377], batch loss: 1.90121, batch accuracy: 61.72, data load time: 0.00189, step time: 0.04245\n",
      "epoch: [8], step: [253/377], batch loss: 1.81872, batch accuracy: 61.72, data load time: 0.00183, step time: 0.04260\n",
      "epoch: [8], step: [263/377], batch loss: 1.86144, batch accuracy: 63.28, data load time: 0.00172, step time: 0.04297\n",
      "epoch: [8], step: [273/377], batch loss: 1.80367, batch accuracy: 67.19, data load time: 0.00176, step time: 0.04226\n",
      "epoch: [8], step: [283/377], batch loss: 1.91898, batch accuracy: 60.16, data load time: 0.00173, step time: 0.04276\n",
      "epoch: [8], step: [293/377], batch loss: 1.32167, batch accuracy: 72.66, data load time: 0.00166, step time: 0.04263\n",
      "epoch: [8], step: [303/377], batch loss: 1.78279, batch accuracy: 66.41, data load time: 0.00167, step time: 0.04253\n",
      "epoch: [8], step: [313/377], batch loss: 1.73998, batch accuracy: 66.41, data load time: 0.00169, step time: 0.04245\n",
      "epoch: [8], step: [323/377], batch loss: 2.08288, batch accuracy: 59.38, data load time: 0.00170, step time: 0.04269\n",
      "epoch: [8], step: [333/377], batch loss: 1.88647, batch accuracy: 62.50, data load time: 0.00168, step time: 0.04288\n",
      "epoch: [8], step: [343/377], batch loss: 1.41502, batch accuracy: 73.44, data load time: 0.00165, step time: 0.04262\n",
      "epoch: [8], step: [353/377], batch loss: 1.63456, batch accuracy: 67.97, data load time: 0.00170, step time: 0.04252\n",
      "epoch: [8], step: [363/377], batch loss: 1.66765, batch accuracy: 67.19, data load time: 0.00170, step time: 0.04251\n",
      "epoch: [8], step: [373/377], batch loss: 2.02829, batch accuracy: 60.16, data load time: 0.00214, step time: 0.04261\n",
      "epoch: [9], step: [6/377], batch loss: 1.47402, batch accuracy: 72.66, data load time: 0.00178, step time: 0.04264\n",
      "epoch: [9], step: [16/377], batch loss: 1.77555, batch accuracy: 64.06, data load time: 0.00174, step time: 0.04240\n",
      "epoch: [9], step: [26/377], batch loss: 1.54511, batch accuracy: 66.41, data load time: 0.00169, step time: 0.04279\n",
      "epoch: [9], step: [36/377], batch loss: 1.62252, batch accuracy: 67.97, data load time: 0.00166, step time: 0.04292\n",
      "epoch: [9], step: [46/377], batch loss: 1.40118, batch accuracy: 70.31, data load time: 0.00198, step time: 0.04245\n",
      "epoch: [9], step: [56/377], batch loss: 1.64852, batch accuracy: 67.97, data load time: 0.00176, step time: 0.04264\n",
      "epoch: [9], step: [66/377], batch loss: 1.39669, batch accuracy: 71.09, data load time: 0.00174, step time: 0.04267\n",
      "epoch: [9], step: [76/377], batch loss: 1.45739, batch accuracy: 70.31, data load time: 0.00169, step time: 0.04269\n",
      "epoch: [9], step: [86/377], batch loss: 1.56094, batch accuracy: 68.75, data load time: 0.00168, step time: 0.04245\n",
      "epoch: [9], step: [96/377], batch loss: 1.46839, batch accuracy: 67.19, data load time: 0.00161, step time: 0.04302\n",
      "epoch: [9], step: [106/377], batch loss: 1.40694, batch accuracy: 71.09, data load time: 0.00166, step time: 0.04241\n",
      "epoch: [9], step: [116/377], batch loss: 1.64437, batch accuracy: 67.97, data load time: 0.00166, step time: 0.04251\n",
      "epoch: [9], step: [126/377], batch loss: 1.60518, batch accuracy: 65.62, data load time: 0.00164, step time: 0.04256\n",
      "epoch: [9], step: [136/377], batch loss: 1.83942, batch accuracy: 66.41, data load time: 0.00166, step time: 0.04279\n",
      "epoch: [9], step: [146/377], batch loss: 1.45878, batch accuracy: 72.66, data load time: 0.00165, step time: 0.04263\n",
      "epoch: [9], step: [156/377], batch loss: 1.52430, batch accuracy: 69.53, data load time: 0.00168, step time: 0.04252\n",
      "epoch: [9], step: [166/377], batch loss: 1.69583, batch accuracy: 66.41, data load time: 0.00183, step time: 0.04257\n",
      "epoch: [9], step: [176/377], batch loss: 1.83002, batch accuracy: 63.28, data load time: 0.00179, step time: 0.04273\n",
      "epoch: [9], step: [186/377], batch loss: 1.72064, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04253\n",
      "epoch: [9], step: [196/377], batch loss: 1.71776, batch accuracy: 62.50, data load time: 0.00185, step time: 0.04258\n",
      "epoch: [9], step: [206/377], batch loss: 1.75414, batch accuracy: 65.62, data load time: 0.00161, step time: 0.04262\n",
      "epoch: [9], step: [216/377], batch loss: 1.42432, batch accuracy: 73.44, data load time: 0.00171, step time: 0.04295\n",
      "epoch: [9], step: [226/377], batch loss: 1.87473, batch accuracy: 66.41, data load time: 0.00174, step time: 0.04244\n",
      "epoch: [9], step: [236/377], batch loss: 1.48432, batch accuracy: 69.53, data load time: 0.00160, step time: 0.04268\n",
      "epoch: [9], step: [246/377], batch loss: 1.62872, batch accuracy: 71.09, data load time: 0.00160, step time: 0.04290\n",
      "epoch: [9], step: [256/377], batch loss: 1.54998, batch accuracy: 68.75, data load time: 0.00174, step time: 0.04250\n",
      "epoch: [9], step: [266/377], batch loss: 1.69925, batch accuracy: 65.62, data load time: 0.00161, step time: 0.04250\n",
      "epoch: [9], step: [276/377], batch loss: 1.40960, batch accuracy: 71.09, data load time: 0.00156, step time: 0.04264\n",
      "epoch: [9], step: [286/377], batch loss: 1.59148, batch accuracy: 70.31, data load time: 0.00159, step time: 0.04275\n",
      "epoch: [9], step: [296/377], batch loss: 1.44166, batch accuracy: 72.66, data load time: 0.00169, step time: 0.04272\n",
      "epoch: [9], step: [306/377], batch loss: 1.60298, batch accuracy: 67.97, data load time: 0.00176, step time: 0.04241\n",
      "epoch: [9], step: [316/377], batch loss: 1.86581, batch accuracy: 61.72, data load time: 0.00178, step time: 0.04266\n",
      "epoch: [9], step: [326/377], batch loss: 1.69899, batch accuracy: 68.75, data load time: 0.00158, step time: 0.04283\n",
      "epoch: [9], step: [336/377], batch loss: 1.72770, batch accuracy: 65.62, data load time: 0.00182, step time: 0.04253\n",
      "epoch: [9], step: [346/377], batch loss: 1.84739, batch accuracy: 63.28, data load time: 0.00164, step time: 0.04246\n",
      "epoch: [9], step: [356/377], batch loss: 1.82340, batch accuracy: 60.94, data load time: 0.00171, step time: 0.04295\n",
      "epoch: [9], step: [366/377], batch loss: 1.55462, batch accuracy: 68.75, data load time: 0.00180, step time: 0.04278\n",
      "epoch: [9], step: [376/377], batch loss: 1.32768, batch accuracy: 73.08, data load time: 0.00216, step time: 0.01815\n",
      "epoch: [10], step: [9/377], batch loss: 1.81491, batch accuracy: 66.41, data load time: 0.00180, step time: 0.04321\n",
      "epoch: [10], step: [19/377], batch loss: 1.55926, batch accuracy: 67.97, data load time: 0.00161, step time: 0.04277\n",
      "epoch: [10], step: [29/377], batch loss: 1.78639, batch accuracy: 64.06, data load time: 0.00171, step time: 0.04247\n",
      "epoch: [10], step: [39/377], batch loss: 1.65238, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04261\n",
      "epoch: [10], step: [49/377], batch loss: 1.45968, batch accuracy: 71.88, data load time: 0.00160, step time: 0.04270\n",
      "epoch: [10], step: [59/377], batch loss: 1.42049, batch accuracy: 70.31, data load time: 0.00177, step time: 0.04249\n",
      "epoch: [10], step: [69/377], batch loss: 1.68181, batch accuracy: 68.75, data load time: 0.00162, step time: 0.04243\n",
      "epoch: [10], step: [79/377], batch loss: 1.92635, batch accuracy: 62.50, data load time: 0.00161, step time: 0.04259\n",
      "epoch: [10], step: [89/377], batch loss: 1.90790, batch accuracy: 62.50, data load time: 0.00163, step time: 0.04294\n",
      "epoch: [10], step: [99/377], batch loss: 1.51819, batch accuracy: 65.62, data load time: 0.00165, step time: 0.04273\n",
      "epoch: [10], step: [109/377], batch loss: 1.78170, batch accuracy: 63.28, data load time: 0.00162, step time: 0.04246\n",
      "epoch: [10], step: [119/377], batch loss: 1.69049, batch accuracy: 64.06, data load time: 0.00182, step time: 0.04260\n",
      "epoch: [10], step: [129/377], batch loss: 1.37905, batch accuracy: 72.66, data load time: 0.00172, step time: 0.04291\n",
      "epoch: [10], step: [139/377], batch loss: 1.55052, batch accuracy: 70.31, data load time: 0.00161, step time: 0.04266\n",
      "epoch: [10], step: [149/377], batch loss: 1.47168, batch accuracy: 69.53, data load time: 0.00183, step time: 0.04286\n",
      "epoch: [10], step: [159/377], batch loss: 1.83243, batch accuracy: 62.50, data load time: 0.00156, step time: 0.04281\n",
      "epoch: [10], step: [169/377], batch loss: 1.98879, batch accuracy: 60.94, data load time: 0.00170, step time: 0.04254\n",
      "epoch: [10], step: [179/377], batch loss: 1.88983, batch accuracy: 63.28, data load time: 0.00169, step time: 0.04240\n",
      "epoch: [10], step: [189/377], batch loss: 1.90888, batch accuracy: 63.28, data load time: 0.00176, step time: 0.04297\n",
      "epoch: [10], step: [199/377], batch loss: 1.49083, batch accuracy: 70.31, data load time: 0.00156, step time: 0.04279\n",
      "epoch: [10], step: [209/377], batch loss: 1.51591, batch accuracy: 70.31, data load time: 0.00169, step time: 0.04242\n",
      "epoch: [10], step: [219/377], batch loss: 1.47525, batch accuracy: 75.78, data load time: 0.00179, step time: 0.04260\n",
      "epoch: [10], step: [229/377], batch loss: 1.68408, batch accuracy: 67.97, data load time: 0.00175, step time: 0.04399\n",
      "epoch: [10], step: [239/377], batch loss: 1.65035, batch accuracy: 69.53, data load time: 0.00176, step time: 0.04264\n",
      "epoch: [10], step: [249/377], batch loss: 1.72423, batch accuracy: 67.19, data load time: 0.00169, step time: 0.04260\n",
      "epoch: [10], step: [259/377], batch loss: 1.75295, batch accuracy: 65.62, data load time: 0.00165, step time: 0.04264\n",
      "epoch: [10], step: [269/377], batch loss: 1.29510, batch accuracy: 70.31, data load time: 0.00160, step time: 0.04262\n",
      "epoch: [10], step: [279/377], batch loss: 1.76604, batch accuracy: 64.06, data load time: 0.00171, step time: 0.04260\n",
      "epoch: [10], step: [289/377], batch loss: 2.10691, batch accuracy: 56.25, data load time: 0.00169, step time: 0.04241\n",
      "epoch: [10], step: [299/377], batch loss: 1.50895, batch accuracy: 67.97, data load time: 0.00180, step time: 0.04259\n",
      "epoch: [10], step: [309/377], batch loss: 1.51210, batch accuracy: 68.75, data load time: 0.00179, step time: 0.04309\n",
      "epoch: [10], step: [319/377], batch loss: 1.45648, batch accuracy: 70.31, data load time: 0.00171, step time: 0.04395\n",
      "epoch: [10], step: [329/377], batch loss: 1.55169, batch accuracy: 70.31, data load time: 0.00155, step time: 0.04246\n",
      "epoch: [10], step: [339/377], batch loss: 1.82444, batch accuracy: 65.62, data load time: 0.00158, step time: 0.04267\n",
      "epoch: [10], step: [349/377], batch loss: 1.73111, batch accuracy: 63.28, data load time: 0.00173, step time: 0.04283\n",
      "epoch: [10], step: [359/377], batch loss: 1.69867, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04250\n",
      "epoch: [10], step: [369/377], batch loss: 1.90060, batch accuracy: 63.28, data load time: 0.00167, step time: 0.04284\n",
      "epoch: [11], step: [2/377], batch loss: 1.73960, batch accuracy: 64.84, data load time: 0.00177, step time: 0.04263\n",
      "epoch: [11], step: [12/377], batch loss: 1.85631, batch accuracy: 60.94, data load time: 0.00163, step time: 0.04258\n",
      "epoch: [11], step: [22/377], batch loss: 1.71303, batch accuracy: 63.28, data load time: 0.00165, step time: 0.04256\n",
      "epoch: [11], step: [32/377], batch loss: 1.72131, batch accuracy: 66.41, data load time: 0.00160, step time: 0.04238\n",
      "epoch: [11], step: [42/377], batch loss: 1.55228, batch accuracy: 67.19, data load time: 0.00176, step time: 0.04270\n",
      "epoch: [11], step: [52/377], batch loss: 1.66674, batch accuracy: 67.19, data load time: 0.00168, step time: 0.04271\n",
      "epoch: [11], step: [62/377], batch loss: 1.55584, batch accuracy: 66.41, data load time: 0.00170, step time: 0.04268\n",
      "epoch: [11], step: [72/377], batch loss: 1.10960, batch accuracy: 75.78, data load time: 0.00179, step time: 0.04263\n",
      "epoch: [11], step: [82/377], batch loss: 1.63822, batch accuracy: 67.97, data load time: 0.00163, step time: 0.04262\n",
      "epoch: [11], step: [92/377], batch loss: 2.11289, batch accuracy: 61.72, data load time: 0.00159, step time: 0.04280\n",
      "epoch: [11], step: [102/377], batch loss: 1.57621, batch accuracy: 69.53, data load time: 0.00180, step time: 0.04251\n",
      "epoch: [11], step: [112/377], batch loss: 1.76980, batch accuracy: 67.19, data load time: 0.00181, step time: 0.04272\n",
      "epoch: [11], step: [122/377], batch loss: 1.65870, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04268\n",
      "epoch: [11], step: [132/377], batch loss: 1.44704, batch accuracy: 71.09, data load time: 0.00185, step time: 0.04276\n",
      "epoch: [11], step: [142/377], batch loss: 1.57623, batch accuracy: 69.53, data load time: 0.00164, step time: 0.04247\n",
      "epoch: [11], step: [152/377], batch loss: 1.85386, batch accuracy: 62.50, data load time: 0.00165, step time: 0.04288\n",
      "epoch: [11], step: [162/377], batch loss: 1.62243, batch accuracy: 70.31, data load time: 0.00167, step time: 0.04310\n",
      "epoch: [11], step: [172/377], batch loss: 1.79749, batch accuracy: 65.62, data load time: 0.00185, step time: 0.04254\n",
      "epoch: [11], step: [182/377], batch loss: 1.45458, batch accuracy: 70.31, data load time: 0.00157, step time: 0.04281\n",
      "epoch: [11], step: [192/377], batch loss: 1.88850, batch accuracy: 62.50, data load time: 0.00190, step time: 0.04282\n",
      "epoch: [11], step: [202/377], batch loss: 1.79788, batch accuracy: 67.19, data load time: 0.00175, step time: 0.04265\n",
      "epoch: [11], step: [212/377], batch loss: 1.55865, batch accuracy: 67.19, data load time: 0.00172, step time: 0.04369\n",
      "epoch: [11], step: [222/377], batch loss: 1.50066, batch accuracy: 68.75, data load time: 0.00177, step time: 0.04266\n",
      "epoch: [11], step: [232/377], batch loss: 1.82010, batch accuracy: 63.28, data load time: 0.00174, step time: 0.04289\n",
      "epoch: [11], step: [242/377], batch loss: 1.69596, batch accuracy: 64.84, data load time: 0.00167, step time: 0.04298\n",
      "epoch: [11], step: [252/377], batch loss: 2.05239, batch accuracy: 59.38, data load time: 0.00161, step time: 0.04259\n",
      "epoch: [11], step: [262/377], batch loss: 1.94181, batch accuracy: 63.28, data load time: 0.00178, step time: 0.04289\n",
      "epoch: [11], step: [272/377], batch loss: 1.56145, batch accuracy: 68.75, data load time: 0.00165, step time: 0.04262\n",
      "epoch: [11], step: [282/377], batch loss: 1.62884, batch accuracy: 67.97, data load time: 0.00170, step time: 0.04257\n",
      "epoch: [11], step: [292/377], batch loss: 2.03698, batch accuracy: 59.38, data load time: 0.00195, step time: 0.04275\n",
      "epoch: [11], step: [302/377], batch loss: 1.33249, batch accuracy: 71.09, data load time: 0.00177, step time: 0.04369\n",
      "epoch: [11], step: [312/377], batch loss: 1.40842, batch accuracy: 68.75, data load time: 0.00171, step time: 0.04254\n",
      "epoch: [11], step: [322/377], batch loss: 1.44021, batch accuracy: 70.31, data load time: 0.00175, step time: 0.04249\n",
      "epoch: [11], step: [332/377], batch loss: 1.54649, batch accuracy: 68.75, data load time: 0.00167, step time: 0.04288\n",
      "epoch: [11], step: [342/377], batch loss: 1.70471, batch accuracy: 65.62, data load time: 0.00162, step time: 0.04309\n",
      "epoch: [11], step: [352/377], batch loss: 2.11224, batch accuracy: 59.38, data load time: 0.00167, step time: 0.04259\n",
      "epoch: [11], step: [362/377], batch loss: 1.62652, batch accuracy: 65.62, data load time: 0.00164, step time: 0.04257\n",
      "epoch: [11], step: [372/377], batch loss: 1.60787, batch accuracy: 67.19, data load time: 0.00163, step time: 0.04271\n",
      "epoch: [12], step: [5/377], batch loss: 1.82183, batch accuracy: 64.84, data load time: 0.00165, step time: 0.04315\n",
      "epoch: [12], step: [15/377], batch loss: 2.01870, batch accuracy: 60.16, data load time: 0.00169, step time: 0.04419\n",
      "epoch: [12], step: [25/377], batch loss: 1.83450, batch accuracy: 62.50, data load time: 0.00162, step time: 0.04271\n",
      "epoch: [12], step: [35/377], batch loss: 2.09410, batch accuracy: 62.50, data load time: 0.00166, step time: 0.04290\n",
      "epoch: [12], step: [45/377], batch loss: 1.49231, batch accuracy: 69.53, data load time: 0.00164, step time: 0.04249\n",
      "epoch: [12], step: [55/377], batch loss: 1.16666, batch accuracy: 75.78, data load time: 0.00167, step time: 0.04255\n",
      "epoch: [12], step: [65/377], batch loss: 1.72930, batch accuracy: 64.84, data load time: 0.00156, step time: 0.04269\n",
      "epoch: [12], step: [75/377], batch loss: 1.96173, batch accuracy: 61.72, data load time: 0.00161, step time: 0.04306\n",
      "epoch: [12], step: [85/377], batch loss: 1.82572, batch accuracy: 63.28, data load time: 0.00171, step time: 0.04248\n",
      "epoch: [12], step: [95/377], batch loss: 1.74233, batch accuracy: 62.50, data load time: 0.00184, step time: 0.04275\n",
      "epoch: [12], step: [105/377], batch loss: 1.35421, batch accuracy: 73.44, data load time: 0.00169, step time: 0.04453\n",
      "epoch: [12], step: [115/377], batch loss: 1.73060, batch accuracy: 64.06, data load time: 0.00160, step time: 0.04278\n",
      "epoch: [12], step: [125/377], batch loss: 1.18479, batch accuracy: 75.00, data load time: 0.00166, step time: 0.04254\n",
      "epoch: [12], step: [135/377], batch loss: 1.71456, batch accuracy: 70.31, data load time: 0.00167, step time: 0.04298\n",
      "epoch: [12], step: [145/377], batch loss: 1.65256, batch accuracy: 67.19, data load time: 0.00156, step time: 0.04293\n",
      "epoch: [12], step: [155/377], batch loss: 1.66190, batch accuracy: 65.62, data load time: 0.00172, step time: 0.04242\n",
      "epoch: [12], step: [165/377], batch loss: 1.52037, batch accuracy: 70.31, data load time: 0.00167, step time: 0.04269\n",
      "epoch: [12], step: [175/377], batch loss: 1.63264, batch accuracy: 67.97, data load time: 0.00170, step time: 0.04283\n",
      "epoch: [12], step: [185/377], batch loss: 1.72053, batch accuracy: 67.19, data load time: 0.00167, step time: 0.04259\n",
      "epoch: [12], step: [195/377], batch loss: 1.94723, batch accuracy: 63.28, data load time: 0.00165, step time: 0.04361\n",
      "epoch: [12], step: [205/377], batch loss: 1.54194, batch accuracy: 69.53, data load time: 0.00172, step time: 0.04272\n",
      "epoch: [12], step: [215/377], batch loss: 1.61326, batch accuracy: 67.97, data load time: 0.00165, step time: 0.04300\n",
      "epoch: [12], step: [225/377], batch loss: 1.56330, batch accuracy: 69.53, data load time: 0.00169, step time: 0.04248\n",
      "epoch: [12], step: [235/377], batch loss: 1.57639, batch accuracy: 69.53, data load time: 0.00172, step time: 0.04248\n",
      "epoch: [12], step: [245/377], batch loss: 1.77984, batch accuracy: 66.41, data load time: 0.00161, step time: 0.04277\n",
      "epoch: [12], step: [255/377], batch loss: 1.73391, batch accuracy: 64.84, data load time: 0.00167, step time: 0.04297\n",
      "epoch: [12], step: [265/377], batch loss: 1.45290, batch accuracy: 71.09, data load time: 0.00179, step time: 0.04260\n",
      "epoch: [12], step: [275/377], batch loss: 1.38470, batch accuracy: 71.88, data load time: 0.00171, step time: 0.04263\n",
      "epoch: [12], step: [285/377], batch loss: 1.76228, batch accuracy: 64.84, data load time: 0.00156, step time: 0.04379\n",
      "epoch: [12], step: [295/377], batch loss: 1.53405, batch accuracy: 67.97, data load time: 0.00167, step time: 0.04254\n",
      "epoch: [12], step: [305/377], batch loss: 1.48088, batch accuracy: 72.66, data load time: 0.00164, step time: 0.04258\n",
      "epoch: [12], step: [315/377], batch loss: 1.34194, batch accuracy: 75.00, data load time: 0.00171, step time: 0.04311\n",
      "epoch: [12], step: [325/377], batch loss: 2.03893, batch accuracy: 61.72, data load time: 0.00170, step time: 0.04252\n",
      "epoch: [12], step: [335/377], batch loss: 1.55415, batch accuracy: 68.75, data load time: 0.00183, step time: 0.04242\n",
      "epoch: [12], step: [345/377], batch loss: 1.51522, batch accuracy: 70.31, data load time: 0.00157, step time: 0.04254\n",
      "epoch: [12], step: [355/377], batch loss: 1.55820, batch accuracy: 70.31, data load time: 0.00160, step time: 0.04300\n",
      "epoch: [12], step: [365/377], batch loss: 2.20896, batch accuracy: 57.81, data load time: 0.00166, step time: 0.04290\n",
      "epoch: [12], step: [375/377], batch loss: 1.69912, batch accuracy: 64.84, data load time: 0.00164, step time: 0.04407\n",
      "epoch: [13], step: [8/377], batch loss: 1.86289, batch accuracy: 61.72, data load time: 0.00178, step time: 0.04261\n",
      "epoch: [13], step: [18/377], batch loss: 1.73739, batch accuracy: 65.62, data load time: 0.00164, step time: 0.04301\n",
      "epoch: [13], step: [28/377], batch loss: 1.74183, batch accuracy: 66.41, data load time: 0.00165, step time: 0.04293\n",
      "epoch: [13], step: [38/377], batch loss: 1.98131, batch accuracy: 58.59, data load time: 0.00168, step time: 0.04268\n",
      "epoch: [13], step: [48/377], batch loss: 1.67187, batch accuracy: 67.97, data load time: 0.00180, step time: 0.04252\n",
      "epoch: [13], step: [58/377], batch loss: 1.70885, batch accuracy: 63.28, data load time: 0.00158, step time: 0.04272\n",
      "epoch: [13], step: [68/377], batch loss: 1.58624, batch accuracy: 66.41, data load time: 0.00158, step time: 0.04284\n",
      "epoch: [13], step: [78/377], batch loss: 1.78622, batch accuracy: 67.19, data load time: 0.00168, step time: 0.04289\n",
      "epoch: [13], step: [88/377], batch loss: 1.47331, batch accuracy: 68.75, data load time: 0.00172, step time: 0.04365\n",
      "epoch: [13], step: [98/377], batch loss: 1.47677, batch accuracy: 72.66, data load time: 0.00156, step time: 0.04278\n",
      "epoch: [13], step: [108/377], batch loss: 1.84100, batch accuracy: 60.94, data load time: 0.00170, step time: 0.04283\n",
      "epoch: [13], step: [118/377], batch loss: 1.72310, batch accuracy: 64.06, data load time: 0.00172, step time: 0.04264\n",
      "epoch: [13], step: [128/377], batch loss: 1.90215, batch accuracy: 64.06, data load time: 0.00166, step time: 0.04280\n",
      "epoch: [13], step: [138/377], batch loss: 1.31280, batch accuracy: 72.66, data load time: 0.00173, step time: 0.04258\n",
      "epoch: [13], step: [148/377], batch loss: 1.23237, batch accuracy: 74.22, data load time: 0.00162, step time: 0.04280\n",
      "epoch: [13], step: [158/377], batch loss: 1.74036, batch accuracy: 65.62, data load time: 0.00173, step time: 0.04273\n",
      "epoch: [13], step: [168/377], batch loss: 1.38377, batch accuracy: 74.22, data load time: 0.00180, step time: 0.04252\n",
      "epoch: [13], step: [178/377], batch loss: 1.53623, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04342\n",
      "epoch: [13], step: [188/377], batch loss: 1.83877, batch accuracy: 63.28, data load time: 0.00164, step time: 0.04275\n",
      "epoch: [13], step: [198/377], batch loss: 1.89191, batch accuracy: 64.06, data load time: 0.00154, step time: 0.04276\n",
      "epoch: [13], step: [208/377], batch loss: 1.33444, batch accuracy: 71.09, data load time: 0.00172, step time: 0.04258\n",
      "epoch: [13], step: [218/377], batch loss: 1.94010, batch accuracy: 62.50, data load time: 0.00166, step time: 0.04256\n",
      "epoch: [13], step: [228/377], batch loss: 1.57426, batch accuracy: 65.62, data load time: 0.00167, step time: 0.04259\n",
      "epoch: [13], step: [238/377], batch loss: 1.82119, batch accuracy: 63.28, data load time: 0.00155, step time: 0.04279\n",
      "epoch: [13], step: [248/377], batch loss: 1.27392, batch accuracy: 74.22, data load time: 0.00166, step time: 0.04257\n",
      "epoch: [13], step: [258/377], batch loss: 2.02456, batch accuracy: 61.72, data load time: 0.00180, step time: 0.04249\n",
      "epoch: [13], step: [268/377], batch loss: 1.97041, batch accuracy: 60.94, data load time: 0.00171, step time: 0.04424\n",
      "epoch: [13], step: [278/377], batch loss: 1.78522, batch accuracy: 67.19, data load time: 0.00166, step time: 0.04286\n",
      "epoch: [13], step: [288/377], batch loss: 1.39009, batch accuracy: 71.88, data load time: 0.00151, step time: 0.04270\n",
      "epoch: [13], step: [298/377], batch loss: 1.81093, batch accuracy: 61.72, data load time: 0.00178, step time: 0.04242\n",
      "epoch: [13], step: [308/377], batch loss: 1.77196, batch accuracy: 64.84, data load time: 0.00172, step time: 0.04272\n",
      "epoch: [13], step: [318/377], batch loss: 1.31634, batch accuracy: 70.31, data load time: 0.00160, step time: 0.04260\n",
      "epoch: [13], step: [328/377], batch loss: 1.79416, batch accuracy: 65.62, data load time: 0.00180, step time: 0.04247\n",
      "epoch: [13], step: [338/377], batch loss: 1.80138, batch accuracy: 64.84, data load time: 0.00173, step time: 0.04238\n",
      "epoch: [13], step: [348/377], batch loss: 1.71017, batch accuracy: 65.62, data load time: 0.00164, step time: 0.04270\n",
      "epoch: [13], step: [358/377], batch loss: 1.64431, batch accuracy: 65.62, data load time: 0.00164, step time: 0.04389\n",
      "epoch: [13], step: [368/377], batch loss: 2.04617, batch accuracy: 57.81, data load time: 0.00171, step time: 0.04259\n",
      "epoch: [14], step: [1/377], batch loss: 1.06103, batch accuracy: 79.69, data load time: 0.00163, step time: 0.04244\n",
      "epoch: [14], step: [11/377], batch loss: 1.34420, batch accuracy: 73.44, data load time: 0.00173, step time: 0.04277\n",
      "epoch: [14], step: [21/377], batch loss: 1.43800, batch accuracy: 71.88, data load time: 0.00169, step time: 0.04284\n",
      "epoch: [14], step: [31/377], batch loss: 1.66553, batch accuracy: 65.62, data load time: 0.00170, step time: 0.04285\n",
      "epoch: [14], step: [41/377], batch loss: 1.62627, batch accuracy: 65.62, data load time: 0.00169, step time: 0.04252\n",
      "epoch: [14], step: [51/377], batch loss: 1.50831, batch accuracy: 71.09, data load time: 0.00165, step time: 0.04245\n",
      "epoch: [14], step: [61/377], batch loss: 1.94859, batch accuracy: 62.50, data load time: 0.00166, step time: 0.04278\n",
      "epoch: [14], step: [71/377], batch loss: 1.87676, batch accuracy: 64.06, data load time: 0.00167, step time: 0.04426\n",
      "epoch: [14], step: [81/377], batch loss: 2.33271, batch accuracy: 55.47, data load time: 0.00173, step time: 0.04236\n",
      "epoch: [14], step: [91/377], batch loss: 1.29311, batch accuracy: 76.56, data load time: 0.00171, step time: 0.04257\n",
      "epoch: [14], step: [101/377], batch loss: 1.92225, batch accuracy: 60.94, data load time: 0.00162, step time: 0.04267\n",
      "epoch: [14], step: [111/377], batch loss: 1.45449, batch accuracy: 71.88, data load time: 0.00172, step time: 0.04304\n",
      "epoch: [14], step: [121/377], batch loss: 1.40207, batch accuracy: 70.31, data load time: 0.00174, step time: 0.04275\n",
      "epoch: [14], step: [131/377], batch loss: 1.44448, batch accuracy: 70.31, data load time: 0.00171, step time: 0.04257\n",
      "epoch: [14], step: [141/377], batch loss: 1.86963, batch accuracy: 61.72, data load time: 0.00174, step time: 0.04253\n",
      "epoch: [14], step: [151/377], batch loss: 1.67868, batch accuracy: 66.41, data load time: 0.00197, step time: 0.04261\n",
      "epoch: [14], step: [161/377], batch loss: 1.40509, batch accuracy: 73.44, data load time: 0.00176, step time: 0.04359\n",
      "epoch: [14], step: [171/377], batch loss: 1.66745, batch accuracy: 64.84, data load time: 0.00173, step time: 0.04272\n",
      "epoch: [14], step: [181/377], batch loss: 1.56264, batch accuracy: 69.53, data load time: 0.00182, step time: 0.04286\n",
      "epoch: [14], step: [191/377], batch loss: 1.64578, batch accuracy: 65.62, data load time: 0.00165, step time: 0.04297\n",
      "epoch: [14], step: [201/377], batch loss: 2.18349, batch accuracy: 57.03, data load time: 0.00171, step time: 0.04252\n",
      "epoch: [14], step: [211/377], batch loss: 1.90421, batch accuracy: 61.72, data load time: 0.00177, step time: 0.04258\n",
      "epoch: [14], step: [221/377], batch loss: 1.52337, batch accuracy: 68.75, data load time: 0.00169, step time: 0.04263\n",
      "epoch: [14], step: [231/377], batch loss: 1.27445, batch accuracy: 75.00, data load time: 0.00165, step time: 0.04279\n",
      "epoch: [14], step: [241/377], batch loss: 1.51791, batch accuracy: 71.88, data load time: 0.00167, step time: 0.04274\n",
      "epoch: [14], step: [251/377], batch loss: 1.82276, batch accuracy: 63.28, data load time: 0.00167, step time: 0.04378\n",
      "epoch: [14], step: [261/377], batch loss: 1.67564, batch accuracy: 66.41, data load time: 0.00163, step time: 0.04256\n",
      "epoch: [14], step: [271/377], batch loss: 1.77560, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04282\n",
      "epoch: [14], step: [281/377], batch loss: 1.74425, batch accuracy: 64.84, data load time: 0.00173, step time: 0.04268\n",
      "epoch: [14], step: [291/377], batch loss: 1.72361, batch accuracy: 64.84, data load time: 0.00231, step time: 0.04264\n",
      "epoch: [14], step: [301/377], batch loss: 1.59825, batch accuracy: 66.41, data load time: 0.00212, step time: 0.04281\n",
      "epoch: [14], step: [311/377], batch loss: 1.42551, batch accuracy: 71.09, data load time: 0.00184, step time: 0.04254\n",
      "epoch: [14], step: [321/377], batch loss: 1.66831, batch accuracy: 65.62, data load time: 0.00156, step time: 0.04243\n",
      "epoch: [14], step: [331/377], batch loss: 1.63220, batch accuracy: 68.75, data load time: 0.00236, step time: 0.04269\n",
      "epoch: [14], step: [341/377], batch loss: 1.34488, batch accuracy: 74.22, data load time: 0.00157, step time: 0.04403\n",
      "epoch: [14], step: [351/377], batch loss: 1.71986, batch accuracy: 66.41, data load time: 0.00165, step time: 0.04254\n",
      "epoch: [14], step: [361/377], batch loss: 2.02118, batch accuracy: 59.38, data load time: 0.00226, step time: 0.04275\n",
      "epoch: [14], step: [371/377], batch loss: 1.95153, batch accuracy: 61.72, data load time: 0.00163, step time: 0.04299\n",
      "epoch: [15], step: [4/377], batch loss: 1.95522, batch accuracy: 61.72, data load time: 0.00179, step time: 0.04281\n",
      "epoch: [15], step: [14/377], batch loss: 1.98163, batch accuracy: 57.81, data load time: 0.00165, step time: 0.04274\n",
      "epoch: [15], step: [24/377], batch loss: 1.62897, batch accuracy: 67.19, data load time: 0.00171, step time: 0.04296\n",
      "epoch: [15], step: [34/377], batch loss: 1.95603, batch accuracy: 64.06, data load time: 0.00181, step time: 0.04251\n",
      "epoch: [15], step: [44/377], batch loss: 1.61894, batch accuracy: 65.62, data load time: 0.00177, step time: 0.04241\n",
      "epoch: [15], step: [54/377], batch loss: 1.63472, batch accuracy: 64.84, data load time: 0.00173, step time: 0.04399\n",
      "epoch: [15], step: [64/377], batch loss: 1.75404, batch accuracy: 62.50, data load time: 0.00164, step time: 0.04278\n",
      "epoch: [15], step: [74/377], batch loss: 1.37458, batch accuracy: 72.66, data load time: 0.00173, step time: 0.04273\n",
      "epoch: [15], step: [84/377], batch loss: 2.18055, batch accuracy: 55.47, data load time: 0.00175, step time: 0.04242\n",
      "epoch: [15], step: [94/377], batch loss: 1.54431, batch accuracy: 68.75, data load time: 0.00177, step time: 0.04262\n",
      "epoch: [15], step: [104/377], batch loss: 1.72975, batch accuracy: 68.75, data load time: 0.00167, step time: 0.04264\n",
      "epoch: [15], step: [114/377], batch loss: 1.57318, batch accuracy: 70.31, data load time: 0.00170, step time: 0.04295\n",
      "epoch: [15], step: [124/377], batch loss: 1.68585, batch accuracy: 67.19, data load time: 0.00168, step time: 0.04236\n",
      "epoch: [15], step: [134/377], batch loss: 1.61188, batch accuracy: 66.41, data load time: 0.00186, step time: 0.04256\n",
      "epoch: [15], step: [144/377], batch loss: 1.41447, batch accuracy: 69.53, data load time: 0.00169, step time: 0.04408\n",
      "epoch: [15], step: [154/377], batch loss: 1.48050, batch accuracy: 66.41, data load time: 0.00169, step time: 0.04257\n",
      "epoch: [15], step: [164/377], batch loss: 1.81436, batch accuracy: 61.72, data load time: 0.00164, step time: 0.04248\n",
      "epoch: [15], step: [174/377], batch loss: 1.91724, batch accuracy: 60.16, data load time: 0.00170, step time: 0.04262\n",
      "epoch: [15], step: [184/377], batch loss: 1.66092, batch accuracy: 67.97, data load time: 0.00167, step time: 0.04256\n",
      "epoch: [15], step: [194/377], batch loss: 1.88526, batch accuracy: 62.50, data load time: 0.00169, step time: 0.04300\n",
      "epoch: [15], step: [204/377], batch loss: 1.80389, batch accuracy: 60.94, data load time: 0.00169, step time: 0.04236\n",
      "epoch: [15], step: [214/377], batch loss: 1.63394, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04248\n",
      "epoch: [15], step: [224/377], batch loss: 1.95716, batch accuracy: 62.50, data load time: 0.00167, step time: 0.04297\n",
      "epoch: [15], step: [234/377], batch loss: 1.84262, batch accuracy: 61.72, data load time: 0.00164, step time: 0.04427\n",
      "epoch: [15], step: [244/377], batch loss: 1.61347, batch accuracy: 68.75, data load time: 0.00176, step time: 0.04240\n",
      "epoch: [15], step: [254/377], batch loss: 1.67193, batch accuracy: 65.62, data load time: 0.00152, step time: 0.04237\n",
      "epoch: [15], step: [264/377], batch loss: 1.49528, batch accuracy: 71.88, data load time: 0.00166, step time: 0.04262\n",
      "epoch: [15], step: [274/377], batch loss: 1.92438, batch accuracy: 61.72, data load time: 0.00172, step time: 0.04258\n",
      "epoch: [15], step: [284/377], batch loss: 1.74848, batch accuracy: 64.06, data load time: 0.00178, step time: 0.04245\n",
      "epoch: [15], step: [294/377], batch loss: 1.75104, batch accuracy: 64.06, data load time: 0.00159, step time: 0.04244\n",
      "epoch: [15], step: [304/377], batch loss: 1.68608, batch accuracy: 66.41, data load time: 0.00168, step time: 0.04247\n",
      "epoch: [15], step: [314/377], batch loss: 1.35811, batch accuracy: 71.88, data load time: 0.00170, step time: 0.04282\n",
      "epoch: [15], step: [324/377], batch loss: 1.71133, batch accuracy: 68.75, data load time: 0.00194, step time: 0.04453\n",
      "epoch: [15], step: [334/377], batch loss: 1.90635, batch accuracy: 62.50, data load time: 0.00172, step time: 0.04260\n",
      "epoch: [15], step: [344/377], batch loss: 1.92939, batch accuracy: 61.72, data load time: 0.00175, step time: 0.04255\n",
      "epoch: [15], step: [354/377], batch loss: 1.48326, batch accuracy: 68.75, data load time: 0.00168, step time: 0.04269\n",
      "epoch: [15], step: [364/377], batch loss: 1.33563, batch accuracy: 73.44, data load time: 0.00171, step time: 0.04256\n",
      "epoch: [15], step: [374/377], batch loss: 1.79655, batch accuracy: 66.41, data load time: 0.00172, step time: 0.04234\n",
      "epoch: [16], step: [7/377], batch loss: 1.25991, batch accuracy: 75.78, data load time: 0.00162, step time: 0.04276\n",
      "epoch: [16], step: [17/377], batch loss: 1.77857, batch accuracy: 64.84, data load time: 0.00172, step time: 0.04253\n",
      "epoch: [16], step: [27/377], batch loss: 1.55376, batch accuracy: 69.53, data load time: 0.00169, step time: 0.04278\n",
      "epoch: [16], step: [37/377], batch loss: 1.35496, batch accuracy: 73.44, data load time: 0.00159, step time: 0.04392\n",
      "epoch: [16], step: [47/377], batch loss: 1.58599, batch accuracy: 68.75, data load time: 0.00173, step time: 0.04274\n",
      "epoch: [16], step: [57/377], batch loss: 1.83112, batch accuracy: 64.84, data load time: 0.00168, step time: 0.04261\n",
      "epoch: [16], step: [67/377], batch loss: 1.52722, batch accuracy: 67.97, data load time: 0.00166, step time: 0.04274\n",
      "epoch: [16], step: [77/377], batch loss: 1.76354, batch accuracy: 65.62, data load time: 0.00164, step time: 0.04254\n",
      "epoch: [16], step: [87/377], batch loss: 1.64082, batch accuracy: 67.97, data load time: 0.00174, step time: 0.04272\n",
      "epoch: [16], step: [97/377], batch loss: 2.14301, batch accuracy: 63.28, data load time: 0.00163, step time: 0.04267\n",
      "epoch: [16], step: [107/377], batch loss: 1.60999, batch accuracy: 69.53, data load time: 0.00173, step time: 0.04259\n",
      "epoch: [16], step: [117/377], batch loss: 2.06525, batch accuracy: 58.59, data load time: 0.00172, step time: 0.04258\n",
      "epoch: [16], step: [127/377], batch loss: 1.37018, batch accuracy: 73.44, data load time: 0.00170, step time: 0.04533\n",
      "epoch: [16], step: [137/377], batch loss: 2.11670, batch accuracy: 60.94, data load time: 0.00162, step time: 0.04256\n",
      "epoch: [16], step: [147/377], batch loss: 1.76157, batch accuracy: 67.19, data load time: 0.00180, step time: 0.04244\n",
      "epoch: [16], step: [157/377], batch loss: 1.94757, batch accuracy: 60.16, data load time: 0.00170, step time: 0.04261\n",
      "epoch: [16], step: [167/377], batch loss: 1.99527, batch accuracy: 60.94, data load time: 0.00165, step time: 0.04263\n",
      "epoch: [16], step: [177/377], batch loss: 1.62761, batch accuracy: 68.75, data load time: 0.00163, step time: 0.04255\n",
      "epoch: [16], step: [187/377], batch loss: 1.69726, batch accuracy: 64.06, data load time: 0.00161, step time: 0.04242\n",
      "epoch: [16], step: [197/377], batch loss: 1.67425, batch accuracy: 64.84, data load time: 0.00179, step time: 0.04285\n",
      "epoch: [16], step: [207/377], batch loss: 1.60825, batch accuracy: 71.88, data load time: 0.00174, step time: 0.04301\n",
      "epoch: [16], step: [217/377], batch loss: 1.77825, batch accuracy: 68.75, data load time: 0.00166, step time: 0.04417\n",
      "epoch: [16], step: [227/377], batch loss: 2.06173, batch accuracy: 58.59, data load time: 0.00173, step time: 0.04271\n",
      "epoch: [16], step: [237/377], batch loss: 2.15734, batch accuracy: 60.16, data load time: 0.00165, step time: 0.04265\n",
      "epoch: [16], step: [247/377], batch loss: 1.64142, batch accuracy: 67.97, data load time: 0.00167, step time: 0.04308\n",
      "epoch: [16], step: [257/377], batch loss: 2.40336, batch accuracy: 50.00, data load time: 0.00173, step time: 0.04262\n",
      "epoch: [16], step: [267/377], batch loss: 1.65004, batch accuracy: 64.06, data load time: 0.00177, step time: 0.04232\n",
      "epoch: [16], step: [277/377], batch loss: 1.77305, batch accuracy: 65.62, data load time: 0.00150, step time: 0.04268\n",
      "epoch: [16], step: [287/377], batch loss: 1.94014, batch accuracy: 63.28, data load time: 0.00177, step time: 0.04264\n",
      "epoch: [16], step: [297/377], batch loss: 1.76666, batch accuracy: 64.84, data load time: 0.00171, step time: 0.04263\n",
      "epoch: [16], step: [307/377], batch loss: 1.97789, batch accuracy: 62.50, data load time: 0.00169, step time: 0.04385\n",
      "epoch: [16], step: [317/377], batch loss: 1.27941, batch accuracy: 75.00, data load time: 0.00161, step time: 0.04251\n",
      "epoch: [16], step: [327/377], batch loss: 1.50317, batch accuracy: 71.09, data load time: 0.00167, step time: 0.04282\n",
      "epoch: [16], step: [337/377], batch loss: 1.59374, batch accuracy: 67.97, data load time: 0.00168, step time: 0.04256\n",
      "epoch: [16], step: [347/377], batch loss: 1.38046, batch accuracy: 72.66, data load time: 0.00163, step time: 0.04250\n",
      "epoch: [16], step: [357/377], batch loss: 1.52573, batch accuracy: 66.41, data load time: 0.00166, step time: 0.04249\n",
      "epoch: [16], step: [367/377], batch loss: 2.06525, batch accuracy: 62.50, data load time: 0.00176, step time: 0.04265\n",
      "epoch: [17], step: [0/377], batch loss: 1.72437, batch accuracy: 65.62, data load time: 0.00511, step time: 0.04293\n",
      "epoch: [17], step: [10/377], batch loss: 1.36096, batch accuracy: 71.09, data load time: 0.00179, step time: 0.04287\n",
      "epoch: [17], step: [20/377], batch loss: 1.78919, batch accuracy: 64.84, data load time: 0.00183, step time: 0.04402\n",
      "epoch: [17], step: [30/377], batch loss: 1.63455, batch accuracy: 67.19, data load time: 0.00175, step time: 0.04260\n",
      "epoch: [17], step: [40/377], batch loss: 1.89003, batch accuracy: 65.62, data load time: 0.00186, step time: 0.04266\n",
      "epoch: [17], step: [50/377], batch loss: 1.82296, batch accuracy: 64.06, data load time: 0.00186, step time: 0.04267\n",
      "epoch: [17], step: [60/377], batch loss: 1.67209, batch accuracy: 68.75, data load time: 0.00177, step time: 0.04259\n",
      "epoch: [17], step: [70/377], batch loss: 1.86546, batch accuracy: 64.06, data load time: 0.00176, step time: 0.04268\n",
      "epoch: [17], step: [80/377], batch loss: 1.37883, batch accuracy: 70.31, data load time: 0.00174, step time: 0.04244\n",
      "epoch: [17], step: [90/377], batch loss: 1.86461, batch accuracy: 60.94, data load time: 0.00179, step time: 0.04287\n",
      "epoch: [17], step: [100/377], batch loss: 1.81324, batch accuracy: 60.94, data load time: 0.00173, step time: 0.04276\n",
      "epoch: [17], step: [110/377], batch loss: 1.73055, batch accuracy: 68.75, data load time: 0.00172, step time: 0.04344\n",
      "epoch: [17], step: [120/377], batch loss: 1.95467, batch accuracy: 63.28, data load time: 0.00172, step time: 0.04252\n",
      "epoch: [17], step: [130/377], batch loss: 1.58911, batch accuracy: 67.97, data load time: 0.00162, step time: 0.04284\n",
      "epoch: [17], step: [140/377], batch loss: 1.78773, batch accuracy: 64.84, data load time: 0.00166, step time: 0.04246\n",
      "epoch: [17], step: [150/377], batch loss: 2.13296, batch accuracy: 58.59, data load time: 0.00170, step time: 0.04266\n",
      "epoch: [17], step: [160/377], batch loss: 1.28198, batch accuracy: 75.00, data load time: 0.00177, step time: 0.04271\n",
      "epoch: [17], step: [170/377], batch loss: 1.77262, batch accuracy: 64.06, data load time: 0.00178, step time: 0.04280\n",
      "epoch: [17], step: [180/377], batch loss: 1.56588, batch accuracy: 67.19, data load time: 0.00179, step time: 0.04297\n",
      "epoch: [17], step: [190/377], batch loss: 1.70700, batch accuracy: 66.41, data load time: 0.00181, step time: 0.04259\n",
      "epoch: [17], step: [200/377], batch loss: 1.79207, batch accuracy: 67.97, data load time: 0.00169, step time: 0.04408\n",
      "epoch: [17], step: [210/377], batch loss: 1.83116, batch accuracy: 63.28, data load time: 0.00161, step time: 0.04259\n",
      "epoch: [17], step: [220/377], batch loss: 1.79141, batch accuracy: 62.50, data load time: 0.00166, step time: 0.04251\n",
      "epoch: [17], step: [230/377], batch loss: 1.64099, batch accuracy: 67.19, data load time: 0.00189, step time: 0.04260\n",
      "epoch: [17], step: [240/377], batch loss: 1.95808, batch accuracy: 60.94, data load time: 0.00165, step time: 0.04281\n",
      "epoch: [17], step: [250/377], batch loss: 1.75538, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04247\n",
      "epoch: [17], step: [260/377], batch loss: 1.83659, batch accuracy: 61.72, data load time: 0.00152, step time: 0.04242\n",
      "epoch: [17], step: [270/377], batch loss: 1.41509, batch accuracy: 71.09, data load time: 0.00166, step time: 0.04264\n",
      "epoch: [17], step: [280/377], batch loss: 1.76267, batch accuracy: 65.62, data load time: 0.00163, step time: 0.04282\n",
      "epoch: [17], step: [290/377], batch loss: 1.72362, batch accuracy: 63.28, data load time: 0.00162, step time: 0.04345\n",
      "epoch: [17], step: [300/377], batch loss: 1.94176, batch accuracy: 60.16, data load time: 0.00164, step time: 0.04244\n",
      "epoch: [17], step: [310/377], batch loss: 1.59922, batch accuracy: 69.53, data load time: 0.00175, step time: 0.04269\n",
      "epoch: [17], step: [320/377], batch loss: 1.84989, batch accuracy: 61.72, data load time: 0.00181, step time: 0.04307\n",
      "epoch: [17], step: [330/377], batch loss: 1.55515, batch accuracy: 66.41, data load time: 0.00190, step time: 0.04248\n",
      "epoch: [17], step: [340/377], batch loss: 1.48239, batch accuracy: 69.53, data load time: 0.00168, step time: 0.04244\n",
      "epoch: [17], step: [350/377], batch loss: 1.78691, batch accuracy: 67.19, data load time: 0.00172, step time: 0.04260\n",
      "epoch: [17], step: [360/377], batch loss: 1.48173, batch accuracy: 69.53, data load time: 0.00177, step time: 0.04289\n",
      "epoch: [17], step: [370/377], batch loss: 1.47086, batch accuracy: 68.75, data load time: 0.00174, step time: 0.04254\n",
      "epoch: [18], step: [3/377], batch loss: 1.87364, batch accuracy: 62.50, data load time: 0.00172, step time: 0.04390\n",
      "epoch: [18], step: [13/377], batch loss: 1.26033, batch accuracy: 74.22, data load time: 0.00172, step time: 0.04283\n",
      "epoch: [18], step: [23/377], batch loss: 1.57000, batch accuracy: 69.53, data load time: 0.00174, step time: 0.04253\n",
      "epoch: [18], step: [33/377], batch loss: 1.65935, batch accuracy: 65.62, data load time: 0.00180, step time: 0.04237\n",
      "epoch: [18], step: [43/377], batch loss: 1.58607, batch accuracy: 66.41, data load time: 0.00175, step time: 0.04272\n",
      "epoch: [18], step: [53/377], batch loss: 1.89990, batch accuracy: 64.84, data load time: 0.00180, step time: 0.04285\n",
      "epoch: [18], step: [63/377], batch loss: 1.12345, batch accuracy: 75.00, data load time: 0.00169, step time: 0.04248\n",
      "epoch: [18], step: [73/377], batch loss: 1.82711, batch accuracy: 64.84, data load time: 0.00165, step time: 0.04256\n",
      "epoch: [18], step: [83/377], batch loss: 2.26056, batch accuracy: 57.03, data load time: 0.00175, step time: 0.04256\n",
      "epoch: [18], step: [93/377], batch loss: 1.55175, batch accuracy: 68.75, data load time: 0.00170, step time: 0.04408\n",
      "epoch: [18], step: [103/377], batch loss: 1.93932, batch accuracy: 63.28, data load time: 0.00173, step time: 0.04258\n",
      "epoch: [18], step: [113/377], batch loss: 1.87478, batch accuracy: 62.50, data load time: 0.00157, step time: 0.04266\n",
      "epoch: [18], step: [123/377], batch loss: 2.13362, batch accuracy: 59.38, data load time: 0.00179, step time: 0.04261\n",
      "epoch: [18], step: [133/377], batch loss: 1.73890, batch accuracy: 66.41, data load time: 0.00166, step time: 0.04286\n",
      "epoch: [18], step: [143/377], batch loss: 1.80219, batch accuracy: 65.62, data load time: 0.00168, step time: 0.04305\n",
      "epoch: [18], step: [153/377], batch loss: 2.07516, batch accuracy: 61.72, data load time: 0.00169, step time: 0.04252\n",
      "epoch: [18], step: [163/377], batch loss: 1.57174, batch accuracy: 67.19, data load time: 0.00164, step time: 0.04238\n",
      "epoch: [18], step: [173/377], batch loss: 1.83762, batch accuracy: 63.28, data load time: 0.00166, step time: 0.04254\n",
      "epoch: [18], step: [183/377], batch loss: 1.60456, batch accuracy: 67.19, data load time: 0.00164, step time: 0.04408\n",
      "epoch: [18], step: [193/377], batch loss: 1.62854, batch accuracy: 67.97, data load time: 0.00164, step time: 0.04295\n",
      "epoch: [18], step: [203/377], batch loss: 1.65389, batch accuracy: 67.97, data load time: 0.00174, step time: 0.04244\n",
      "epoch: [18], step: [213/377], batch loss: 1.50237, batch accuracy: 71.09, data load time: 0.00182, step time: 0.04266\n",
      "epoch: [18], step: [223/377], batch loss: 1.56695, batch accuracy: 67.19, data load time: 0.00168, step time: 0.04302\n",
      "epoch: [18], step: [233/377], batch loss: 2.19566, batch accuracy: 57.81, data load time: 0.00166, step time: 0.04254\n",
      "epoch: [18], step: [243/377], batch loss: 1.70862, batch accuracy: 64.06, data load time: 0.00177, step time: 0.04239\n",
      "epoch: [18], step: [253/377], batch loss: 1.67199, batch accuracy: 67.97, data load time: 0.00169, step time: 0.04258\n",
      "epoch: [18], step: [263/377], batch loss: 1.28421, batch accuracy: 75.78, data load time: 0.00180, step time: 0.04268\n",
      "epoch: [18], step: [273/377], batch loss: 1.79383, batch accuracy: 64.84, data load time: 0.00184, step time: 0.04379\n",
      "epoch: [18], step: [283/377], batch loss: 1.30518, batch accuracy: 74.22, data load time: 0.00170, step time: 0.04255\n",
      "epoch: [18], step: [293/377], batch loss: 1.94049, batch accuracy: 59.38, data load time: 0.00185, step time: 0.04297\n",
      "epoch: [18], step: [303/377], batch loss: 1.75656, batch accuracy: 66.41, data load time: 0.00171, step time: 0.04262\n",
      "epoch: [18], step: [313/377], batch loss: 1.48144, batch accuracy: 71.09, data load time: 0.00186, step time: 0.04255\n",
      "epoch: [18], step: [323/377], batch loss: 1.59778, batch accuracy: 67.97, data load time: 0.00185, step time: 0.04259\n",
      "epoch: [18], step: [333/377], batch loss: 1.61801, batch accuracy: 66.41, data load time: 0.00161, step time: 0.04309\n",
      "epoch: [18], step: [343/377], batch loss: 1.66886, batch accuracy: 67.97, data load time: 0.00160, step time: 0.04254\n",
      "epoch: [18], step: [353/377], batch loss: 1.62199, batch accuracy: 70.31, data load time: 0.00181, step time: 0.04246\n",
      "epoch: [18], step: [363/377], batch loss: 1.75874, batch accuracy: 67.19, data load time: 0.00157, step time: 0.04377\n",
      "epoch: [18], step: [373/377], batch loss: 1.50894, batch accuracy: 70.31, data load time: 0.00165, step time: 0.04310\n",
      "epoch: [19], step: [6/377], batch loss: 1.65665, batch accuracy: 67.97, data load time: 0.00166, step time: 0.04270\n",
      "epoch: [19], step: [16/377], batch loss: 1.96341, batch accuracy: 61.72, data load time: 0.00164, step time: 0.04257\n",
      "epoch: [19], step: [26/377], batch loss: 1.57273, batch accuracy: 69.53, data load time: 0.00167, step time: 0.04262\n",
      "epoch: [19], step: [36/377], batch loss: 1.87375, batch accuracy: 63.28, data load time: 0.00165, step time: 0.04267\n",
      "epoch: [19], step: [46/377], batch loss: 1.95622, batch accuracy: 61.72, data load time: 0.00169, step time: 0.04261\n",
      "epoch: [19], step: [56/377], batch loss: 1.85315, batch accuracy: 64.84, data load time: 0.00184, step time: 0.04243\n",
      "epoch: [19], step: [66/377], batch loss: 1.35234, batch accuracy: 72.66, data load time: 0.00166, step time: 0.04258\n",
      "epoch: [19], step: [76/377], batch loss: 1.73338, batch accuracy: 64.06, data load time: 0.00164, step time: 0.04417\n",
      "epoch: [19], step: [86/377], batch loss: 1.65680, batch accuracy: 67.19, data load time: 0.00168, step time: 0.04270\n",
      "epoch: [19], step: [96/377], batch loss: 1.89983, batch accuracy: 63.28, data load time: 0.00164, step time: 0.04242\n",
      "epoch: [19], step: [106/377], batch loss: 1.50261, batch accuracy: 68.75, data load time: 0.00170, step time: 0.04266\n",
      "epoch: [19], step: [116/377], batch loss: 1.70808, batch accuracy: 67.19, data load time: 0.00160, step time: 0.04267\n",
      "epoch: [19], step: [126/377], batch loss: 1.49305, batch accuracy: 71.09, data load time: 0.00159, step time: 0.04356\n",
      "epoch: [19], step: [136/377], batch loss: 1.33320, batch accuracy: 73.44, data load time: 0.00168, step time: 0.04298\n",
      "epoch: [19], step: [146/377], batch loss: 1.32919, batch accuracy: 71.88, data load time: 0.00186, step time: 0.04252\n",
      "epoch: [19], step: [156/377], batch loss: 1.56078, batch accuracy: 71.09, data load time: 0.00181, step time: 0.04284\n",
      "epoch: [19], step: [166/377], batch loss: 1.73722, batch accuracy: 67.19, data load time: 0.00188, step time: 0.04456\n",
      "epoch: [19], step: [176/377], batch loss: 1.77169, batch accuracy: 66.41, data load time: 0.00169, step time: 0.04275\n",
      "epoch: [19], step: [186/377], batch loss: 1.43665, batch accuracy: 69.53, data load time: 0.00163, step time: 0.04276\n",
      "epoch: [19], step: [196/377], batch loss: 1.59478, batch accuracy: 67.19, data load time: 0.00166, step time: 0.04299\n",
      "epoch: [19], step: [206/377], batch loss: 1.75834, batch accuracy: 63.28, data load time: 0.00166, step time: 0.04253\n",
      "epoch: [19], step: [216/377], batch loss: 1.67469, batch accuracy: 66.41, data load time: 0.00177, step time: 0.04270\n",
      "epoch: [19], step: [226/377], batch loss: 1.42896, batch accuracy: 69.53, data load time: 0.00172, step time: 0.04280\n",
      "epoch: [19], step: [236/377], batch loss: 1.58364, batch accuracy: 67.97, data load time: 0.00176, step time: 0.04248\n",
      "epoch: [19], step: [246/377], batch loss: 1.60318, batch accuracy: 65.62, data load time: 0.00159, step time: 0.04281\n",
      "epoch: [19], step: [256/377], batch loss: 1.70739, batch accuracy: 65.62, data load time: 0.00163, step time: 0.04384\n",
      "epoch: [19], step: [266/377], batch loss: 1.67415, batch accuracy: 64.84, data load time: 0.00177, step time: 0.04282\n",
      "epoch: [19], step: [276/377], batch loss: 1.58233, batch accuracy: 67.19, data load time: 0.00174, step time: 0.04248\n",
      "epoch: [19], step: [286/377], batch loss: 1.84072, batch accuracy: 64.84, data load time: 0.00176, step time: 0.04245\n",
      "epoch: [19], step: [296/377], batch loss: 1.76151, batch accuracy: 65.62, data load time: 0.00179, step time: 0.04259\n",
      "epoch: [19], step: [306/377], batch loss: 1.67097, batch accuracy: 66.41, data load time: 0.00165, step time: 0.04267\n",
      "epoch: [19], step: [316/377], batch loss: 1.32151, batch accuracy: 71.88, data load time: 0.00158, step time: 0.04258\n",
      "epoch: [19], step: [326/377], batch loss: 1.51035, batch accuracy: 70.31, data load time: 0.00170, step time: 0.04259\n",
      "epoch: [19], step: [336/377], batch loss: 1.82801, batch accuracy: 64.06, data load time: 0.00181, step time: 0.04288\n",
      "epoch: [19], step: [346/377], batch loss: 1.58041, batch accuracy: 66.41, data load time: 0.00167, step time: 0.04541\n",
      "epoch: [19], step: [356/377], batch loss: 1.70260, batch accuracy: 65.62, data load time: 0.00170, step time: 0.04248\n",
      "epoch: [19], step: [366/377], batch loss: 1.85930, batch accuracy: 60.94, data load time: 0.00170, step time: 0.04266\n",
      "epoch: [19], step: [376/377], batch loss: 1.76710, batch accuracy: 59.62, data load time: 0.00188, step time: 0.01835\n",
      "Finished training.\n",
      "\n",
      "TESTING MODEL\n",
      "AUC: 0.773740849937183 on test dataset\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'conduct.<locals>.CNN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     conduct()\n",
      "Cell \u001b[0;32mIn[11], line 751\u001b[0m, in \u001b[0;36mconduct\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    750\u001b[0m     args, _ \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_known_args()\n\u001b[0;32m--> 751\u001b[0m     main(args)\n",
      "Cell \u001b[0;32mIn[11], line 165\u001b[0m, in \u001b[0;36mconduct.<locals>.main\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_auc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon test dataset\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# save model locally in notebook for manual evaluation\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m checkpoint_model(model, \u001b[38;5;28mfloat\u001b[39m(test_auc))\n",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mcheckpoint_model\u001b[0;34m(model, test_auc)\u001b[0m\n\u001b[1;32m     11\u001b[0m old_test_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(file\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_auc \u001b[38;5;241m>\u001b[39m old_test_auc:\n\u001b[0;32m---> 14\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model, model_file_path)\n\u001b[1;32m     16\u001b[0m     file\u001b[38;5;241m.\u001b[39mtruncate(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m     file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda/3-2024/lib/python3.12/site-packages/torch/serialization.py:652\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 652\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda/3-2024/lib/python3.12/site-packages/torch/serialization.py:864\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    862\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    863\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 864\u001b[0m pickler\u001b[38;5;241m.\u001b[39mdump(obj)\n\u001b[1;32m    865\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    866\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'conduct.<locals>.CNN'"
     ]
    }
   ],
   "source": [
    "for _ in range(200):\n",
    "    conduct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23799f4b-7e50-4a82-8c46-54e56affb614",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eefa5dd-a923-4451-9e6b-d90487a2a6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 14:59:29.659069: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 14:59:29.666193: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-20 14:59:29.674779: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-20 14:59:29.677438: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 14:59:29.683849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-20 14:59:31.973371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import time\n",
    "from multiprocessing import cpu_count\n",
    "from typing import Union, NamedTuple\n",
    "\n",
    "from torch.utils import data\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.backends.cudnn\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision.datasets\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def crop_to_region(coords: Tuple[int], img: Tensor, crop_size: int=42) -> Tensor:\n",
    "    \"\"\" \n",
    "    Given coordinates in the form Tuple[int](y, x), return a cropped\n",
    "    sample of the input imaged centred at (y, x), matching the input size.\n",
    "    Args:\n",
    "        coords (Tuple[int]): The input coordinates (y, x) where the crop will be\n",
    "        centred.\n",
    "        img (Tensor): The input image, either 3x400x400, 3x250x250, 3x150x150\n",
    "        crop_size (int, optional): The size of the returned crop. Defaults to 42.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: The image cropped with central coordinates at (y, x) of size \n",
    "        (3 x size x size) # is size here referring to 42?\n",
    "    \"\"\"\n",
    "    _, H, W = img.shape\n",
    "    y, x = coords\n",
    "    y_min, x_min = max(0, y-crop_size//2), max(0, x-crop_size//2)\n",
    "    y_max, x_max = min(H, y+crop_size//2), min(W, x+crop_size//2)\n",
    "    region = img[:, y_min:y_max, x_min:x_max]\n",
    "    if region.shape[1] < crop_size:\n",
    "        to_pad = crop_size - region.shape[1]\n",
    "        padding = (0, 0, to_pad, 0) if (y-crop_size//2) < 0 else (0, 0, 0, to_pad)\n",
    "        region = F.pad(region, padding, mode='replicate')\n",
    "\n",
    "    if region.shape[2] < crop_size:\n",
    "        to_pad = crop_size - region.shape[2]\n",
    "        padding = (to_pad, 0, 0, 0) if (x-crop_size//2) < 0 else (0, to_pad, 0, 0)\n",
    "        region = F.pad(region, padding, mode='replicate')\n",
    "    return region\n",
    "\n",
    "class MIT(data.Dataset):\n",
    "    def __init__(self, dataset_path: str):\n",
    "        \"\"\"\n",
    "        Given the dataset path, create the MIT dataset. Creates the\n",
    "        variable self.dataset which is a list of dictionaries with three keys:\n",
    "            1) X: For train the crop of image. This is of shape [3, 3, 42, 42]. The \n",
    "                first dim represents the crop across each different scale\n",
    "                (400x400, 250x250, 150x150), the second dim is the colour\n",
    "                channels C, followed by H and W (42x42). For inference, this is \n",
    "                the full size image of shape [3, H, W].\n",
    "            2) y: The label for the crop. 1 = a fixation point, 0 = a\n",
    "                non-fixation point. -1 = Unlabelled i.e. val and test\n",
    "            3) file: The file name the crops were extracted from.\n",
    "            \n",
    "        If the dataset belongs to val or test, there are 4 additional keys:\n",
    "            1) X_400: The image resized to 400x400\n",
    "            2) X_250: The image resized to 250x250\n",
    "            3) X_150: The image resized to 150x150\n",
    "            4) spatial_coords: The centre coordinates of all 50x50 (2500) crops\n",
    "            \n",
    "        These additional keys help to load the different scales within the\n",
    "        dataloader itself in a timely manner. Precomputing all crops requires too\n",
    "        much storage for the lab machines, and resizing/cropping on the fly\n",
    "        slows down the dataloader, so this is a happy balance.\n",
    "        Args:\n",
    "            dataset_path (str): Path to train/val/test.pth.tar\n",
    "        \"\"\"\n",
    "        self.dataset = torch.load(dataset_path, weights_only=True)\n",
    "        self.mode = 'train' if 'train' in dataset_path else 'inference'\n",
    "        self.num_crops = 2500 if self.mode == 'inference' else 1\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[Tensor, int]:\n",
    "        \"\"\"\n",
    "        Given the index from the DataLoader, return the image crop(s) and label\n",
    "        Args:\n",
    "            index (int): the dataset index provided by the PyTorch DataLoader.\n",
    "        Returns:\n",
    "            Tuple[Tensor, int]: A two-element tuple consisting of: \n",
    "                1) img (Tensor): The image crop of shape [3, 3, 42, 42]. The \n",
    "                first dim represents the crop across each different scale\n",
    "                (400x400, 250x250, 150x150), the second dim is the colour\n",
    "                channels C, followed by H and W (42x42).\n",
    "                2) label (int): The label for this crop. 1 = a fixation point, \n",
    "                0 = a non-fixation point. -1 = Unlabelled i.e. val and test.\n",
    "        \"\"\"\n",
    "        sample_index = index // self.num_crops\n",
    "        # print(sample_index)\n",
    "        \n",
    "        img = self.dataset[sample_index]['X']\n",
    "        \n",
    "        # Inference crops are not precomputed due to file size, do here instead\n",
    "        if self.mode == 'inference': \n",
    "            _, H, W = img.shape\n",
    "            crop_index = index % self.num_crops\n",
    "            crop_y, crop_x = self.dataset[sample_index]['spatial_coords'][crop_index]\n",
    "            scales = []\n",
    "            for size in ['X_400', 'X_250', 'X_150']:\n",
    "                scaled_img = self.dataset[sample_index][size]\n",
    "                y_ratio, x_ratio = scaled_img.shape[1] / H, scaled_img.shape[2] / W\n",
    "                \n",
    "                # Need to rescale the crops central coordinate.\n",
    "                scaled_coords = (int(y_ratio * crop_y), int(x_ratio * crop_x))\n",
    "                crops = crop_to_region(scaled_coords, scaled_img)\n",
    "                scales.append(crops)\n",
    "            img = torch.stack(scales, axis=1)\n",
    "            \n",
    "        label = self.dataset[sample_index]['y']\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset (length of the list of dictionaries * number\n",
    "        of crops). \n",
    "        __len()__ always needs to be defined so that the DataLoader\n",
    "            can create the batches\n",
    "        Returns:\n",
    "            len(self.dataset) (int): the length of the list of dictionaries * number of\n",
    "            crops.\n",
    "        \"\"\"\n",
    "        return len(self.dataset) * self.num_crops\n",
    "\n",
    "\n",
    "trainingdata = MIT(\"data/train_data.pth.tar\")\n",
    "valdata = MIT(\"data/val_data.pth.tar\")\n",
    "testingdata = MIT(\"data/test_data.pth.tar\")\n",
    "\n",
    "\n",
    "class NormalisedDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# each element in self.dataset dictionary which has three components so just get X and y component (so X component 3x3x42x42 and y is label) -> inputs to the CNN\n",
    "\n",
    "\n",
    "# print(trainingdata.dataset[0]['y'])\n",
    "# print(trainingdata.dataset[0]['X'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc63d3a-0a34-44e6-b184-b08283151671",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f21bf8-99ea-4e38-826b-ce24a2fb3afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "0.01992413029074669 -0.003527479013428092 -0.011873003095388412 0.9579979777336121 0.948402464389801 0.9503791928291321\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "training_data_augmented = trainingdata.dataset * 2\n",
    "for i in range(len(trainingdata.dataset), len(training_data_augmented)):\n",
    "    training_data_augmented[i]['X'] = torch.flip(training_data_augmented[i]['X'], dims=[3])\n",
    "    \n",
    "print('done')\n",
    "\n",
    "red_channel = ([sample['X'][:, 0, :, :] for sample in training_data_augmented])\n",
    "blue_channel = ([sample['X'][:, 1, :, :] for sample in training_data_augmented])\n",
    "green_channel = ([sample['X'][:, 2, :, :] for sample in training_data_augmented])\n",
    "\n",
    "normalised_training_data = training_data_augmented\n",
    "\n",
    "# red channel is a list of 3x42x42 i.e each resolution 42x42 image only the red channel, likewise with the blue and green channel\n",
    "#so want the mean of the red channels, blue and green channel\n",
    "\n",
    "def channel_mean(x):\n",
    "    return (torch.stack(x).mean().item())\n",
    "\n",
    "def channel_std(x):\n",
    "    return (torch.stack(x).std().item())\n",
    "\n",
    "# def channel_mean(x):\n",
    "#     channel_sum = 0 # sum is 0 to begin with\n",
    "#     for i in range(0, len(x)): # go through each item in the list\n",
    "#         item = x[i] # extract 3x42x42 list\n",
    "#         for j in range(0, 3): # find the sum of each element of the 3x42x42 list and increment to the running sum\n",
    "#             for k in range(0, 42):\n",
    "#                 for l in range(0,42):\n",
    "#                     channel_sum += item[j][k][l].item()\n",
    "                    \n",
    "#     return (channel_sum / (len(x)*3*42*42)) # mean of x i.e. total of all values / number of values \n",
    "\n",
    "red_mean = channel_mean(red_channel)\n",
    "blue_mean = channel_mean(blue_channel)\n",
    "green_mean = channel_mean(green_channel)\n",
    "\n",
    "red_std = channel_std(red_channel)\n",
    "blue_std = channel_std(blue_channel)\n",
    "green_std = channel_std(green_channel)\n",
    "\n",
    "print(red_mean, blue_mean, green_mean, red_std, blue_std, green_std)\n",
    "\n",
    "for i in range(0, len(normalised_training_data)): # goes through the current list\n",
    "    training_data_X = normalised_training_data[i]['X'] # gets the 3x3x42x42 X\n",
    "    training_data_X[:,0,:,:] = (training_data_X[:,0,:,:] - red_mean) / red_std # gets red channel values and normalises them\n",
    "    training_data_X[:, 1, :,:] = (training_data_X[:,1,:,:] - blue_mean) / blue_std\n",
    "    training_data_X[:, 2, :,:] = (training_data_X[:,2,:,:] - green_mean) / green_std\n",
    "    \n",
    "    normalised_training_data[i]['X'] = training_data_X\n",
    "    #print('in loop')\n",
    "\n",
    "final_data = trainingdata\n",
    "final_data.dataset = normalised_training_data\n",
    "\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f40b1-d23e-421a-a990-c616abadc845",
   "metadata": {},
   "source": [
    "# Format Files and Generate Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30d8e222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 1024])\n",
      "torch.Size([3, 768, 1024])\n"
     ]
    }
   ],
   "source": [
    "# this code generates the ground truth dictionary for inference datasets indexed by file name (formatted so they end with _fixMap.jpg)\n",
    "# ensure the predictions dictionary matches this format for file name\n",
    "\n",
    "def format_file_name_fixMap_jpg(filename):\n",
    "    return f\"{filename[:-5]}_fixMap.jpg\"\n",
    "\n",
    "def get_filenames_fixMap_jpg(dataset: Dataset):\n",
    "    filenames = [format_file_name_fixMap_jpg(sample['file']) for sample in dataset]\n",
    "\n",
    "    return filenames\n",
    "\n",
    "def get_ground_truth_dict(dataset: Dataset):\n",
    "\n",
    "    filenames = get_filenames_fixMap_jpg(dataset)\n",
    "\n",
    "    ground_truth_dict = {}\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    for filename in filenames:\n",
    "        ground_truth_dict[filename] = transform(Image.open(f\"data/ALLFIXATIONMAPS/ALLFIXATIONMAPS/{filename}\")).squeeze() * 255\n",
    "    \n",
    "    return ground_truth_dict\n",
    "\n",
    "# to show usage\n",
    "# print(list(get_ground_truth_dict(get_filenames_fixMap_jpg(valdata.dataset)).values())[7].shape)\n",
    "\n",
    "val_ground_truth_dict = get_ground_truth_dict(valdata.dataset)\n",
    "test_ground_truth_dict = get_ground_truth_dict(testingdata.dataset)\n",
    "\n",
    "print(list(get_ground_truth_dict(valdata.dataset).values())[0].shape)\n",
    "print(valdata.dataset[0]['X'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d864ff8-c958-4638-8da8-89f9cff73ff1",
   "metadata": {},
   "source": [
    "# Define ROC-AUC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ed7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics code\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "\n",
    "def roc_auc(pred, target, n_points=20, include_prior=False):\n",
    "        \"\"\"\n",
    "        Calculates the Reciever-Operating-Characteristic (ROC) area under\n",
    "        the curve (AUC) by numerical integration.\n",
    "        \"\"\"\n",
    "\n",
    "        target = np.array(target)/255\n",
    "                \n",
    "        # generated = pred\n",
    "        # changed above comment line to below one as above was throwing error\n",
    "        generated = np.array(pred)\n",
    "        # min max normalisation\n",
    "        generated = (generated - generated.min())/(generated.max() - generated.min())\n",
    "\n",
    "        def roc(p=0.1):\n",
    "            x = generated.reshape(-1) > p\n",
    "            t = target.reshape(-1) > p\n",
    "\n",
    "            return np.sum(x==t)/len(t)\n",
    "\n",
    "        calculate_roc = np.vectorize(roc)\n",
    "\n",
    "        x = np.linspace(0, 1, n_points)\n",
    "        auc = simpson(calculate_roc(x))/n_points\n",
    "\n",
    "        return auc\n",
    "\n",
    "def calculate_auc(preds, targets):\n",
    "\t\"\"\"\n",
    "\tinputs -- 2 dictionary with prediction and target images. The 2 dictionaries have the  same number of keys, where each key identifies a unique image. \n",
    "\tThe predictions have the predicted fixation maps while the targets have the ground truth fixation maps which are available from \"https://people.csail.mit.edu/tjudd/WherePeopleLook/\" \n",
    "\t\"\"\"\n",
    "\tassert preds.keys() == targets.keys()\n",
    "\tmean_auc = 0\n",
    "\tfor key in preds.keys():\n",
    "\t\tmean_auc += roc_auc(preds[key], targets[key])\n",
    "\tmean_auc /= len(preds.keys())\n",
    "\treturn mean_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaca6d5",
   "metadata": {},
   "source": [
    "# Model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6264845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = \"./model/model.pth\"\n",
    "score_file_path = \"./model/test_score\"\n",
    "\n",
    "def checkpoint_model(model, test_auc):\n",
    "\n",
    "    path = Path(score_file_path)  # Path to the file you want to check\n",
    "\n",
    "    if path.exists():\n",
    "        with open(score_file_path, 'r+', encoding='utf-8') as file:\n",
    "            \n",
    "            old_test_auc = float(file.read().strip())\n",
    "\n",
    "            if test_auc > old_test_auc:\n",
    "                torch.save(model, model_file_path)\n",
    "                \n",
    "                file.truncate(0)\n",
    "                file.seek(0)\n",
    "                file.write(str(test_auc))\n",
    "    else:\n",
    "        torch.save(model, model_file_path)\n",
    "    \n",
    "        with open(score_file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(str(test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af4c64-fa95-4185-bfbe-0122c83914ae",
   "metadata": {},
   "source": [
    "# Initialise and Train Mr-CNN\n",
    "\n",
    "### To see logs:\n",
    "module load anaconda \\\n",
    "pip install tensorboard \\\n",
    "python3 -m tensorboard.main --logdir=./logs \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98698d5-be75-4d86-842e-9916707cba5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset_root=PosixPath('/home/qz21635/.cache/torch/datasets'), log_dir=PosixPath('logs'), learning_rate=0.0002, batch_size=128, epochs=20, val_frequency=4, log_frequency=10, print_frequency=10, worker_count=0, sgd_momentum=0, data_aug_hflip=False)\n",
      "Writing logs to logs/CNN_bn_bs=128_lr=0.0002_momentum=0.9_run_31\n",
      "About to train...\n",
      "epoch: [0], step: [9/377], batch loss: 1.00034, batch accuracy: 53.12, data load time: 0.00183, step time: 0.04394\n",
      "epoch: [0], step: [19/377], batch loss: 0.94298, batch accuracy: 54.69, data load time: 0.00174, step time: 0.04287\n",
      "epoch: [0], step: [29/377], batch loss: 0.97710, batch accuracy: 57.03, data load time: 0.00184, step time: 0.04423\n",
      "epoch: [0], step: [39/377], batch loss: 1.01382, batch accuracy: 49.22, data load time: 0.00193, step time: 0.04311\n",
      "epoch: [0], step: [49/377], batch loss: 0.92732, batch accuracy: 57.03, data load time: 0.00188, step time: 0.04514\n",
      "epoch: [0], step: [59/377], batch loss: 0.97269, batch accuracy: 50.00, data load time: 0.00188, step time: 0.04386\n",
      "epoch: [0], step: [69/377], batch loss: 0.97739, batch accuracy: 52.34, data load time: 0.00196, step time: 0.04359\n",
      "epoch: [0], step: [79/377], batch loss: 1.00452, batch accuracy: 47.66, data load time: 0.00177, step time: 0.04330\n",
      "epoch: [0], step: [89/377], batch loss: 0.86461, batch accuracy: 57.81, data load time: 0.00165, step time: 0.04436\n",
      "epoch: [0], step: [99/377], batch loss: 0.93182, batch accuracy: 47.66, data load time: 0.00168, step time: 0.04303\n",
      "epoch: [0], step: [109/377], batch loss: 0.96491, batch accuracy: 53.12, data load time: 0.00180, step time: 0.04510\n",
      "epoch: [0], step: [119/377], batch loss: 0.90040, batch accuracy: 57.03, data load time: 0.00175, step time: 0.04312\n",
      "epoch: [0], step: [129/377], batch loss: 1.03272, batch accuracy: 47.66, data load time: 0.00179, step time: 0.04459\n",
      "epoch: [0], step: [139/377], batch loss: 0.93623, batch accuracy: 56.25, data load time: 0.00189, step time: 0.04356\n",
      "epoch: [0], step: [149/377], batch loss: 1.08162, batch accuracy: 46.09, data load time: 0.00181, step time: 0.04457\n",
      "epoch: [0], step: [159/377], batch loss: 1.11059, batch accuracy: 42.19, data load time: 0.00172, step time: 0.04360\n",
      "epoch: [0], step: [169/377], batch loss: 0.98023, batch accuracy: 53.12, data load time: 0.00189, step time: 0.04472\n",
      "epoch: [0], step: [179/377], batch loss: 0.93327, batch accuracy: 52.34, data load time: 0.00171, step time: 0.04432\n",
      "epoch: [0], step: [189/377], batch loss: 1.02290, batch accuracy: 49.22, data load time: 0.00180, step time: 0.04413\n",
      "epoch: [0], step: [199/377], batch loss: 0.88177, batch accuracy: 58.59, data load time: 0.00156, step time: 0.04486\n",
      "epoch: [0], step: [209/377], batch loss: 1.07533, batch accuracy: 43.75, data load time: 0.00194, step time: 0.04352\n",
      "epoch: [0], step: [219/377], batch loss: 0.83471, batch accuracy: 61.72, data load time: 0.00178, step time: 0.04514\n",
      "epoch: [0], step: [229/377], batch loss: 0.91453, batch accuracy: 57.81, data load time: 0.00176, step time: 0.04358\n",
      "epoch: [0], step: [239/377], batch loss: 0.87626, batch accuracy: 57.81, data load time: 0.00170, step time: 0.04405\n",
      "epoch: [0], step: [249/377], batch loss: 1.00184, batch accuracy: 47.66, data load time: 0.00188, step time: 0.04353\n",
      "epoch: [0], step: [259/377], batch loss: 0.90917, batch accuracy: 53.12, data load time: 0.00193, step time: 0.04461\n",
      "epoch: [0], step: [269/377], batch loss: 0.99185, batch accuracy: 45.31, data load time: 0.00186, step time: 0.04344\n",
      "epoch: [0], step: [279/377], batch loss: 1.14447, batch accuracy: 39.84, data load time: 0.00176, step time: 0.04397\n",
      "epoch: [0], step: [289/377], batch loss: 0.91630, batch accuracy: 49.22, data load time: 0.00179, step time: 0.04495\n",
      "epoch: [0], step: [299/377], batch loss: 1.12767, batch accuracy: 41.41, data load time: 0.00175, step time: 0.04316\n",
      "epoch: [0], step: [309/377], batch loss: 1.00676, batch accuracy: 50.00, data load time: 0.00187, step time: 0.04475\n",
      "epoch: [0], step: [319/377], batch loss: 0.93749, batch accuracy: 56.25, data load time: 0.00167, step time: 0.04259\n",
      "epoch: [0], step: [329/377], batch loss: 1.04526, batch accuracy: 53.12, data load time: 0.00190, step time: 0.04417\n",
      "epoch: [0], step: [339/377], batch loss: 0.96883, batch accuracy: 53.12, data load time: 0.00188, step time: 0.04384\n",
      "epoch: [0], step: [349/377], batch loss: 0.95394, batch accuracy: 53.12, data load time: 0.00180, step time: 0.04434\n",
      "epoch: [0], step: [359/377], batch loss: 1.08422, batch accuracy: 46.88, data load time: 0.00165, step time: 0.04488\n",
      "epoch: [0], step: [369/377], batch loss: 1.03623, batch accuracy: 47.66, data load time: 0.00162, step time: 0.04344\n",
      "Finished training.\n",
      "\n",
      "TESTING MODEL\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 755\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    754\u001b[0m     args, _ \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_known_args()\n\u001b[0;32m--> 755\u001b[0m     main(args)\n",
      "Cell \u001b[0;32mIn[42], line 161\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m worth_it:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTESTING MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m     test_auc \u001b[38;5;241m=\u001b[39m test_model(model, testingdata, test_ground_truth_dict, DEVICE)\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_auc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon test dataset\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# save model locally in notebook for manual evaluation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 695\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, dataMIT, ground_truth_dict, device)\u001b[0m\n\u001b[1;32m    691\u001b[0m batch \u001b[38;5;241m=\u001b[39m img_crops[j \u001b[38;5;241m*\u001b[39m batch_size:(j \u001b[38;5;241m*\u001b[39m batch_size) \u001b[38;5;241m+\u001b[39m batch_size,:,:,:,:]\n\u001b[1;32m    693\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 695\u001b[0m preds \u001b[38;5;241m=\u001b[39m sigmoid(model(batch)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m))\n\u001b[1;32m    696\u001b[0m \u001b[38;5;66;03m# preds = (preds > 0.5).float()\u001b[39;00m\n\u001b[1;32m    697\u001b[0m preds_rows\u001b[38;5;241m.\u001b[39mappend(preds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Train a simple CNN on CIFAR-10\",\n",
    "    formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    ")\n",
    "default_dataset_dir = Path.home() / \".cache\" / \"torch\" / \"datasets\"\n",
    "parser.add_argument(\"--dataset-root\", default=default_dataset_dir)\n",
    "parser.add_argument(\"--log-dir\", default=Path(\"logs\"), type=Path)\n",
    "parser.add_argument(\"--learning-rate\", default=2e-4, type=float, help=\"Learning rate\")\n",
    "parser.add_argument(\n",
    "    \"--batch-size\",\n",
    "    default=128,\n",
    "    type=int,\n",
    "    help=\"Number of images within each mini-batch\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--epochs\",\n",
    "    default=20,\n",
    "    type=int,\n",
    "    help=\"Number of epochs (passes through the entire dataset) to train for\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--val-frequency\",\n",
    "    default=4,\n",
    "    type=int,\n",
    "    help=\"How frequently to test the model on the validation set in number of epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--log-frequency\",\n",
    "    default=10,\n",
    "    type=int,\n",
    "    help=\"How frequently to save logs to tensorboard in number of steps\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--print-frequency\",\n",
    "    default=10,\n",
    "    type=int,\n",
    "    help=\"How frequently to print progress to the command line in number of steps\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-j\",\n",
    "    \"--worker-count\",\n",
    "    default=0, #cpu_count(), #note make this 0 if not using lab machine\n",
    "    type=int,\n",
    "    help=\"Number of worker processes used to load data.\",\n",
    ")\n",
    "parser.add_argument(\"--sgd-momentum\", default=0, type=float)\n",
    "parser.add_argument(\"--data-aug-hflip\", action=\"store_true\")\n",
    "\n",
    "\n",
    "\n",
    "class ImageShape(NamedTuple):\n",
    "    height: int\n",
    "    width: int\n",
    "    channels: int\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# to save and manually evaluate trained model\n",
    "trained_model = 0\n",
    "test_auc_score = 0\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    for i in range(200):\n",
    "        # # Stack X tensors and extract y values\n",
    "        # X_train = torch.stack([sample['X'] for sample in trainingdata.dataset])\n",
    "        # y_train = torch.tensor([sample['y'] for sample in trainingdata.dataset])\n",
    "\n",
    "        # # Calculate mean and std for normalization\n",
    "        # mean_train = X_train.view(X_train.size(0), X_train.size(1), -1).mean(dim=(0, 2))\n",
    "        # std_train = X_train.view(X_train.size(0), X_train.size(1), -1).std(dim=(0, 2))\n",
    "\n",
    "        # # Normalize X_train\n",
    "        # normalised_X_train = (X_train - mean_train[None, :, None, None]) / std_train[None, :, None, None]\n",
    "\n",
    "        # # Create the custom dataset\n",
    "        # normalised_trainingdata = NormalisedDataset(normalised_X_train, y_train)\n",
    "\n",
    "        # Pass the dataset into DataLoader\n",
    "        # train_loader = DataLoader(normalised_trainingdata, batch_size=128, shuffle=True)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            final_data, #trainingdata,#normalised_trainingdata,\n",
    "            shuffle=True,\n",
    "            batch_size=args.batch_size,\n",
    "            pin_memory=True,\n",
    "            num_workers=args.worker_count,\n",
    "        )\n",
    "\n",
    "        ######################\n",
    "        \n",
    "        print(args)\n",
    "        \n",
    "        args.dataset_root.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "\n",
    "        # if False:\n",
    "        #     train_dataset = None #torchvision.datasets.CIFAR10(args.dataset_root, train=True, download=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]))\n",
    "        # else:\n",
    "        #     train_dataset = trainingdata #normalised_trainingdata # torchvision.datasets.CIFAR10(args.dataset_root, train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "        test_dataset = testingdata.dataset #torchvision.datasets.CIFAR10(args.dataset_root, train=False, download=False, transform=transforms.ToTensor())\n",
    "        \n",
    "        \n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            shuffle=False,\n",
    "            batch_size=args.batch_size,\n",
    "            num_workers=args.worker_count,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        model = CNN(height=42, width=42, channels=3, class_count=2)\n",
    "\n",
    "        # for torchviz visualisation of architecture\n",
    "        dummy_input = torch.randn(1, 3, 3, 42, 42)\n",
    "\n",
    "        output = model(dummy_input)\n",
    "\n",
    "        graph = make_dot(output, params=dict(model.named_parameters()))\n",
    "\n",
    "        # Save or render the graph\n",
    "        graph.render(\"cnn_graph_merged\", format=\"png\")  # Save as PNG\n",
    "\n",
    "        ## TASK 8: Redefine the criterion to be softmax cross entropy\n",
    "        #criterion = nn.CrossEntropyLoss()\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        ## TASK 11: Define the optimizer\n",
    "        # optimizer = None #torch.optim.SGD(model.parameters(), lr=args.learning_rate, momentum=args.sgd_momentum)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args.learning_rate, momentum=args.sgd_momentum)\n",
    "\n",
    "        log_dir = get_summary_writer_log_dir(args)\n",
    "        print(f\"Writing logs to {log_dir}\")\n",
    "        summary_writer = SummaryWriter(\n",
    "                str(log_dir),\n",
    "                flush_secs=5\n",
    "        )\n",
    "        trainer = Trainer(\n",
    "            model, train_loader, test_loader, criterion, optimizer, summary_writer, DEVICE\n",
    "        )\n",
    "\n",
    "        print(\"About to train...\")\n",
    "        worth_it = trainer.train(\n",
    "            args.epochs,\n",
    "            args.val_frequency,\n",
    "            print_frequency=args.print_frequency,\n",
    "            log_frequency=args.log_frequency,\n",
    "        )\n",
    "        print(\"Finished training.\")\n",
    "        summary_writer.close()\n",
    "\n",
    "        if worth_it:\n",
    "            print(\"\\nTESTING MODEL\")\n",
    "            test_auc = test_model(model, testingdata, test_ground_truth_dict, DEVICE)\n",
    "            print(\"AUC:\", test_auc, \"on test dataset\\n\")\n",
    "\n",
    "            # save model locally in notebook for manual evaluation\n",
    "            checkpoint_model(model, float(test_auc))\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, height: int, width: int, channels: int, class_count: int):\n",
    "        super().__init__()\n",
    "        self.input_shape = ImageShape(height=height, width=width, channels=channels)\n",
    "        self.class_count = class_count\n",
    "\n",
    "        # Define 1st Conv, Pool, and BatchNorm\n",
    "        \n",
    "        # Conv 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=self.input_shape.channels,\n",
    "            out_channels=96,\n",
    "            kernel_size=(7, 7),\n",
    "            padding= (0,0), #(2, 2),\n",
    "        )\n",
    "        self.initialise_layer(self.conv1)\n",
    "        \n",
    "        # Pool 1\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # BatchNorm 1\n",
    "        self.batchnorm1 = nn.BatchNorm2d(self.conv1.out_channels)\n",
    "\n",
    "        # Define 2nd Conv, Pool, and BatchNorm\n",
    "        \n",
    "        # Conv 2\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=96,\n",
    "            out_channels=160,\n",
    "            kernel_size=(3, 3),\n",
    "            padding= (0,0) #(2, 2)\n",
    "        )\n",
    "\n",
    "        self.initialise_layer(self.conv2)\n",
    "        \n",
    "        # Pool 2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # BatchNorm 2\n",
    "        self.batchnorm2 = nn.BatchNorm2d(num_features=self.conv2.out_channels)\n",
    "        \n",
    "        # Define 3rd Conv, Pool, and BatchNorm\n",
    "        \n",
    "        # Conv 3\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=160,\n",
    "            out_channels=288,\n",
    "            kernel_size=(3, 3),\n",
    "            padding= (0,0) #(2, 2)\n",
    "        )\n",
    "\n",
    "        self.initialise_layer(self.conv3)\n",
    "        \n",
    "        # Pool 3\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "        # BatchNorm 3\n",
    "        self.batchnorm3 = nn.BatchNorm2d(num_features=self.conv3.out_channels)\n",
    "\n",
    "        \n",
    "        # Define FC 1\n",
    "\n",
    "        self.fc1 = nn.Linear(2592, 512)\n",
    "        self.initialise_layer(self.fc1)\n",
    "\n",
    "        # BatchNorm layer after first FC layer\n",
    "        # import pdb; pdb.set_trace()\n",
    "        self.batchnorm4 = nn.BatchNorm1d(num_features=self.fc1.out_features)\n",
    "\n",
    "        \n",
    "        # Define FC 2\n",
    "\n",
    "        # self.fc2 = nn.Linear(1536, 512)\n",
    "        self.fc2 = nn.Linear(1536, 512)\n",
    "\n",
    "        self.initialise_layer(self.fc2)\n",
    "\n",
    "        # BatchNorm layer after second FC layer\n",
    "\n",
    "        self.batchnorm5 = nn.BatchNorm1d(num_features=self.fc2.out_features)\n",
    "        \n",
    "        # Define FC 3\n",
    "\n",
    "        self.fc3 = nn.Linear(512, 1)\n",
    "        self.initialise_layer(self.fc3)\n",
    "\n",
    "        # BatchNorm layer after third FC layer\n",
    "        self.batchnorm6 = nn.BatchNorm1d(num_features=self.fc3.out_features)\n",
    "    \n",
    "    # FORWARD METHOD for running 3 parallel CNNs\n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "#####\n",
    "        # #images = images.reshape(-1, 3, 42, 42)\n",
    "        # images1 = images[:, 0, :, :, :]\n",
    "        \n",
    "        # #pass first resolutions through the network\n",
    "        # x1 = F.relu(self.conv1(images1))\n",
    "        # x1 = self.pool1(x1)\n",
    "        # # x1 = self.batchnorm1(x1)\n",
    "\n",
    "        # x1 = F.relu(self.conv2(x1))\n",
    "        # x1 = self.pool2(x1)\n",
    "        # # x1 = self.batchnorm2(x1)\n",
    "        \n",
    "        # x1 = F.relu(self.conv3(x1))\n",
    "        # x1 = self.pool3(x1)\n",
    "        # # x1 = self.batchnorm3(x1)\n",
    "\n",
    "        # # Flatten the output of the pooling layer so it is of shape (batch_size, 4096)\n",
    "        # x1 = torch.flatten(x1, start_dim=1)\n",
    "        \n",
    "        # # Pass x through the first fully connected layer\n",
    "        # x1 = F.relu(self.fc1(x1))\n",
    "        # # x1 = self.batchnorm4(x1)\n",
    "        \n",
    "        # images2 = images[:, 1, :, :, :]\n",
    "        \n",
    "        # #pass second resolutions through the network\n",
    "        # x2 = F.relu(self.conv1(images2))\n",
    "        # x2 = self.pool1(x2)\n",
    "        # # x2 = self.batchnorm1(x2)\n",
    "\n",
    "        # x2 = F.relu(self.conv2(x2))\n",
    "        # x2 = self.pool2(x2)\n",
    "        # # x2 = self.batchnorm2(x2)\n",
    "        \n",
    "        # x2 = F.relu(self.conv3(x2))\n",
    "        # x2 = self.pool3(x2)\n",
    "        # # x2 = self.batchnorm3(x2)\n",
    "\n",
    "        # # Flatten the output of the pooling layer so it is of shape (batch_size, 4096)\n",
    "        # x2 = torch.flatten(x2, start_dim=1)\n",
    "        \n",
    "        # # Pass x through the first fully connected layer\n",
    "        # x2 = F.relu(self.fc1(x2))\n",
    "        # # x2 = self.batchnorm4(x2)\n",
    "        \n",
    "        \n",
    "        # images3 = images[:, 2, :, :, :]\n",
    "        \n",
    "        # #pass third resolutions through the network\n",
    "        # x3 = F.relu(self.conv1(images3))\n",
    "        # x3 = self.pool1(x3)\n",
    "        # # x3 = self.batchnorm1(x3)\n",
    "\n",
    "        # x3 = F.relu(self.conv2(x3))\n",
    "        # x3 = self.pool2(x3)\n",
    "        # # x3 = self.batchnorm2(x3)\n",
    "        \n",
    "        # x3 = F.relu(self.conv3(x3))\n",
    "        # x3 = self.pool3(x3)\n",
    "        # # x3 = self.batchnorm3(x3)\n",
    "\n",
    "        # # Flatten the output of the pooling layer so it is of shape (batch_size, 4096)\n",
    "        # x3 = torch.flatten(x3, start_dim=1)\n",
    "        \n",
    "        # # Pass x through the first fully connected layer\n",
    "        # x3 = F.relu(self.fc1(x3))\n",
    "        # # x3 = self.batchnorm4(x3)\n",
    "        \n",
    "        \n",
    "        # ## TASK 6-2: Pass x through the last fully connected layer\n",
    "        # #IMPORTANT: concatenate fc layers before next steps\n",
    "        # xCat = torch.cat((x1, x2, x3), dim=1)\n",
    "#######\n",
    "        # print(images.shape)\n",
    "\n",
    "        batch_size = images.shape[0]\n",
    "\n",
    "        images = images.reshape(-1, 3, 42, 42)\n",
    "        \n",
    "        x = F.relu(self.conv1(images))\n",
    "        x = self.pool1(x)\n",
    "        # x = self.batchnorm1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        # x = self.batchnorm2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        # x = self.batchnorm3(x)\n",
    "\n",
    "        # x = x.reshape(-1, 3, 42, 42)\n",
    "\n",
    "        # Flatten the output of the pooling layer so it is of shape (batch_size, 4096)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # print(x.shape)\n",
    "        \n",
    "        # Pass x through the first fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.batchnorm4(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "        # print(len(x))\n",
    "        # import sys; sys.exit(1)\n",
    "\n",
    "        x = x.reshape(batch_size, -1)\n",
    "\n",
    "\n",
    "        # x = self.fc2(xCat)\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        # x = self.batchnorm5(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        #x = self.batchnorm6(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def initialise_layer(layer):\n",
    "        if hasattr(layer, \"bias\"):\n",
    "            nn.init.zeros_(layer.bias)\n",
    "        if hasattr(layer, \"weight\"):\n",
    "            nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        criterion: nn.Module,\n",
    "        optimizer: Optimizer,\n",
    "        summary_writer: SummaryWriter,\n",
    "        device: torch.device,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.summary_writer = summary_writer\n",
    "        self.step = 0\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        epochs: int,\n",
    "        val_frequency: int,\n",
    "        print_frequency: int = 20,\n",
    "        log_frequency: int = 5,\n",
    "        start_epoch: int = 0\n",
    "    ):\n",
    "        self.model.train()\n",
    "        \n",
    "        worth_it_counter = 0\n",
    "        \n",
    "        #import sys; sys.exit(1)\n",
    "        # for epoch in range(start_epoch, 5):\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "\n",
    "            if worth_it_counter > 10:\n",
    "                print(\"\\nExitting this train since accuracy too low:\", accuracy)\n",
    "                return False\n",
    "\n",
    "            self.model.train()\n",
    "            \n",
    "            data_load_start_time = time.time()\n",
    "\n",
    "            epoch_accuracy = 0\n",
    "            epoch_loss = 0\n",
    "\n",
    "            for batch, labels in self.train_loader:\n",
    "                \n",
    "                batch = batch.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                data_load_end_time = time.time()\n",
    "\n",
    "                # print(type(batch))\n",
    "                # print(batch.shape)\n",
    "                # print(type(labels))\n",
    "                # print(labels[0])\n",
    "                # import sys; sys.exit(1)\n",
    "\n",
    "\n",
    "                ## TASK 1: Compute the forward pass of the model, print the output shape\n",
    "                ##         and quit the program\n",
    "                logits = self.model.forward(batch).squeeze()\n",
    "                #print(logits.shape)\n",
    "                                        \n",
    "                #import sys; sys.exit(1)\n",
    "\n",
    "                ## TASK 7: Rename `output` to `logits`, remove the output shape printing\n",
    "                ##         and get rid of the `import sys; sys.exit(1)`\n",
    "\n",
    "                # Task 7 done above\n",
    "\n",
    "                ## TASK 9: Compute the loss using self.criterion and\n",
    "                ##         store it in a variable called `loss`\n",
    "\n",
    "                loss = self.criterion(logits, labels.float())\n",
    "\n",
    "                ## TASK 10: Compute the backward pass\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                ## TASK 12: Step the optimizer and then zero out the gradient buffers.\n",
    "                \n",
    "                #self.optimizer.step()\n",
    "\n",
    "                #self.optimizer.zero_grad()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    preds = (logits > 0.5).float()\n",
    "                    accuracy = compute_accuracy(labels, preds)\n",
    "                \n",
    "                if accuracy < 0.5:\n",
    "                    worth_it_counter += 1\n",
    "\n",
    "                data_load_time = data_load_end_time - data_load_start_time\n",
    "                step_time = time.time() - data_load_end_time\n",
    "                if ((self.step + 1) % log_frequency) == 0:\n",
    "                    self.log_metrics(epoch, accuracy, loss, data_load_time, step_time)\n",
    "                if ((self.step + 1) % print_frequency) == 0:\n",
    "                    self.print_metrics(epoch, accuracy, loss, data_load_time, step_time)\n",
    "\n",
    "                self.step += 1\n",
    "                data_load_start_time = time.time()\n",
    "\n",
    "                epoch_accuracy += accuracy\n",
    "                epoch_loss += loss\n",
    "\n",
    "            # log epoch accuracy and epoch loss\n",
    "            epoch_accuracy /= self.train_loader.batch_size\n",
    "            epoch_loss /= self.train_loader.batch_size\n",
    "            self.summary_writer.add_scalar(\"epoch_accuracy\", epoch_accuracy, self.step)\n",
    "            self.summary_writer.add_scalar(\"epoch_loss\", epoch_loss, self.step)\n",
    "\n",
    "            self.summary_writer.add_scalar(\"epoch\", epoch, self.step)\n",
    "            # if ((epoch + 1) % val_frequency) == 0:\n",
    "            # HARDCODED VAL FREQUENCY FOR DEBUGGING\n",
    "            if ((epoch + 1) % 21) == 0:\n",
    "\n",
    "                val_auc = self.validate()\n",
    "                # log val auc\n",
    "                self.summary_writer.add_scalar(\"val_auc\", val_auc, self.step)\n",
    "                # import sys; sys.exit(1)\n",
    "                # self.validate() will put the model in validation mode,\n",
    "                # so we have to switch back to train mode afterwards\n",
    "                self.model.train()\n",
    "            \n",
    "            # if epoch == 3:\n",
    "            #     self.validate()\n",
    "            #     self.model.train()\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def print_metrics(self, epoch, accuracy, loss, data_load_time, step_time):\n",
    "        epoch_step = self.step % len(self.train_loader)\n",
    "        print(\n",
    "                f\"epoch: [{epoch}], \"\n",
    "                f\"step: [{epoch_step}/{len(self.train_loader)}], \"\n",
    "                f\"batch loss: {loss:.5f}, \"\n",
    "                f\"batch accuracy: {accuracy * 100:2.2f}, \"\n",
    "                f\"data load time: \"\n",
    "                f\"{data_load_time:.5f}, \"\n",
    "                f\"step time: {step_time:.5f}\"\n",
    "        )\n",
    "\n",
    "    def log_metrics(self, epoch, accuracy, loss, data_load_time, step_time):\n",
    "        self.summary_writer.add_scalar(\"epoch\", epoch, self.step)\n",
    "        self.summary_writer.add_scalars(\n",
    "                \"accuracy\",\n",
    "                {\"train\": accuracy},\n",
    "                self.step\n",
    "        )\n",
    "        self.summary_writer.add_scalars(\n",
    "                \"loss\",\n",
    "                {\"train\": float(loss.item())},\n",
    "                self.step\n",
    "        )\n",
    "        self.summary_writer.add_scalar(\n",
    "                \"time/data\", data_load_time, self.step\n",
    "        )\n",
    "        self.summary_writer.add_scalar(\n",
    "                \"time/data\", step_time, self.step\n",
    "        )\n",
    "\n",
    "    def validate(self):\n",
    "\n",
    "        print(\"\\nValidating model...\")\n",
    "\n",
    "        auc = test_model(self.model, valdata, val_ground_truth_dict, self.device)\n",
    "\n",
    "        ##############################\n",
    "        \n",
    "        # self.model.eval()\n",
    "\n",
    "        # dataset_size = len(valdata.dataset)\n",
    "\n",
    "        # print(\"\\nValidating model...\")\n",
    "\n",
    "        # batch_size = 50\n",
    "        # num_batches = int(2500 / batch_size)\n",
    "\n",
    "\n",
    "\n",
    "        # preds_dict = {}\n",
    "\n",
    "        # for i in range (dataset_size):\n",
    "\n",
    "        #     # potential bug: getting height and width mixed up, so if results look bad, make sure to check this is right\n",
    "\n",
    "        #     formatted_filename = format_file_name_fixMap_jpg(valdata.dataset[i]['file'])\n",
    "        #     height = valdata.dataset[i]['X'].shape[1]\n",
    "        #     width = valdata.dataset[i]['X'].shape[2]\n",
    "\n",
    "        #     rescale_to_img = transforms.Resize((height, width))\n",
    "\n",
    "        #     img_crops = torch.stack([valdata.__getitem__(i * 2500 + j)[0] for j in range(2500)])\n",
    "\n",
    "        #     preds_rows = []\n",
    "\n",
    "        #     for j in range(num_batches):\n",
    "                \n",
    "        #         batch = img_crops[j * batch_size:(j * batch_size) + batch_size,:,:,:,:]\n",
    "\n",
    "        #         batch = batch.to(self.device)\n",
    "\n",
    "        #         preds = self.model(batch).detach().cpu().reshape(1, 50)\n",
    "        #         preds = (preds > 0.5).float()\n",
    "        #         preds_rows.append(preds)\n",
    "\n",
    "\n",
    "        #     sal_map = torch.cat(preds_rows, 0) * 255\n",
    "        #     # visualise_sal_map(sal_map)\n",
    "\n",
    "        #     # print(sal_map.shape)\n",
    "\n",
    "        #     # print(torch.count_nonzero(sal_map[0]))\n",
    "\n",
    "        #     sal_map = rescale_to_img(sal_map.unsqueeze(0).unsqueeze(0)).squeeze(0).squeeze(0)    # unsqueezing and squeezing done because transforms.Resize requires (., ., H, W) shape tensor\n",
    "\n",
    "        #     # print(height, width)\n",
    "        #     # print(sal_map.shape)\n",
    "            \n",
    "        #     preds_dict[formatted_filename] = sal_map\n",
    "\n",
    "        # # print(preds_dict)\n",
    "\n",
    "        # # MOVE THIS TO OUTER CODE SO THAT WE DON'T CALCULATE THIS DICTIONARY EVERY TIME SINCE WE SIMPLY DON'T NEED TO DO IT EVERY TIME\n",
    "        # val_ground_truth_dict = get_ground_truth_dict(valdata.dataset)\n",
    "\n",
    "        # # print(preds_dict.keys() == val_ground_truth_dict.keys())\n",
    "\n",
    "        # auc = calculate_auc(preds_dict, val_ground_truth_dict)\n",
    "\n",
    "        ######################\n",
    "\n",
    "        print(\"AUC:\", auc, \"on validation dataset\\n\")\n",
    "\n",
    "        return auc\n",
    "\n",
    "        # print(\"OK\")\n",
    "        # import sys; sys.exit(1)\n",
    "\n",
    "        # results = {\"preds\": [], \"labels\": []}\n",
    "        # total_loss = 0\n",
    "        # self.model.eval()\n",
    "\n",
    "        # # No need to track gradients for validation, we're not optimizing.\n",
    "        # with torch.no_grad():\n",
    "        #     for batch, labels in self.val_loader:\n",
    "        #         batch = batch.to(self.device)\n",
    "        #         labels = labels.to(self.device)\n",
    "        #         logits = self.model(batch)\n",
    "        #         loss = self.criterion(logits, labels)\n",
    "        #         total_loss += loss.item()\n",
    "        #         preds = logits.argmax(dim=-1).cpu().numpy()\n",
    "        #         results[\"preds\"].extend(list(preds))\n",
    "        #         results[\"labels\"].extend(list(labels.cpu().numpy()))\n",
    "\n",
    "        # accuracy = compute_accuracy(\n",
    "        #     np.array(results[\"labels\"]), np.array(results[\"preds\"])\n",
    "        # )\n",
    "        # average_loss = total_loss / len(self.val_loader)\n",
    "\n",
    "        # self.summary_writer.add_scalars(\n",
    "        #         \"accuracy\",\n",
    "        #         {\"test\": accuracy},\n",
    "        #         self.step\n",
    "        # )\n",
    "        # self.summary_writer.add_scalars(\n",
    "        #         \"loss\",\n",
    "        #         {\"test\": average_loss},\n",
    "        #         self.step\n",
    "        # )\n",
    "        # print(f\"validation loss: {average_loss:.5f}, accuracy: {accuracy * 100:2.2f}\")\n",
    "\n",
    "\n",
    "def test_model(model, dataMIT, ground_truth_dict, device):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = len(dataMIT.dataset)\n",
    "\n",
    "    batch_size = 50\n",
    "    num_batches = int(2500 / batch_size)\n",
    "\n",
    "    preds_dict = {}\n",
    "\n",
    "    sigmoid = nn.Sigmoid()\n",
    "\n",
    "    for i in range (dataset_size):\n",
    "\n",
    "        # potential bug: getting height and width mixed up, so if results look bad, make sure to check this is right\n",
    "\n",
    "        formatted_filename = format_file_name_fixMap_jpg(dataMIT.dataset[i]['file'])\n",
    "        height = dataMIT.dataset[i]['X'].shape[1]\n",
    "        width = dataMIT.dataset[i]['X'].shape[2]\n",
    "\n",
    "        rescale_to_img = transforms.Resize((height, width))\n",
    "\n",
    "        img_crops = torch.stack([dataMIT.__getitem__(i * 2500 + j)[0] for j in range(2500)])\n",
    "\n",
    "        preds_rows = []\n",
    "\n",
    "        for j in range(num_batches):\n",
    "            \n",
    "            batch = img_crops[j * batch_size:(j * batch_size) + batch_size,:,:,:,:]\n",
    "\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            preds = sigmoid(model(batch).detach().cpu().reshape(1, 50))\n",
    "            # preds = (preds > 0.5).float()\n",
    "            preds_rows.append(preds)\n",
    "\n",
    "\n",
    "        sal_map = torch.cat(preds_rows, 0) * 255\n",
    "        # visualise_sal_map(sal_map)\n",
    "\n",
    "        sal_map = rescale_to_img(sal_map.unsqueeze(0).unsqueeze(0)).squeeze(0).squeeze(0)    # unsqueezing and squeezing done because transforms.Resize requires (., ., H, W) shape tensor\n",
    "\n",
    "        preds_dict[formatted_filename] = sal_map\n",
    "\n",
    "    auc = calculate_auc(preds_dict, ground_truth_dict)\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "def compute_accuracy(\n",
    "    labels: Union[torch.Tensor, np.ndarray], preds: Union[torch.Tensor, np.ndarray]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        labels: ``(batch_size, class_count)`` tensor or array containing example labels\n",
    "        preds: ``(batch_size, class_count)`` tensor or array containing model prediction\n",
    "    \"\"\"\n",
    "    assert len(labels) == len(preds)\n",
    "    return float((labels == preds).sum()) / len(labels)\n",
    "\n",
    "\n",
    "def get_summary_writer_log_dir(args: argparse.Namespace) -> str:\n",
    "    \"\"\"Get a unique directory that hasn't been logged to before for use with a TB\n",
    "    SummaryWriter.\n",
    "\n",
    "    Args:\n",
    "        args: CLI Arguments\n",
    "\n",
    "    Returns:\n",
    "        Subdirectory of log_dir with unique subdirectory name to prevent multiple runs\n",
    "        from getting logged to the same TB log directory (which you can't easily\n",
    "        untangle in TB).\n",
    "    \"\"\"\n",
    "    tb_log_dir_prefix = (\n",
    "    f\"CNN_bn_\"\n",
    "    f\"bs={args.batch_size}_\"\n",
    "    f\"lr={args.learning_rate}_\"\n",
    "    f\"momentum=0.9_\" +\n",
    "    (\"hflip_\" if args.data_aug_hflip else \"\") +\n",
    "    f\"run_\"\n",
    ")\n",
    "    i = 0\n",
    "    while i < 1000:\n",
    "        tb_log_dir = args.log_dir / (tb_log_dir_prefix + str(i))\n",
    "        if not tb_log_dir.exists():\n",
    "            return str(tb_log_dir)\n",
    "        i += 1\n",
    "    return str(tb_log_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args, _ = parser.parse_known_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfce0d9",
   "metadata": {},
   "source": [
    "# Qualitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a7bde43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 96, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (batchnorm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(96, 160, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (batchnorm2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(160, 288, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (batchnorm3): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2592, out_features=512, bias=True)\n",
       "  (batchnorm4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=1536, out_features=512, bias=True)\n",
       "  (batchnorm5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (batchnorm6): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "trained_model = torch.load(model_file_path, weights_only=False)\n",
    "trained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce4905d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualise_sal_map(sal_map):\n",
    "\n",
    "    # Convert the tensor to a numpy array (matplotlib works well with numpy arrays)\n",
    "    map_np = sal_map.numpy()\n",
    "\n",
    "    # Plot the tensor as an image\n",
    "    plt.imshow(map_np, cmap='gray', interpolation='nearest')\n",
    "    # plt.colorbar()  # Optional: add a colorbar to visualize the range of values\n",
    "    plt.title('Saliency Map')\n",
    "    plt.axis('off')  # Turn off axis ticks\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c7185e-749c-423e-9380-316a4e00e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_dict(model, dataMIT, device):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = len(dataMIT.dataset)\n",
    "\n",
    "    batch_size = 50\n",
    "    num_batches = int(2500 / batch_size)\n",
    "\n",
    "    preds_dict = {}\n",
    "\n",
    "    sigmoid = nn.Sigmoid()\n",
    "\n",
    "    for i in range (dataset_size):\n",
    "\n",
    "        # potential bug: getting height and width mixed up, so if results look bad, make sure to check this is right\n",
    "\n",
    "        formatted_filename = format_file_name_fixMap_jpg(dataMIT.dataset[i]['file'])\n",
    "        height = dataMIT.dataset[i]['X'].shape[1]\n",
    "        width = dataMIT.dataset[i]['X'].shape[2]\n",
    "\n",
    "        rescale_to_img = transforms.Resize((height, width))\n",
    "\n",
    "        img_crops = torch.stack([dataMIT.__getitem__(i * 2500 + j)[0] for j in range(2500)])\n",
    "\n",
    "        preds_rows = []\n",
    "\n",
    "        for j in range(num_batches):\n",
    "            \n",
    "            batch = img_crops[j * batch_size:(j * batch_size) + batch_size,:,:,:,:]\n",
    "\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            preds = sigmoid(model(batch).detach().cpu().reshape(1, 50))\n",
    "            preds_rows.append(preds)\n",
    "\n",
    "\n",
    "        sal_map = torch.cat(preds_rows, 0) * 255\n",
    "\n",
    "        sal_map = rescale_to_img(sal_map.unsqueeze(0).unsqueeze(0)).squeeze(0).squeeze(0)    # unsqueezing and squeezing done because transforms.Resize requires (., ., H, W) shape tensor\n",
    "\n",
    "        preds_dict[formatted_filename] = sal_map\n",
    "\n",
    "    return preds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85d1fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_dict = get_preds_dict(trained_model, valdata, DEVICE)\n",
    "test_preds_dict = get_preds_dict(trained_model, testingdata, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a21fd4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7125706323002338\n"
     ]
    }
   ],
   "source": [
    "model_test_auc = calculate_auc(test_preds_dict, test_ground_truth_dict)\n",
    "print(model_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c599e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sal_maps(i, preds_dict, ground_truth_dict):\n",
    "    file_name = list(preds_dict.keys())[i]\n",
    "    return preds_dict[file_name], ground_truth_dict[file_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec36fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ecff710",
   "metadata": {},
   "outputs": [],
   "source": [
    "j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "608367cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAGZCAYAAAD/+YnsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAADrkElEQVR4nO19e6xt31XWPPecc3+tKa8WwvulpBQiSvCVFrRosAhprSWKFUmUktgmKggYBYK8QrQBDUqkxj9AEqjy0CpiQ21VEP+hkKBN8IGIFAMIlEYQFO49557tH3Wc+53vfOMxH2uffX93j2Rnveaac8zHGt83xpxr7ZPdbrdrRznKUY5ylKMc5amSe3etwFGOcpSjHOUoR9m/HAnAUY5ylKMc5ShPoRwJwFGOcpSjHOUoT6EcCcBRjnKUoxzlKE+hHAnAUY5ylKMc5ShPoRwJwFGOcpSjHOUoT6EcCcBRjnKUoxzlKE+hHAnAUY5ylKMc5ShPoRwJwFGOcpSjHOUoT6EcCcBRjlKUt7/97e1Vr3pV+4iP+Ij2zDPPtA/8wA9sL37xi9uXfMmXDOX31V/91e3k5OTGuU/91E9tn/qpn7pA27uVk5OTdnJy0v7sn/2z8vrXfu3XXqd55zvfuVfdjnKUo7xHjgTgKEcpyJvf/Ob2kpe8pP3v//2/29d//de3t771re3v/J2/0z75kz+5fdd3fdeyct7whje0N7zhDcvyu0t5r/d6r/Y93/M97dd+7ddunN/tdu3bvu3b2nu/93vfkWZHOcpRWjsSgKMcpSRf//Vf3z76oz+6/ct/+S/bq1/96vbSl760vfrVr25/82/+zfY//sf/WFbOx3/8x7eP//iPX5bfXcorX/nKttvt2nd+53feOP9v/s2/aT/90z/d/uSf/JN3pNlRjnKU1o4E4ChHKcm73/3u9v7v//7t7Ozs1rV7924+Rt/1Xd/VXvayl7UP/uAPbs997nPbx33cx7Uv/dIvbf/n//yftBw1BfDw4cP2dV/3de1FL3pRe+aZZ9oHfMAHtM/7vM9r73rXu26k+6iP+qj28pe/vL3lLW9pn/RJn9Se+9znthe96EXtW7/1W2+V83M/93Ptz/25P9c+/MM/vN2/f799yId8SPvjf/yPt1/8xV9sv/7rv97e933ft732ta+9dd873/nOdnp62r7hG74hrcv7vM/7tFe96lW3yv/Wb/3W9smf/MnthS984a173va2t7VXvvKV7cM+7MPac57znPYxH/Mx7bWvfW375V/+5RvpbPrk3//7f98+67M+q733e793e5/3eZ/2uZ/7ubfa5ShHOYqWIwE4ylEK8uIXv7i9/e1vb1/wBV/Q3v72t7eLiws37U/+5E+2z/zMz2zf8i3f0t7ylre0v/SX/lL77u/+7vaKV7yiu9yrq6v2yle+sr3+9a9vn/M5n9Pe/OY3t9e//vXtbW97W/vUT/3U9hu/8Rs30r/jHe9oX/IlX9K+6Iu+qH3v935v+x2/43e0z//8z28/9EM/dJ3m537u59rv+T2/p/3Tf/pP2xd/8Re37//+729/+2//7fY+7/M+7X/9r//Vnve857XXvOY17Y1vfGP71V/91Rv5v+ENb2j3799vr3nNa0r6f/7nf3774R/+4faf//N/bq219iu/8ivtTW96U/v8z/98mf6nfuqn2otf/OL29/7e32tvfetb21d+5Ve2t7/97e1TPuVTZJu/6lWvah/zMR/T/vE//sftq7/6q9s/+2f/rH36p3962D9HOcpR/r/sjnKUo6Tyy7/8y7tP+ZRP2bXWdq213fn5+e4lL3nJ7m/8jb+x+7Vf+zX3vqurq93FxcXu3/7bf7trre3e8Y53XF/7qq/6qh0/gi996Ut3L33pS6+P/9E/+ke71trun/yTf3Ij3Y/+6I/uWmu7N7zhDdfnPvIjP3L3nOc8Z/czP/Mz1+d+4zd+Y/f85z9/99rXvvb63Gte85rd+fn57j/9p//k6v1TP/VTu3v37u2+8Ru/8UZeL3jBC3af93mf595n0lrb/fk//+d3V1dXu4/+6I/e/eW//Jd3u91u983f/M275z3vebtf+7Vf233DN3zDrrW2++mf/mmZh7Xdz/zMz+xaa7vv/d7vvb5mbfdFX/RFN+554xvfuGut7b7jO74j1fEoR3na5RgBOMpRCvKCF7yg/bt/9+/aj/7oj7bXv/717ZWvfGX7r//1v7Yv+7Iva5/wCZ9wI0T93//7f2+f8zmf0z7ogz6onZ6etvPz8/bSl760tdauPeGq/It/8S/a+77v+7ZXvOIV7fLy8vr3iZ/4ie2DPuiD2g/+4A/eSP+Jn/iJ7SM+4iOuj5/znOe0F77whe1nfuZnrs99//d/f/uDf/APto/7uI9zy/2tv/W3tpe//OXtDW94Q9vtdq211v7hP/yH7d3vfnf7C3/hL5T1tzcBvv3bv71dXl62b/mWb2mf/dmf3Z73vOfJ9L/0S7/UXve617UP//APb2dnZ+38/Lx95Ed+ZGtNt92f/tN/+sbxZ3/2Z7ezs7P2Az/wA2Udj3KUp1WOBOAoR+mQ3/27f3f7q3/1r7bv+Z7vaT//8z/fvuiLvqi9853vbF//9V/fWmvt13/919vv//2/v7397W9vX/d1X9d+8Ad/sP3oj/5oe9Ob3tRaa7dC9pn84i/+YvuVX/mVdv/+/XZ+fn7j9wu/8Au35sZf8IIX3MrjmWeeuVHuu971rvZhH/Zhadlf+IVf2H7yJ3+yve1tb2uttfbN3/zN7cUvfnH7pE/6pK462HqFv/7X/3r7sR/7MTf8f3V11V72spe1N73pTe2v/JW/0v71v/7X7Ud+5EfaD//wD7fWdNt90Ad90I3js7Oz9oIXvKC9+93v7tLxKEd5GuX2iqajHOUoJTk/P29f9VVf1b7xG7+x/fiP/3hr7T0r3H/+53++/eAP/uC119/ae+a+R+T93//92wte8IL2lre8RV5/r/d6r+48P+ADPqD97M/+bJruD/2hP9R++2//7e3v/t2/2573vOe1H/uxH2vf8R3f0V3eh3/4h7dP+7RPa1/zNV/TPvZjP7a95CUvkel+/Md/vL3jHe9o3/Zt39b+zJ/5M9fn/9t/+29u3r/wC7/QPvRDP/T6+PLysr373e+WROgoRznKTTkSgKMcpSD/83/+z/bBH/zBt85bWPpDPuRDWmvt+sM+zzzzzI10f//v//2hcl/+8pe37/zO72yPHj1qv+/3/b6hPFg+4zM+o337t397+4mf+In2sR/7sWHaL/iCL2ive93r2q/+6q+2D/zAD2x/4k/8iaEyv+RLvqQ997nPDe8fabs3vvGN7Xf9rt91ffzd3/3d7fLy8lnxMaWjHGVrORKAoxylIJ/+6Z/ePuzDPqy94hWvaC960Yva1dVV+w//4T+0v/W3/lZ73vOe177wC7+wtdbaS17ykvZ+7/d+7XWve137qq/6qnZ+ft7e+MY3tne84x1D5b761a9ub3zjG9tnfuZnti/8wi9sv/f3/t52fn7efvZnf7b9wA/8QHvlK1/ZXvWqV3Xl+bVf+7Xt+7//+9sf+AN/oH35l395+4RP+IT2K7/yK+0tb3lL++Iv/uL2ohe96Drt537u57Yv+7Ivaz/0Qz/UvuIrvqLdv39/qB4ve9nL2ste9rIwzYte9KL2237bb2tf+qVf2na7XXv+85/fvu/7vu96CkLJm970pnZ2dtb+8B/+w+0//sf/2P7aX/tr7Xf+zt/ZPvuzP3tIz6Mc5WmS4xqAoxylIF/xFV/R3u/93q994zd+Y/ujf/SPts/4jM9o3/RN39Q+7dM+rf3Ij/xI+4RP+ITW2nvm4N/85je33/Jbfkv73M/93Paa17ymPe95zxv+WuDp6Wn75//8n7cv//Ivb29605vaq171qvbH/tgfa69//evbc57znOtye+RDP/RD24/8yI+0l7/85e31r399+yN/5I+0v/gX/2L71V/91fb85z//RtrnPve57RWveEU7Oztrr3vd64bqUJXz8/P2fd/3fe2FL3xhe+1rX9v+1J/6U+2XfumX2r/6V//KvedNb3pT+y//5b+0z/qsz2pf+ZVf2V7xile0t771rcNE5ShHeZrkZGdLfI9ylKMcheThw4ftoz7qo9qnfMqntO/+7u++a3Wu5au/+qvb13zN17R3vetd7f3f//3vWp2jHOWJlOMUwFGOcpRb8q53vav9xE/8RPsH/+AftF/8xV9sX/qlX3rXKh3lKEdZLEcCcJSjHOWWvPnNb26f93mf1z74gz+4veENb+h+9e8oRznK4ctxCuAoRznKUY5ylKdQjosAj3KUoxzlKEd5CuVIAI5ylKMc5ShHeQrlSACOcpSjHOUoR3kKpbwI8Ju+6Zvkeft6l21be/z/6OpaJrgkAfevrq7KeSjB/2yv6OVd4/M9x97+6DWlI/83vUrvLfvA89xG3jbSBa/hfdl+Vqerq6u22+3ao0eP2tXV1fXv0aNHN85FYnW1fC4vL6/vt3089+jRI7eueLzb7drFxUW7uLhoDx8+vN5/8ODB9bnLy8t2cXFx48991O83f/M3bzxLVs69e/dutdfp6Wk7OTm53t67d+/6Z2lPT0+v63V1ddUuLy/bw4cPb7SdXcP2UW3G57K0pgP++Dz2rfWL7dt561c1DlWb4M/a4+zs7MY50xPLwbJMF5WO03vXbUxivvfu3buhF/+sL1nU82vlerpxfbB/1HGlT3ukx1545aqys3xG7E2ky+r0IxhUlf/7f/9vmuYYATjKUY5ylKMc5SmUIwE4ylGOcpSjHOUplCMBOMpRjnKUoxzlKZTpDwHtdrt2cnJyvW2t3Zjjsms9+ZnMzvujoE6oMwrP5bLwPXjM8+ve3B2m4/K8az1ydXV1a84cy/Ak66NMJ+96Zf1Cdf5fzSNW2imaT4zmcdU9eKzWVHh52toENTeLc8T4ay3uT9VGrKfdf3Jycj2nbmLrAliUfjz/W5krVm2FotYE3Lt379azanXonf/l9mX7xHXGe7y1AGquPdqvjCXvhzqrukV1jY7x/so4V9d6Rdk7E65jL15U12v13NurB5dbvXfG1q+QMgHwKoTgz5WpGC8lHvCvWHyCxoXTVPNXYK9AQbUJSvVaZZ/riIubRga5p39Ur8pgHgF+vi/KU9XD2yrwVYYzyxv1YCPrkQNv4SLr0trN/jw5ObkB6p5cXV1dg7sBiSKwTAIsf29Bm+WnwES1C6dR/Y8/Bntuy8y4eu1teUfPGwK9Osf9VwV/RQRYRyYb2EZRHVU+FR289lX5z4I/51MF/C30qALubFm9ju9dyRQBUODPnbzCi8+Y6Ihnyl5GJArU8RoTgYgEbEkIuH4ZCegdoB4Z6JVsRXDm9aOXmOlrWw+Y2Tv3jHWlrgyWnCdHAZRnpvSvgL43Nuzao0ePZLvZOVuNjm9Y2NbaCce6AquoDp6+BvzW557XH4FYVA4Da2YruF5cfuRdV4EX95E0Yp09fbN6ql9E2DxC4JW1CoRRssjrqnIr8iSA9kqZmgJQgNjabSAczTs6rlyrhOUjIEEA9fL3AJ/Li0B4i6mA1jQJ6BngisBkOiqdvfCvkgz8veOIOEUGmQ14xVhmwvdzSF+BP6bjCEA2JrxIjIoccD1wmg4BCNNz/RVpycBCjSUmASiKCERgqsrzwJAlqiduR8Dfa4+oLIxUVMAxqq/Xbl75UTmj4JjZsRHbPitqPFb0mLHHmS4oPeXMtNGSCADuV0Gm4pH2kACVJ6ZXnnsmyluK6puBZXTOE8/4V4kCk4BqfbOpmxVEhQ2/B/4jwK/0VT8Ov3uGMhL2GDl/BfAK8NUPxxeG9aviTcOh123lcPtfXl7eqBf2lwemmJ6PPUOH+XoecQSuPBYz0K+CIu5zft4USYWocN7cxxjlWkUAPD22AP6orocomW5eG21BBnpkRZtORwBai8HQ9r17s/PRcRYeUw+Px/Z6CIFaSMhtEG1VnUdC69V02VqMzJB7degBfuXlofDHo3gfj3uIoDKAFY+c535ZonUqikio/DOvEe/32lz1K491HLfYRnb97Mw3A/ZhIAX+M4Yegd/yRdBTgM5lMwCzHkwiOKyeASKfi8qO+lKdz4BdtUMk1bKzulbKyvR4tkilze+KBKxq5+kIgF3zPP+RsHNWrnctiwBE9/SACs9P9oB9VJdKmL1KIliYBGRz6Io0RHWr1peNPl/L9r08I4mAV4Xd0Xgqqa4/sB9GGbhM/NKg0hHz8uqZEWyPCCDwen2iSBPXryJeWivXvnpn44u9f24H1IefYbXlsPputyut/1F1iMBfEceI3KkymBxVgAi3rIM3nleDdc9Y6JHK870SiFe1i9d3iBt47i7IxNIIgO3btV7wV3lH5yqAn12LiA3fr0gAXlMAOQrYI1IhAfuUKnDj4jbP68fjalplhNE4ep6/F8pV7cdGnUFele+BJxIDzrsq2ZSPgadNJSD4Yz8gaDI54LasSLUuXjRAPfsM6B4pxXujEHumk+pbRQis7IxIVq5ltoqvKdCv6KHK2MI+zdy3b3s5m8cMkdgqX5bp7wC01u+tVsR76Cv3jV7vuRaFrD2Q6gE573jUS+4Vb97YK4uvcVtEnr8nWbuwVD0d5Y0prw699Mi7xC1+Tx9f8cvA38S+AW8eKrdbpf04eqOeQ3srgMu2dPZ/BFdXV9f/iZDpngkDpiJZTNL4Pqufpwu3lffL9KzqzVEjdX9P+6xyoFZIxf726MeRmt77Rq/33tfb7oqgbNFvW+S55DsAdt3bx3Q9shrUegDeS5sBP2+ja1l5EcDvC/wjvav1VCCGnl5WJ1W/e/futUePHpXrrsCCjbmBHAI/7ts93qKy1to1YPIfCVleTArsPgN+y+P09PSWB+5FShTAc7hfPb8c1kdBAsDtMUICFHCymOHNvFmPPGA+tq2Cf4XgVX/qfi5Hla/Af4UD1QNoUdoRsFf3ryA2lXaptKMH2iM69rTxyvxmZNmXAKN9dbxv2QL8KySgeq2qT69XXBFvgWClzSqEwAP/nnLwuPrwV0V5oGqentMrcOB5fZ7fr4jNTSPg2z/E2X5VVDRA7fM9XHe1RiITzzPyyAAaXa+N1TWUiIBiGg+gKuVlJETp1dNmW9nJfUUUKp610kXVfcTeVZzOu8QiT+4CI5dMAVSlysRG8vWkN99e8M+AvhoBqJxbDf5VIMnK8YxrBv7V1/6qerB4IFGNBrDnq9LxwjgMmauFfxGAmpdvzwl6/UgEFIBFz1a2AJS9VQX+/DfLnofrSeQxRwQg22cdIsKoiADnmela1a2nbbz28gDbsxNe2i1A3wPZHt1UfpFkz7/3rFftCeu5L8J0l7L0LYBoH/NZzXJW5afyGQmHj1zL9KgA5EoZqUfPMeepjkfaSYn3EDMIIVDb9cpKbwQAux+nAKJFY1wXBH6bEmDwHxEjAQzgKrLBxEd9KTFqV9XOXAbWnxfkeeV4xM3EDLY3ZiPyzeVyn0e6qPYYIQII+qounN/IWJgFNdX+FU+b61XRZdbmVbAGx1xFJ8w7k610XilLvgQY7a+S6EFYna9JT8hfnVsdAcj0XSWRHpGHhcdeFMAkiz5kRCBqB88TyFatMwCiF2wfxcm8WAN/BaAcTfDqjR/oae3mOPSeAzas1Xp6+2run99s6JHIazZykoHsiNHtef488OfV/Zg+269IZC9Hr7H0AG+kZ48enoc9Q0IYsEfvV+dXAb9K22O3Zwher2w+BTBDBqrszcqZEQ+gejz76rkKqM94vDNSZd0eEYjIgElErHp19CTz+tUx7jPwKXBQkQAFmJWV4gb86Anzn/Sw9P7RlopseN8fYP1VO/QKGn+MSPB/FFS87ZHIkfdsqjHg9TXqoOpXOReJ8v57AaECZlEadc2rWwSoPfpkulZ0rOpWKW9FX87qU+nDWZkiACNe2lbAFjHDHiLR2jrwjyIAkV6HAP69wmw36gf0+JSx4/s5b+8f9LIP7njApua6s4ePwR8BVYEmLwSsRAEwjRcFqJKAqLwoGoA62c97s6DHC46MutpG9/H5CsGu6lmRlcCP+1WPFNNm26puHvmoerW9gFclLTMSEameCM+hyAqdygSg4g1WWPisZAOlUpaXpjLfX61jBOI9nvVWMhqCN1EGy/btnh4SwHmr8kxUaN3zXL2/2sW5eg5tKw8XPUVOl+kQrRlgg4pRAAX66lVAnjLgNtvtdvKfABXgKx1ZP24PS4fnqgCmnpsRb2mfzgZKD0hUr6u2q3i8vB+RgEiwLC7X0y2SzF4rYJ7tJ2VT8FxmY0bBf1/2e5XsPQLg3T9ybWXHjM73R/vVsmevV/8ed6YMT9jY9zB5IwGcn9q39Ha+F+grXr/6aE9WdwX+0dRBdQ5dgTwTAX4tkEmMF1ZXdeS6qPbHspksqKgNk4Ssvl40qCKzz1Al/96IR2X8RN5oVHZ0z4jX7xExvKaOe6IAPQTE0yu7rydqonTKjr1yK+LldZekYfMIwGrvPzruZaatbeP147aSZyTVdCtIQG+ZLFWmr8pQxsLzaBXwM8AqUqAW4+E289BNFLBjmV4UAPXHe7md1FoA3udP+Fp6yxNJVsVDq3j/2EccERkBQMyb91dFAWalB3x7HBK+d6Z8zqfXe82iMFE0oKJXVgcvClDRewTwvTEWtdvIeKzKirxHxl5rCxYB3hX4j6YxiYBfnYvIR+b1j4J/r4ySgBWDjx8qNSCVAbEoAF5DYGQw9sBVefiY1gN/RSDw1biozplOyvOPwAINL4f/0eNHEoBRgN1ud/11RMw/GhNe+N/TD7eqDbiNIqk4FaNSBYfW4r6o3ovblc/3aB2i46ozp4C/p109XaJyvXMr2rRipyIiq/p2VV/3EqBRwGfZawRgldIzkn18ZtTrr6T1zo2kMeldCd5bdqRLxUvI8ld5qjlzBpos5O+Bsuf5K4CO6uF5/xkR8MDSax8EevVDsmDgH4XxUX+uC7YZ6+LtY/35OwNM6jIbspoYq/xGbBASs4jAeZGTKM8V+mX6qPORbVIRgFkS0CujY6EasfGiHJzOu9crO7q3Itlzsrrd9xoBqDbQFiyrCvzZucpxb15PskRhNLze+7lhBiUFUt5iwAroq9A/E4+ozpjOizBEJCATaxcGfPP+T09Pb5znPC30b22vCAcTHiZB3D+WH/cZgr8Cy0o9K+k47Yh3HBn8UVGRHUWMWQdPx179eiIVnt1SWwb8zHte5b322P9eMsLgP9PukcyQJEUCtiJc0xGAqhet7lOVWgmOPX80U/F2KgOzhxDNigJVb0W4d1+1rt651mphz8grMgBBvT3gR8D1vPwKCcB9LBf1QxBu7fEf5Nh5jjTwJ4D587mYr/pTKa+9EfTt3mhMKYJiurJ+XjvzGFE/rw/tGNPxPurKYMP1z44zsqYIauTd8n1RGtQlA9mqcHTGkwqRUNcZACPbrrz+7L5MIodhJE/Gkqp+mfMyIxGxqESIvLG0WpZOAeB+RfEszYrwdi+wVzz26rEyelt3qEmFCPSAfyWPVcJeKHtYlX0vHz5v7dPzPj2HuhFQvT/OQTDHaENUNo4f9bbEycnJ9d/6YvlepIMjE1YfBH/Pk1W6oY5odPGHkQFFHLAuUbkeeVBpI49fHXvlz+TP16tSBf/K9VnJyMeK8rP2qZI+RQKqZayWnqhCr/O0WjadAkBZ/cczPY0ySgKifU/XfQF9tT29z8qiZH03U5ceg6gWkWUAH13z9lWoG3XzPNerq6t2dnZ2HQW4d+9eu7y8vBGVsGOVv3rHPxPvz39Mn5OTkxug7kUgsvUJo88TthG3GX7pLxsHHqgqEp3lEZGE0QhAtcwqcfLqfldSiQiwrCIBUf7esSq7ok/myM7UR91bIQNRm289NjZbBNhaDjaVvHvStOaHlFaCfVYHz+vfNxNF4b6oErdKv2fXGCBUH/H8e9XjZ29e3e8BHRt29UPwsnzwHIO/vUHAZCbygCvtyYL1Ozk5uS4fpyPUfkQAKkQgGtvePtdfATTmH4FoBKC9wI/leee9fFmfDPiza4cmahx4oFu9v0eqztZMf2Tlem2A0gPes5GALWSTDwG1dvvDOl66HqbM11UDR0ZjNfBXytpHp3rAmqWfTbPFvSYR2ONCOt7yOT7vXTO9DfR5lb2BrC2+Y10RbLMxE3n/FWOipnUQ1DEqwfuYNoqGRLopT4xBn7/z74G/Grvec+WRh1HgRx1WRwCU/j2S9ceqcnrLrtoar50q0lMHhQNePlXs6dVD4U4G/t49+yYBSxcBmlS+qhftjwg3Hh/36JIdZ55J1XMZlcqK+h6DHu1X7q2cj4SNrefx4xavZ78sXwYuXHFv4H96eno9j97a4z5A8Lfrlh8/BxjO72knBCllSJiA7Ha7G9MRuK/eSKh6/ygKKL1t9udPDMJcRqaD5cF6VY+9CADXD6+rdqjoPCrVvsmIlHcPt0MmM05Hb3SgOg6ium8NrB5hjI4PgQQsmQJAyf5IJwPlEYnAv4cErD5eVb9IKkBc8a6y/HrLrOalHpwKCVDnK3koAGRQNvC3nxGCs7Oz63OWFsEf3xI4PT29Mf+t3tuP2gfbBD9MxJEAiwZY2ZaeV/3bfpU0eX2J7YT76pnj1w9VfT0PXLWHIk4zwM96e0RgRQSgIure2fyiMbYCbLz2qN6TkT7vWJWjSKTKYyup9N+hRQKW/R1wzyd11bZ3IHmNFBkvVTbve+dGj/fJ5jyJ6rcK/Kv3ZAY3AnMDbZXeIwRquiASXnRngI2gj+Bv+SIRsGiBkQBuM7UoLtOJw/78ap/V33sDIJrznwEZE89jrpJAb9/LV5VrxwzY0XFUHxUlyICnmv+zVXrrP2ofK30R5b8Pu/wkjINpAlB5pxyPo4gApx9pQM+bqHjmWxCBrWWWLVaMLKdH8cAdj9U2yl+BkwcSqIf6qY/kqPooMMd57Hv37rUHDx60i4uL9vDhw3ZxcXEDXJmccH1xHlyRAq+N+VsDCvhxi+CPOqn2wrKq/Y7fNMC69RIL7xr3M35fgL8tUM1fkUXeRnVQJDMrK5Is/UpCFp0/BOdkVGbaaF/1fhLIYJkA9Cxcqg6yURKgQChifZG328MQD4UM8EdXvEFWLV954iP3RscRCcBz0U+9Jsj1zX5K8J1489qtjS8uLq69/wcPHrSHDx+2hw8fXofc+WM/Xv74D3pRWq5bBvjRloGL+8XaTB1HQItAPAv8Km9cX8HlRf2oylJgz+d4IWRWp6yOkT7e8Uqg6LVdK+3U1oC3Rf4r6n/oQO/J0jUAVQCshPI8icBOAQLvR2Qgkkp0Izu3UqL3+k3Y6EfiAQSKl1cFXLz+UYY18roqIKPAItK9tXbLe2/tcaj+4uLimgA8ePCgXV5etouLi+vX6wxwWRgo0fNXdcet3d8L/JYH7mfPTIXAsW5M2rgsVa4HeB7BMB0xmqPSY324PA/UK+eyOlUBXF3bF2D0OCmzNusQQDDTYSsnzbOdhx4FWL4IMEpf8cBnGiwjHBEJqOSjru3L6/ekQgSUKHKQEQYe2OqaRwTUvsrf+0VeMwM9h4z573VVeZV+M+//4uKiXVxc3Ai1K3BQkQ9bG4Cg4kU27Bp/6Cfy+Pl7ClGbMTFjwqZ04n2ls0oTkZ1oPKBwH2bj1xtL3jVPt8o5TyrgvxIgehyVp9nzbW07Wx3ZuEMjBMu+BFhN00sCcL+34SoRgJ5BcGjgj+IRgSq4YXqTChmokAjPi1T5KaPsfSTIyrdjXCznRQDUgjoDUU8X27+4uLgRBbApAIsEmNhUAuaH0QD8fC+Xh/mYXuoDPkwElL5qy22GbeONFQXeypD1gF0FRFXoX0VQouhORCij9vL2e4jMTPuY9ABGZme9Y+9cJIcEYiaZTiujHVvKPnXbLALQm28GELP58rkR799Lc0iDidcHzEiFDETeohcWs2ueQeQFWXgtYtYqbKxIQFae+kjO1dXVddgff1kEAF8FNO/fzmPe2EZYNi/w8z74U/UqM48/ImvVvvDEA39vHGDIn/uTiYjnRHig740xVVelf7Wu1eNIem1jlQhk5z05RPCfkVEHKcszIsurZRSDphYBZpXyAIQBmPftgR55SNQ5tR1psEMGfpQqCYhAIkobhYcj0K+UjQZaef7KaOOY4ZX7vHKcdeT35aPto0ePbpAAA2F85U6BqfL+sWwmAUwAGPC91/vU+M6ibBFw4j73A9aP71f73L+qX1l3zEcRPFU/JAiKzKltJN54jrz/jDgpqdi66nPH51barUMF/1Gs6G2LLP0+22cF/pQJQLVi0QDnh6laASYFPSEtLwLg3ddbhyifJ0lW1SFqk4rx8wDRu48BRQn2N/9Bjf25D4bsMS/2yu0tAZvHt7ztWwEG8AhS+N4/fwMAz1feDvDaQZ1Tz42qV+851T6Zl+rdj/dGdeipH+qiSMYKT96rS5anV5/VXmJkE7NzStRzvcr+ee3RI2r8ZUA/ovdqgB9tu1X2ejkBGBGPDKiwJF+L9nvSeeVWdJ1tm60JREa2tii/Cva8r8LhkceYlY8AayBu+7gYD0mAevfcIgq73e7Wv/ohGaiAvx0bYUDjPwMEGehzu6r2rabx2tskK5fFI/dYhwz01Va9399TjyxNBv49fdnb9yp91dvP7CTXKwPY7JxHpCIdR2SECEQy8yxmMkpKVrbXsi8BRsIPdgWQuAPZoEeePe975zKvJfI+qlLprOwhHhH1rYC7jFR44BKtgM88NuXhKS/aQNcA2tKhx26RAAN0E9tH4G+t3SAE6rU1S4Pl4r56Q8F7W6HavhH4R95/hQBE/eDpEx2bqGeb9yMi7tkFJA3ql+mbXavWT8lqb79aJm6r+ygeEcju90gdHq+W7BnKrm/ZPzP9v9qG7yUCEIG/B0w80CqevRrk3j1RWSsly1PptAUhuEthkOGV7tHWu9bbVzg2EOQN+Ftrt6YBsCz7ocevCAEf2z4TAQb7zCj0gHEE/nxvlXCNkICoHigR4HjnOGLg1VnVsQLeM+cq17z+3hc5iGymss9eW88SCru+VZ1nvH8WdkqzNFW9qrIFDuwlAmAy4oVWwBy9rplG6hmIIwN2FOwrA68iI+3Poth8T/leiD/y8vk48+r4GMHXruM0QGvtmgR45aCXjhGF1ppcDxCBP95rkRr2/O/du3fj1cRq+yrirPa9dldtqfa98rcSNQ68uiH4473ROIvKiY6z+yPZmgR4IF/dKsnAf5ZQeHWIxGurHnISjfNe4jea9i4cvaURgMrAyc5VRA02zodXwVcXWFU9sewc6+qliwDVIwPVNlNvA1Tur+bfQ5YY/D0AnzF8Ufjf9lu7OTasjTDUz8CPXj+/YYDgf3JycuNPgzLwV8bS8p31sD0i4IGhRwAwD3VcBVKTKJLXW1ZGcjBNdi7Sv9ce9MgW3m/0/EagnxEAD6i3IBQ9siVwbklqe2SrOi6NAHgDYxT8M++fgT/6m1X1Wlzvqusew6iYpdItAnw25nh+hgRE+qwGf9TD7kNwZcCtMn6PQHiCAI2v4uEUAObNxIAjAPyaoZoCYKOKZIDn/WeAX7WdRwQwPbclX+MysnPZcWToI6KsdPPSe6Q5qwuXw+m2BAIPVFeWmXnrEQFQ3jrvR8TWyy/y/FdKJRJQkRGScsjef2sbRwCihzU7FxkJz3OqDGAsb9WrV5Fx3DfgK4kWBKq2ybyyingel/fjqQETz6BH9zO5wLywjRGQrd52zBEBXu2PoI8gjnm31qTnb+d7FvxVgS0bbxHYZ8CYnYskA32Vv0daovK9Z31GDsULVFK1mdn9CsjZTtj1yjOq8s3y2KKdZwDbs2GVsg55zKCUCUAGlNnfrrZWjwTwYIm2VnZ1wNnWq89Ix40M3iy6kYlHFjzhTwV7D2NPXUYHuUcCsjLQGBnII/BnX/TDj+Yo8oDCBhFJwtnZ2XWZRgw4DyYD3E9MUDxDjM8VP2MeKfDGRNZfnldWHRMeAa9I1cBW9BhJw+Xv04CPEKzMfvR68QrsMz0yAsfjSbXt1u0dOTjeGIj2K2WNOkxZe7a2PlKwbAogIgheCDrqnAqrtLwjkqA6w3v1TOl3KOINkFEi0JoGlC3qnK36jwgACt+jAD/63Kt3DfNu7XFbMlna7Xbt7Ozsxtw/XrOphJkwo4E+fq9gxHvuiSwoY13x/FiPSr0rRnbE+EZScUzuQnrtTmUcZP3uEQEst2IHojQKCO+SYPXKzPibqVdG7iMZJQZ7eQuAvc9IIu+f9zG/Cvhnx965TM8oTc/5TCKwZ10qZXhRga1EgT7/KqK8fgT/CPj5nPctf/TarX3w9b/dbnfrX/1au/02QaQ/C09JsQ49wO6Nlcyj87xDvO7dq8LITCSwrSueYaRbVO+qrCYbvWVWr/USrSg6xGPDO66AdeZdq+jrCBnIyGePqGejShJXe+BZeVymsgEzOu31OwA4T6rYJz/knIcCf2Vs+AFB3dVraCtEhU23ksrD0KPL6DoIk57/HWCDz6BcFS+8j8CuylCEQ4GNeeKttRt/4cvrAzzypIClGnnCKEBr/eDvlZGBhQf+Gdm19uIfXlMLHLmNKgQdy6ym7wWYrYhAFWQiyZyiig4e8PP1SAcvnbLr2X6ka+V6T9RDne/Rcd9EwMrcqrylBKDiHSijhteVMUbhlf4ZAYiMQpXZ9kp07+i1TKJ2W8melUQeLYoHwjiXH+mMeSjPH/+Qh71+vlfpYzrj4jybYmLDgGPNyAaPY/6pvwA2UZ6Zlc8GoLLexms7r0wul+/zyAA+v9FrjxyhiT757EnkXUb1zOQuwX8E9D2bF9VDtZlqvyifajSoen5F39k9MySA9yvj4S6IgJLZ8vf2Z0AoZhBauxl+RsOmvBK8H7feuR59PQ86A2zvAdmXZPqra3y9R3ral+f+lceXPYDqWHn96of5ebowGcB6Wn/izxb82b5XVyMRSEYyQc/f9hX4W1krjE/FM+qNANibEUgETKxumCePhaoHyjqrbY+sAqRV+Xq2j4mAevYjchTZ1gqYoi6zJKB6LZMqCWgttof7tt+eHihRxGVWNpkCyAaeiREBJAHsbWBab+sRgmgQeuDD+fQ2/FYePkpmUCIy4ElVNy+vnvv5p7x1rzy8h382n4/nOB8sg/dbux3NYA8LPwTExIDzRLDLPDQlbNyjVwc9wzEiHvhHzxSTACYC+Gx7wMV1Udc5EuFFJlbJFvlWwZ/14GNl+6I28cBf2Y7ROs+QnX1JtSyv7TjNjF0fJaqrsGTJIsDIaONDrwRJABrjHiD1Bp0CmpVSJTpe+pGoQ8/D1DNIZh7ADBi81+94nHgsPDuu6IFlMAHI3lKw7eXlZbu6urrePnr06NbPm4JQfc+hcNRlt7s5pYHEhhcuRkSXy6yIR1SqhJrb1Oqq9PXIgAf+fOwBXg8QjTwvlXy9axVS0dNXVZIyQ/Irz+BK0jCbz6roWDY2tvDKPVHYMksGpgmAeuCU8VQegkm1AmqxWeSdKPAfZVw96aoGxUvndXSvrH4gKuWoa9gHipR5hCAqJwK+1m4vpPP0wXwVCcFzBr4M/kgIorUHkaA+PF+u3lRQ7VUdbxWpAD+Wy+3EUxXZa5cqiofiRfcUCfD092xERriziEsUbl8p+wAbru8K4B+ZKpgVj3hlwrryeNon4EfCY31Ur6URADZOUaPxOXy3eiSM7g3MrR7MSh4ZQHE6b+phX/puJR7gq8V4fJ+XX5RGhT45fwRblQb1w2P29hn88e0DzBfLyurjLWpUnn8EqrNSfaZU+UgCkCDw/Qj8o16WAv9oH/UdBf9ZUFsxtdBj+D1gy/LvOT50qYK46pu7BP7q2B6RKQKgjCzu2w/nBNW9rc09ENGDqMK7lfxmw/CVMlqL1xus0neljNQ9Cv97wJCV6aWN5oSzstV4wZ8K/RtQ44/r3tNG/Poie85eW6qxMzImZkCN0+B6hayPe8E/8tTUMzSifwb+3hirysqpgGrZFcKzBfCvIDxKRupceTZG7PCIzLZLldR4smQKwDOsZqwwHKs+RTtTdnQcze2uKjM7X8lvxnBX6jUz9zd6D5NDNZftjZ2srCxt5p2pVwijSADqbV55tAagV7g+alEj5u2B6ehYighWNia8e9VUn8pzJNrnXffqj7YmshlbzLtnsmKqL8t/xtbyc+xdw/JG8h6R6v2q/j12dmtnsFe8+ozI8i8BKmPPnza1dLhdRQSi98l7vYHqwzniXbTmzy9VBmdPh68YpBVg9o55YVwEtlWdK54TPyCcPxNV9UNdFehzVEC9opfNb2P+rA/mycTJqxeWlY2lCvh7zw3mjWmysjkf66te8sviPa88zkbBW9WXpxRmpTJdGuk1K6qO0b66v7X4DY6txSN1owQ5kpXTtL2yQv9lawA844kkgPe9SmAe1Qp6wO+BUw9or4xS8LXeAbmvgdYD+HzOA1oFXOpaT1mttRugm7UPgz2TVQX8dnx5eXnL20fv/PLy8lYf4oer8BqmUdMOOMUQvUXhPUcjQNwztriP1boLrmfm7Y88Zxm5UWRjxTOk6ozn9y0RQM/O/2f7K8nHiH6Vcz3OlYmXTpWzNbmpPsO9UiYAUaPxamsEeHxvmj8Owv+ZjmVVGh/L4HMzxi0qc9U1TBPNNfbml5W18r6qkWDAxTQr+sv7OI6NMZ6X92TmIa7cVzE83lsLEQHIgC6bEonOVQmzV1ZkcFcAx2oQqsoIqI6WowQJyKp27PH87wLsULJntdouI+1XWSfRm1+W11bja4oAYEPwx3xwH+cDFfAjIVD/7sfgoaR3cG5t7GfLGC1zK6LjXY/avWI80Ih5BrWnvfkYx5zJo0ePboxXXKluW/zQD398B8chj0lMq7x9G9+PHj26Mf49kuIRAtvnc5jOyh4ZExWvLxsP+wyPqjbg80yWvHuyclDUmFPpvHNVySIdWT+vmmKpEq5eB2b1GKm0VybVOuxT95m0SsoEoPKHLybRQ+L9iY/6YV74VbWsvKpUjOM+jNeszBr43vwy9qsiAJGwcYrGj/fwqq/kIfjj+OHP7Vr53itrPE444mT/AKh04/+usH3ve/5IBhTQ2zaLAKB+qh0rMuvl9KSffc4iwxwRpplnh8dtFHWJxrfJSP/0kCyPrPTICkKpjkdEOQ2z/Rld2wf4e3LnEQD87rmJ8nTUvndfVdjAZQO5h3l6D5A63meYseIBVwZfL9DPRgGiNFEEx/MuFBnwxgKTAPb87RyPUxtfHMVioLf7LC168JeXl+3k5CSsIwovjK14VOrnfUipKl5kz8qs3Fstl+sZPdOrSWi2PyrRx8lwi+Osx5OujIue9Flelfur/T5jt0ZlRWS34mRWbWe1P/aJLShTEQDPc0dPSz3w6iHseWDZm1IsfCb8WDUYKzptNI9eYI+ub00Eqn2g+iyLCjBDZ2/frinPv7V2HYpX3iEvVrV9XsdweXnZzs7ObuiV1RvXLGRjwFvjovazck2w/dTzNCuzRrhybQbke/VjG6O2tq/IWC84RNcioF5FLCqS6bAPqYxXD9BH27DSt5VyojKq12dlmgCohX28z4bK87DYqPE1PI/emAL/1UZMdWSVMa+WEcBW6bYgAj0PR2saMDMioDwoPO9FAvA7FOqbFPzhGt7aeFXz9ZeXl+309FTqrqICphOm478Ljp4B9eNyuV2x7JGxW0nf2/9Zuux8tl0hPA5tjNlxDxHIdKv2SUYovP7tjSiMSGR/Z2xXlndPmopE9ojTZPn09MU+MWUJAbDf6empPEbAZwLAx9GX2PCB4lAu6jQDzFEnK2ZYYXhbM+JekMZzVYPd45nxOSZ7Jtw2yqvnvBj8vfZHMEXwV8DvlcdrCna73bW3j/P+XCc7r/Jlz9+uqf8tUPkrwOdz0b1MkqM27CW8Hrnk/qpKZdz2EIBVNoEjS0wCKsBfBYSeNqvYolE5BG/fRNkNT4/RSAqnq5xX+NAj1WdwpUyvATg9Pb0Get6enZ3d+P909XetHvDza134YI+GTbxQkBJlULywaaRTBZxVXhW2OQvWan+ETETXqgNWAXtv+ZX8uZzI6Np/U7T2OGJg49meB/wbYH5GGKRbezytYG8i2NZ0i8ZR1P8z/TpLmpWuqszevovGgHo+1fnsOVURqFFR/TeTJ5OKikR2agvp1e3QZLSNMjvYi1HZcXZ+VMoEwOY4UQz8vZ8RADN4/E9qts+hs0ePHl3fx4ulOLTr7VelAjYeCcCyFJCrfa+cUSbaC8h4vgIgvXn35JHdG+nJxh6P1Ud81BaJpiojegXPxMadt6pfnbu6umpnZ2ft4uKinZyctIcPH7bWHq9HsLHAX/1T5dq+Kh8JDz9jyovla6pMVT9FrrI2qOSbpVeErlJejx69gmNxFvB6n8OtvH8sp5qPGgve+JglEXfR3150slpOZPO3Jm0oZQJw//79W+fQy+ft6elpu3///rXHhF9Rs31bOW2RgdZuPtRmoHEaQQ2q6JjFGyw4CD3A8YyNZ3hGSYDnvYzUq0evkYer8vCpRWyZeB5etK8+MawAX+2znkqPaOxkq/n5PK4jsLztWcH0iqBgnhFg231q3PL9ighUZQb8szSV53kW+KvitXcVhDOpguzW9ayWnQF3BJKr6nCXZM/ymRm/lfxRVvf9EgLAPyMC9+/fb2dnZ9dgf3l52S4uLm68NoWG7uTk5JYR50WEM3+20tpYyI9JQLSv7ony4XtmQ5LePTMkYFSXrK8ywMhAPwJ+O2/H3r/sqQV9inzYluvkAWhrt78BgNdRH5tSsGfCW6NQKRPrEHnK2a8imF8GDNXxwwRFXVvxnPTqoo5ZFzU+PcclkrsE+B7p7dNojPCxR3h7ys30WSUr84vGP59bMU6mpgAY+M/Pz29s79+/387Pz6+B38BfvR5o6wCUJ87GH7d8vbXbwOM1WsTelAHjcGq0n22rJGBUKt6YBzDRwBohYL3CRtMzpp7Hj+dwfQkvOvU+uKPOcd4G1PxaoV3zQNXGvv2JEP6fAC4u5DI9QT1UO6rxyXrhlzmZAETjqGqQe8EvMnxRmZk3VpVK+SxoH3oBf5Wssh1byUjEAKXappUyonP77ruKTtF9M/pORQBOT0/b+fm5C/zPPPNMOz8/bxcXF9fTAmxkzEizMc72IyDwDGJrNTbqlaM8KQX8uJ+RFyVsYCOJBkF2LmLcWwB9tf58D//U/wl4P/UNfSYFrJPXX5YXC69TQUBVr8naPUhE7NlAcuy9Etja7XB0LwmwPBT4Y9RtBFSj9BVCo/RU2968K1KJQCjA8KIed0EEZmVfRGIVYWttvO9HwfcudPHyndG3TADOz89v3/z/Qd9+Bvz2e85znnNNCuzNAFQWvR8V+vSEDToyb3z1C8thQUNT6TBMq0KrqqM88GdCEZVpuiqphFp7SEAP6PeQlBGJAD267qVTC/94DYBqF/Vaqgl63wya/D0MBHibAmPPXz0jSj8cc5i2uhDRi1AwGchIQM9zGqVh8QyhFzGbEXwGPfCPSIHKh+u8kkB5wmOmx2aosnmcj4iyiVx+LwnoSesROO94lcxGFDyiucLjZ5kmAPfv378Gftzev3+/Pfe5z23n5+ft4cOHN4wLGldbIHh6enodBWCjxqI+f2qGnT0h88jsPpSRwddLAmxfEQBMlxEBNRg83XtJQQX4q2WZbtX7K+UqEPf6PyIIvA6AiYKJWv0f1ZU/PITfwzg50a/KnpycXK+Nweuq7koyb9gT5U2rSIU3xpX0koMewp2NewV8swYyIwRcHh6rre3PtsmoVMdKtX+zfDwClxHKEd1GZR8RDi5rhLyotlpJBMoEwBM0vOjR27z/ycnJ9QJA++F/quPrgOrB9sCJQSF6xYvv430FFurndYYCWJU3tlck3vfFq4M2A/zWYtAf8fZ69Iq8owjcOQ0fZ9EBVYYSJpHRw4j3YPrIY1VjyH78Ku3Jycn1mMZ9/shRJBghY48f62f6VcKOKv8tpDrutwTQkXIj0ri1ZIDvAUgVWDwCxtf3CbLPFhm18aNSJgAXFxe3zuHq/ocPH7YHDx7ceBPAXgM0MvDgwYPrxYAPHz68teVXoJSgEfRIgDL4KB4zV8DDx5HnrzyAHuA3qRAE9RByPUc8+95jJVGYNMrX+3lz4R5ZyPJQwqRLffjK8uIV/Hidj3m82O/Ro0ft4uLimgCbDvZmjU2hGUm2cq0M/HG9sZ7e+FUgYen4zYgRQhiRgoqRw2eL9feeT9RrBnyiZ7snD6WTl2cvifK8bN6PyEAlqqGuR8cReZyxLdUpjsr9+5Rqn6507nqkTABwdbKJeR8Wej87O7sOc56enrYHDx7cIABGFMz42TnbrxiV1mph4Z7BlhlN23phLB6QnI8XUu4RzJ/zq3iBXrnZucq+N+c1YgyifsxIQjYGPEFvPQNI1BPD/op84ZQXHtt1A3/MFz+idX5+fv082ToZzofL9sgo7kdemzeWI5k1QiYRIHnPa29/R+ChCFsVbLyyM1CLSIDXXxGYV8eyp1tv37OMjpdZ8rMyfY+Mjv2RaZnV4N/aJAGwMKJ9zpRf87N5TYwUePuXl5chm0SJAD8zBtHgi4ymkZyKMEh45fQIG6KIEHhljLQJ7nv6e4ZqtrzW4g/h2PlsOiO6zm2KBhTXrZguHIJXnip69Ng23GdIAEwM8I0AWL6mC78xg+OCwUu1RWU/A4ZRqeYREUr1rM9KBvJMDCr5ecL5zE6feDah914Ufp4jktIjs8B/aDIL/qvKnmnDaQJgwsYSjakZLfU5YAN+XgMQiQf2vF/Nxztm4FCGPcpXva6W6dZDgnpCdVG5swRA3VOZBlDXPOMekb4oTbR2AHXFH6+Gx0V7bADVOZOIeCgCYJEc+ww2TqFZe+KfEKk6Wn0i8doQz0V59AC5Rw578zL9eDtDqr0yFJHqeXYq4kUTK/dF+1Xvv1JGpt9Mm+8L+Lfy/rP2WF1uhbyPSJkARF9M887hw8nzluhJ8VxmJpHHwuC7hai8vdcOlZHqBefMs/Puq5bhXa8a3Mjb7PWcFLB5deE0ETmIhMFevbuPhhTbwPsGf7bl+XzL2/I7Ozu7zp+jB5eXlzfePIi8QOVNqzZWUyheqLkCjJEOkZ5eW6rjKjHtleyZ63m2MiJVfS56CNkKEmBlrgTqjPy3lrfXIUo0HqLncaQ+0fgfkakIABsSZVDQw1FGOmPxVSDPDEdr24Yxo1fHMkO1BRseZeyZgVV1iB7enrop8I7GS1ROtO7CGxsK/NW7+fzuP4KwGtMG+Fg+Py+og+2fnJykzx2CQ2WrpjE4XyMWDDyj4B+RRXUcjTGvH2efoQhkPTD0jjEflS+TC7XNRIH6LLhw/iN6tVbvC+85rhDGQxE1BrL+Z/HsZiXCOzvup94CQEOG3gzue15c9TW0ykNebYTKIFo10FYSAM8jqXonlTJU+ioBUGX0tiOn743gsIGqLoxkqTywVfFeTVX7DB74xUD7kyAkKPzDe/mcAgsDeY4kqD5U5WB6/nnt7rWrMpgZEUXZikCzXlGZrG+lrlXpsVtZNGCVjDoYI2m3AP/e57xCgHB8HiphYZkmAJ4BiLy11vwP/GDeXAaeV7Ki0avMKyrXM1hV8Mz0QrCI7lthGFU/VAa68obUsXeOP67jCQI9p+VrHqgo0Nrtdjc8fFvMenV1deM7/hbKV4CAzwKT4+jZQf14v/LOv0cArE1UPTkPzssjHeqZ53/vzJ7dLQBcSa998MZwNe9VXjjnNwLqvaDUY7s8fSPpScv3KT1HpNq/0XWsh4qarRAPcxQm9EqZANh/lnvK8YMegT8KGyf1XrUyJnx/FmrsEU/vDOzUOfXgVAiAGpzKK4m8FO98xVh5/Ynnsa+8NyRQR35YuNxKXTzx+iaKBKj6nJycXIfr2dvGhXtedEsZNhvHOO/vtWVETCLP2tqZ2xMjClY37CuPvGTgj23igT7WlevG7YblVgluj1TsgWe81bO4hSeP/eg9J71EI6tTJD3gz7qMpo0chqzuo2Olhwj0jk1Pf8+Oe/sVfUZkKgJg4jWEBxAVr1AZEn5lSnk5UeOpcz0DtneARaBfPeYO9o57dOV2iAaSZ9RZIs9UeZiRDnbcGwUYIQGmu/KcFcHa7W4v4GMQZfBD8EcCgemjLadXooCfwf/k5OTGNwUMtPkVVyQA3p8FYd4R8HvXsZ2wzC3Af5VEQMXSY5BVXTPj3ksEWhuzceqeXuDL7vH6updwbTFmesvd2vtf6ei2tiACUGE4ren36CNW29pNQ4oh19Zu/tc6G+4RBmXpZ6XngfHK9vLw2G4vGVDghuftHmW0q29rYN74+qRXNt9jMksCuJ24nb139pVODG7cNkowLX/2upcUZsJAbfVC4LbXDPk5wrrbs6pIAP+rIb+F4QE/t5kiNIcA+JnN8GSV4Y/ARNnLFeVWbNZs32Q2qsfzj4B+hgRU+r6HpI72TQW3LN2sTEcAPADm8+o+TM/igT8aHGXk0HuJRHVe5jWPSDXPChHxmF+1HhHoR8DM+aIhj8gbP8QILKxDr/dXJQuRfiiVBYOq/njMaRn4bQyPfPOiRzzwVySACQA+P3yfbe3X2uN2s/opjx/fKuApgco0ChPT3vbptQVVkOJznh2rSDb+Rzx+1KGi276IwEweTIJUXltEAip6RZ55LxmokpFZmYoAKA9BeQlRlIDB2hZbtXaTBOBHhKJ7lQfY01C9A352oCnDxt629+dAJtGAZ2DDhW0sTAKUIedznreCOirPRQmWy/3KwO7VgdNandQ0gJqfxv0IFCr9ju2DBEC92qck++AUSub58zUmAUxmEOxxv7X3/Aso5sPtq6IB9uwaEbQ24X7at/Hm8iOJbImXT0TUI6KTlVM9r2QU6FWaERDq8ZwzgjXr8XPevVGAlbrMYteIlAnAgwcPbp1jj0B5CEgCPA8QRb1GiF8RtI+goMFjD1Z9uKXSkL0Gv7ezVQdzPr3z6xVR+XuL9qy9GBC8Fex4jydIBqOpoEhGSIDlrTw85c17nimCIuvrER9+3Q/Hrx0zQeat0kEJjnEGfDUFYMePHj26/uogeukG2ur5Pjk5uUUATFePAJhu3loG1MkzhFxX75jP9XjO3jjmce71lxofIzbCAxfvuGrbVN6RzfPO9ZSLwFo57+UfldULvCsJZkT4vHNeXaKxX82jV6a+BIgGgx8MNqzc4V4F8O+C8ZUr9qYiImHejZWnSAI3dhX8RzzBLO0swM+IB6Lc3nhOAWYkOC4iooZ5cRmVlfwIPHYNiaSXpnI+IwCovyISlgb/ZbDnoba2MzFQNgDnNvX2kQTwWgAkAdw/KPb8McmxOqsIniKN/MPpA68NsrGm7EvFKPN9GcmwNJ5tUXl7x9Vr0T0V73Ek7wpQR/dl+VRxIZJVJGtUovxWATXLTHuhLCEAJhbqY4OPCntiDz7Pl7IB53twW/EOe0WBHO7fJXhXpWfAcz25/mzwW6v9fbHpwd4o6sg6ZOCP+iiw8aIWimRk4M/gpfS2dsapKmwDHJNeBCYTA/7dbnfLo+fImyICds3uU1EBdQ+K6nuvDbM5/mg8YBTHIwY9z3kESgqIMqCOwN/T1csrE65ndjwiVSCbAbtqhKMqo0Cu+n5Gj6iMHvH6sfd8VaYJAAs+yOq9fm+LBoMNN2+jEArqFT2kFe/f07e1+j/wsWzFCFeUqwxh5ilHeZlYn56ent4AFQQdBsRK/txXCujRG8VxhDp64M/pWXiOngFAeTvotVfri8BtfYTnLKpg56yd7Tq3uZ3H6RiMCnAZ2MaWBz/Xyuvn9lTtoepnvywiwOIBuSpTHTOIe/l7oO/d03N+pYyAQ8VZWEE0WuuPnlYjGj35rrLH3G4z+XpjNzs/IlP/BYDhTBQzHjyvqH4Vr0sZYZwGUIMDVyR7aSLxmHwE/FUmj+Lp1Kvr7ECOHrAIVHGr7m3tNtAzAcje08/0ZvC3fdNThaCjMajyUg+fpzPfg/dZfbntkABlbYFEAtMrT5+PLb2d4+eI11mgTmpRotd+eKzGh+eBrRDOMwL9irMQlYHjInv+V4M+19N7hkdIAN4/IxHYVyMOqMsIeZiRnvar4MwIBq3oU0/KBCCagzWJGD0v7lPnMT8ur/ogYvlqwVnUeBmgeTr1EIBMKoaxArgVyUAfz7Exj6Zk+NgDehUNiCTTVZEUL4rkEQIP/JHMevqYqMgB1h+fC85zt9NvLCCZ5X2OAHjAn3n/rbUwOpGtw1CRFfVDMT1Vuh5SyMDNUiEEFfBnEPIiDlsAVMXwryIBJr1kIHNoVP/z+UjXfZOsXllNZltb36coS/4OmI03P9Q4p4/HfI6lyqQyJjzaWBkhqBKAyAPic73A76UbiSDwfezJKgBlvXCfPVMDtygaYJJ5aVgeL/pjkqIAXYGWSqvqq3Tk9lRtgyQAnw+7lo0jFTlR7Yx6eXP5SALQ+1d18SI0Cqg9wK88A6yHEZ2R6JB6BrzxpUA9etZ6gX8GlEYAfytZUY7XtivyngX/Hsdpq7yjMj0HaCbvJQSABR9c63D+FOrl5eWNY8tfeS0eSLABM1FpTN8qMWDDpYyc2o/ahfNH0F0F/itEgZ2qM56LpkbQoLemvX3uZzwfDX7WDwkmH3u6Z+CP95tE7+hnZJYX3qn29hZJsvfeWrsVAbB0qj1VXqaHRwS8to6An895gjpaOgb+XiKA42WUBFTKwDz29XxWAN97XvZFFDLZos22bP/escGyqt29Ppype5kAqEI4nMkPvl3HECIaZwR//gMWuweNG/74WwB8bHnhvbZvMhoViIxctTMY2LhzPcNVzT9jh96crt3L4Gf9hMcR6PO+9SmTsygakJEiFPaKrXxsB/zoDYfAvZXxdi/P0VfASIEfgy+fZ7Fy7Z19TFsZ0xz+N72wrkzkeOrO7uVIC+YX1UNFbbLxzOkjzzp6JjJSze2yT6Jt4ukXjfuRaxUiVknbI1E/Z5GWfUlmX6Lnq6dNZ2ULAlcmAD3CgBiFYlWYGY0kA3wG/N6qZ+5EjyEjYLAHW/EeM4kA3/NavPtRd+++yDhHXq0Cfz6XGd6e8+zt8WtzLEgOeN4axxbqenp6eoN82v1ZJAYJqR1jXXrWhuC+evceBeuFBArTWp0y4fl+jIqpulgbIVExEuWR08jY43jJniFlG7xnj9uVtxH54PRq36uPR3R6xQOXu/bWZ8G56sDsO4LC5e4jzYxsnX+ZAPQqwh3qPcgReDKon56e3gL8iCBE+mdgWa2jWvClhA1uhfVHK8PVA5rl7T18qgzsFwX+igBUjCKHrxF4PaDFdJw3tgO3Mf/9LupuwGaA5hGyiBCqNvWAKBtbXDa2P+pnxAjJTGX8mXjAb/Xi6TKsv0UhmBiwqLeDLC9eKGj7VeD3wNlr58ozPdpnWLee83xdAX/1GV4BnLO2vWJb+dpqIlAhLD31vEsCts+ypyIA6mMmHpNWD7eaY+UvpdnPwJ/fJbePnzAZsPtHRQ0mz1BxhEA9xDwP7glHPyzfnlflqg8RpmOw5TA/gz8SgF5vCMPMHBFhIqAInRfdUR600tt+2NY8J2/52XkO+2Pb2f294IT3enXD8cahefwKoCInKJlHy8TM6n15eZmCPj9visTaNJ9aBFkF/QoB8Oqn2oJBJ8vXpNdrz87j+I4IAD8vnqwgBT15K3JuoqIteD4iE731qORZzeMu5C7KXjoFoFg9P9h4DffZ4+Dwv4G/B/gqKpDpqI6juqmfmhfFurAubGhNmNSoOsy8L6/q4x0zAYjWAKhQfcUj4JC/peM+rbQXt52dwwiA0h3BHfOy+vB1FQXwDKLXzkoiUoi6Zc8Q6qXSYCg/08HarLV2TQI4f5Ro/GLeFnFhQ5+RAEzntW9vu2e2IMtjlgiwrfL2VT9HdZkB0UhU+/SCqwJnT8eKV+/dNyKVyAXKyratOlGryd00AfCMu1qMFYFoNAgM9JEEVAkAG4WMQfN5ZfA88Gci4wGhtU9kKJSRbO32H93MeAKRwVPePhMDbAMPpDPh9uXFgGrVu/IwcYxY21kEwP5AiokAvnliPyQGPI74OpNWBiuvbdkD9cQbA6rd7JwCzJE+4rd+7ENgnIdap8P76j5+Pvh5ykiAapPKcSTZs1Tx5NV5dcxAr8CfiZ+NNTXuMru2WipkgEk1nmPCspoE9Egv8EfXqsSz8uxH51e1ybIIAHuD9kCb0WSQVEDC3iAD/9nZWUoAWrsdPlehW8Wm+cHia1gH9aEZfJMB64AdHjE9NgBqlf5uF7+X7YlnGJUxxfrY1uqMr29iHTlkn+kQtT0bDiYBlkaNEYwSmf5nZ2c36mJbS4eEAMcmptntdu3y8vJaJ7uGQBkRgKiPVP/jVqVV+eLzpT6BrLxEryyrK5MQJFOYF/YD/+x++2MvvJ/HmgL7CsFS53r6oFcqfZbtK6fFc2I8QsT1YoCYAVAmGViOKpPvVVuPCETAthUJGAX+ap4jhNIbM5zXqjaZJgDISNEzwlAfA300iHtYtBIkA5EBiH6Yxva9raoLkhlFKrCtLB/2KKN6Kk9J1dGrO7cDn2ev386pfawv18vqGhkPte/dwyQRhQlhNG1g4GY6MxngsWtbnAu3scyeW2bQ1Hj2CCCLFwUxQQKDzx3qy+VwXkiiPTKn2jkCRCYI0TqFEfCvAH/2PFQNvgfkapvdUyUAFVF2pvdedT46F9mpzIb16rdatgD/imR1qbZblexmMv0pYCvcfmYozTAo8FeGSBkTJBLo0XCo0RrNjF7P9IP380C2t6EVE7c62KpqbA/0Ktn4eSFS1mtkAJlwPzPYq30GPnyvvzqg2ejZOOIyo3HIjBl1R8A3vRDUDfjRs8dX3qzPeIzYOd6yTl57MwHAOmSAj9d6xmXFeJi3jmJRFo7a4bPIeWKkTE0pKYLkkUEeTx7ZUu3heVOrgSC7JwNqtGVYL48cqXYcJQGof09+WCfeZuWNnFshGXlpbY4IVPT2xjL2s2c/VrXLFAGwgcdGsrXH3gh6H7hlw9za7dA9A5+dR8KARohBJwN4fniiqQJlrFCiwaLuM72RBGB91KprD/jV4PA8N6WXV//qoPPq15r/RbrIk/Ly5XpxehtzSn8EfpxK2O0eT23YmLIIAZZrXjX2EUYEsM4Z6Kt6K+Dv9QJ7JZpGsnZRbYjePOqMuvK6AyMU6rnzAN6uYXsqQoD6RSQA041INI6z51/VKRvfDMIeCVgp0TPfSzI9whaVV722QjKgj0jCTHmRDvtuoykCoAY/gpn6B0EeuHYvv96HadFwMPDbvXgOpyK8X/SPdtGgZ0IStRevibD70ctFsMf2sHpERMRrSxYeXKp+ivzgsWcYOC/uQwQCvM5pMxLgGU0WBSq2VWXZWLDxakB2cXHRzs7OrvPC11OVt29pcE1ABkisDwO/6s8VRjEifnYeo02mG65xOTs7SwnhycnJDcBXBEC1SQbqo0C/ElB6gSEjAYroWDnqmbd9teVyRyQiAl56Bfge0amWm11fAdAR0Ge2NbonO1e9viURWjIFoMI/0Rwi3+t5QmY0zNhaWNbIAuZv5xlk2Phwvr2sNjquLs7DNsL5WmsDS4MhZzvH+1ieN++tBjjmlUUZovu8hYrcp+wRshelxgnnb/kqwIraGAEVo0XondrxxcXFdR4XFxc3viXAJIYjAtZnqL8H4srrj54Fblc77hVsSwZ5HlMI2KYTfo6Yx1+UFy7yw2fRBJ9ZO+Y6V0BmC8/fyyMjryyV/uI6VgA/I2IV6QWgLH3k0fbklaUZAWgvnyyKo6RSbi+ZGk07IlP/BdBau+EVoGHkuXgVCo48QLwfHwLMG1do49SDEQQ0QrzP6xG8+VbuYDaakUSkCcEfgYTL9QiAmhZhMqCIGesdef54Xhl7u1+BNOaFYwP7tfLwqDIV0cH8cB0KgzV+UIpD2R5JwnFm+WB9eSoAz2N/eeOK9eQIgGdAIrCLhMF/t7sZEVNjDPW2emHfc564z29gRAST61yNAIy2xeh9K8TTW52v7HMeVR1GrnnpVf/N5tlb9qiMkAnUbwXB9PLeSqYjAGaocMEUzulbGuwgA2gTz6B7ZaLhxoVJPC9peTDgq8WICMZYTi+b5flgJVg2fmAF25JBhvNkUsCggWsjeh4ONM68ANCTbEoEQdTSc7SmtbztPGBiwLG2Ozs7uxUFsFcF7ZVSnHoy7x/rb8CFwB95ZbavSJDpjvVlMsz9aNei9hgVfh64HbkcroORVq+/MG/+EJMiAb0RAI8EKFCNxn+1fSNPv+f5wnvUuFFlezpFaXt06cnL0xmv9djM3vK3lhEigPdF53ra3Du/kmgsIQC8NQPBhtP20UtHUtDaTWNux7ZFAOAIAHomaAQY8Nmwt+Z7YLyQLZsGQX1ZFFAg2LOn6k0lRMBjx+xteyw8W/Tn1YP7yKurSRSZUOe9xY9YP7yGi/eYWCAhNK//7OysnZ2dtfPz81vj8Orqqp2fn1/X0cYqvjqopgM4osPghPXEfmHA52cC+yoCvx5RETFerY/6mpheuDYC87Rnm58zD/gjA6fqVwF6lVf1WkQaqmQg0mkGDLaWXuBfmXaV9Dg61fxQtvbws+NRUhXJ9BRApZFwPYAZXAZxDkmiwWevxAwuRwEQTDlPNj7o3TLQI3CgrlhnNmBMUGbEY9EeAUAgYm9JGXNua7WvPoqT6esdW5kMJtjWSAAUCagYe85fjRHz/I0E2GI27lMGLQxht/b4y3gnJyc33hqwe7y+s7rZvdwWWA/1wCuv0RsX6pnieyvtyREJu2aRHMwPST4LgzkCOYMt193rf48MjHj8GeDPAsAWBnxUDh3MD1HYLs+KGrP7busliwBZ2MiYITFPCsPBuKAP7/VIQGu3P/vK87no9SpvFY0hRy5YD7zG9/JxFrq2vHrEaw9uG56uYK8yy4PJC4I/XlNgw/vqWNWbSQASAKsTer6cl4ra8DiwH4b8EfxPT09vePyep2rjGL+AiN8K4C8jcv+oPlBepIrYcLuqn/Lqsc94y/2Dba3W61gabnecrsLnWJEDnmbjaAn276hhXGVEM5LgXa+UjeNjNI9KmhkdvXwqz/WzXdDOZuLZLrYBiuhmZaxo+yVfArStAsXWbq8TwDUCbHAicMH8PAKAUYZeQRLgGSWPAPR6/RX9Km1r5XL5KnTL+SpiZFsVGvbqmhECz5NlwGb9UU+vvTzAt3GAYwMXABr4379//7oML0qEZBH1wHGN57i/cO0At7vqpwxkWHAMeLqrc2rMet4+64RTGVY2rmfhryZif1saJm8mEfh7Hn9VKm06Ej3oSa/OVQlPT50zYjWS59MI+EpmSICds3w4jRcp2qLtpwhA5I209tggKa/UmwO1fNW+HaORN4POpEAZLeVpWX4mRgK8hzQD/+xhUsaVy2Ajp8A/KxM9UlWPbKv6kXWpbJV+qu/tnJFEnJYxHbBdMA+rJ55H4Ffev3n+Z2dnciGcGtNIVFBXJgWqf5hIYHoWdc5bF+GNDT72Ft5hmViGF/7H58oDfAX+EfBjJMAjqxWJyMEI8K8mCzxWse8iQKhIBZBmwf8oN6WXBOB9eN4D/oOKAHiDR82V2lZ9SUwpziCYCRp69vr4PJ+zLRomNEoIRBjCtPpGIBwZnR5DoYyYKtcDZc4rOhdNW0TkjuvsbRlQsM48P2/neRqCwQPvR7A3IqgA//z8/Mbv/v377f79++38/Pw6P0VIeExgyN++IIjp1NcIVb95bV45j/nzc4drN7znkwWBE/vBhMm0Gsu9ETArT5EA1Enp6enP53pE2Sa1HwGmZ7i9tosIi2cDVHnesdIlSstlz0iPLnxthpSs0H3r8riu2THfE+XXK9MEgI0M/sxIepIBv1cxBPLWHq/uVsCvQMLqwmFMrKf3UEZAqJhc1DlR/dEAZOCvgFgZ5IrBwLxxP/M++T4PEBTQ4kp8JidsmJUxVWTA8sVpAJ7/9xYBeu1qZURTElx3zAenAjwg5n7JwN/rD3wuozK5bBQP+DF6huUpcs372F+KBHA9VwFDJKru3rhDifpJ5cN54TMekYEZwbxW510pk8/vE5xXSQWEe6Ti9UdlrmzDaQKgVosj+KvPAWf5ZqAZAQgCP3qE+HDhGgEmAQxATA6qYFipR5bGK9cDqqp3jmmiMlvzvz2gznn3cBuZKI+by2CQtz7xPHUVEeJpAI4OWNtlRKDiBbbWbgC9tQe3AQIitxsDROQJcv+rY17Mie0f1YGBmdfuWN5qPQDvIxGI5v9Zv6itVcRgBuQyksljoFpWlUyo+ngSkY8Rr/8uhfXdF1FBqZTnEZgKsVF1xHLVcRVL7iwCwHPE7G1wyFMBBOfPleH5eVxIyEaIDQwuTDLgt/+zx3IUC2cvRemqwM+Oq1GASBRoKtBX7cwEgAlCtfzqVi0MjPqbgcV+7PUbyWQCYKCOnj6DvM3x82JAJAiKPNiHpWx9AE8TeGRYtT+OK3w+7Bzue+/9R30T6ZFJdWxaOgRz1EGVx8+X2p+VCARnxfO8snKUHWPbcuiybx25XQ4R/Ct5rG63bMysKG/qNcBoYREaCvRs0NBlgMReclRh9ETwXhQrG3VRXiSDU+SlWL4oCvy5I9kzwjTqgVDeP4J/FA5W4Fw99oy9l6dnlBWbPTm5OTWDpA4B0oDYjjE9e/QI9kYA7IM/WAa2DRptJAF2nqMJlvbk5ORWhMuAktcx4PiMPFfb8vjF9Dwe1fjj9GoRobrXBNPiM4Bf/LR0HAVs7fY/M2K5iiwpYSLF96n6jxhzZWS9c5Utp/fyWVWPQyMXIx78KtDvbYMRPbMIixclGNFvVJeqTP8dcOTdKU8dFWajxNfwnLpmOigdPS+NjzkkaflzHVgHpYti/bg/QgI846lWdrORzKYEKvu9QK+ueQsA2fO2n6oPA5Ka4+cIAK74ZyK32+1urFRXJMC+eKfGsp1X9UbAVdNL2RoCy8MD8eheJrZeejW2TDdrY7vPIwPWhrbF9T+cJ+evSIAaw0q2AFC7xyMC3hiPngfMV5Wpnsmq3qzToYC/yQgJ2LeM6pcBb0YSonHBkvXrLLGYJgBsoD0DhA8SGqXMSHHlPM/etpaW/+4X97Eu6lO8ESEwfTAt6qbAW3l52K7eVAOm8drb9hVQKgOrrnGbeGk8EqHEM5iqDdGjV+XyOQR/NQUQTQtwGyNgmV4G/peXl+38/PzWtIE3plR/Y3qeG8e2UMSPnxfUPfIqeZzhOLayMZ0aNzyuLT1HAJAE8FQgA382ntQYjYjBCvBX4j2rXjm8ZQOvwDoC/0MHzqocMklZNUay/KNowEqdRu+dJgCqcAZOZVCi8L/nVaNXosq1c7x4z84b0J6enraLi4vrcwrwrWz186YMcC0CM70eEqC8DmUEMQqAb1tEhlUBfmbUKmQhEjU+lPfPr1164hEA/mG+PO9v9cJQtdenJyc3Py4VPQt2HceUmgJQYMxt5I3PiiFVBNvGGD5/TCb5+VGgj88Wev3YnhEBV+OT27KHYK4A/wz08Xms6sZOgLo3yjMrp8fLXgG+I217SKC/WjISYGlaO9x2mP4UsDcFgPs8P6/SqTwU+KtBr8LU+N12XAxo183DY7CP9g1IrOPxXiYnWFbk4WEdVCRAGUoO/at3z3HfA/0RsI+MswIxdQ+TKQRxFG8aiNcA2JYjAJg/7qs2xweV+5j/YChaj4HpUOzjOGpcoz6qDVkf/BMrfs1WeV1q7QEL1sN08frC6oH34DjEMRRFAdQ4jcYv6tqzj21RlYgQYP5qq4h/VlakdyRR/qtBJ4qGjEiF4PTIXYCscm68dJWIwb5l6X8BKCPP13COsepJcohe5aeAzlb985sAlk4t6uJy8Zp1IoarLZ334FfAX0lkeBBw0Ogq41mZEohIgroPz1n74Nb2IwPoRQAQ5JmEIWnwCACe4zGDx6q+kYeN/aHaHEkZt0PWdjgeTdDr936eqGveVJs3lcR5cRQA24Xv9aJSqh1Um3jHrFsP+PN5tk3Zc6n09EiAytOuec9DVv9I7sq77IlAoFTvwTZbKVuCbaSzd+2uwL+1hX8HHJ3jMCTPfyIZ4Pl2z5Dzw4Zgp+YvMQ1+wpQ9dywDjZ6VqdYg4H2VOX3UW0UBVDplaBHE2JhG3j7nF6WzfZWvifLU0fApUGFAN2LF57j/mTDgliMAqLvX/tgHlj/qqATnvPmPhBD4GPwtnUd+cVwjUWUwrYr3HPK+B9pKeHziM5ct8DOJxpn6KekFf+/+iOx5IB6RgMr9Vm6FCBy6jJKAZ7tU7f9dS5kAZIYhIgJqcZDyGCxta4+BXxEDBi/et3zsftwisEdArdYhRIMdQaoKkpFH53l9qLPSK/KcPJIQgT7mbyCtPKlom3msqGtWH/ZimSzidEJksFUdWVe1ONQWjVo5TBKjunl1QvGeIx6rlTZVi0PVM8jz9SpSYIL1Vc9h5RjbJGoHBZxRWt7H65Vj5QjwddapR0+UZwP4m/TW/a5JA/btaj0qdo7T3mVblAmA90W/qmFnQ8NGCcP2Cvi9qQPPK+XybdCxB+Y99MqIGABGbcBAH+XH89PsiUbeCRMATMvtzL/KWoCojp5x9M7xoknVPlguRkKwn1SdcWEnnsO0WC8PIJhk8b7VA9cWcLtnnq6XzhNcn6BIoGoXJtUe8bYxgv/2iOl6RAG9bb01BdkYy0CVr3mgzPl6RDXSxRMG/6jcTJ5U8DfpBbO7JgGoRyY4rrYoZ0tCkkmZAFxcXJTSqQp4gKPmm3GBEwK/ncvut62aT/U8E8xfiTLyHIqvhJy5LF79blu8lg069EI9758Ne+Tx82DPtl7dUDzARD2VXorgsKHnFevWbvYOP7YBgyTrZ+3JpAzH4tXVe74QyK+Pqnb3xgqWXyFWCPq8NkD1BRJuBH4VeUPyzWF81UeWLuq/yvQTSwUQGGSiY48gR8TZKz/Sl0Ef9VDHnDYqV5XZk/4upAfMVpMA1bYrpAreW5a1VZ9PTwGwZ4OiPAkvPRtyjgB4+WE+USMxaNg+bqNpDgQJE/UVuGpHGZCoe9HjNN13u8evMSIgsDHzwFStE8Ct2veMpulWfTCUh81lKmCIyAjWicvBlftIJpgIcD3Vn0ohEVOLC5UxZ71MmAgo8OB6qrrjPq+pUeSDF4yq6AATRAXm3F/qupemCv4RWGIa7ne+rtpMgT+TBqU/68d18PRXx6qdIsmI4kiePffNAFyFDKwmAfsSr116CNBoeSvznZ4CaK1mFCqSgT6DTvUBUoSiV0d+hQx1NkNiXqGnHx5bOlu5zmnxTQNeWMjrANTrYFYeGnnl3Xn7niFTizIzibx/1tPSZ7owwNt5BG0GQstbrSPgsL/3428KKP24XsoLVgtQLS8GeO5vBXBcLof97c+5PLBXRIDr0Vr+/QiTKI8qGETg4AEx58/gr354jyrPA3yPPGTPRdWAjxj6HkAdJSBPu1RJXmQXVpS/gghsTgCyAcSL7Ris8YHKQJsBWnlZmHeP7Hb6k7a84tvSmkRRC6srArzlhZ4yTi+g94hpPYDFvsnmYfE6/mcCgj96yFXxvC5PKv2M4WwuiwkAti+vAcH7GPxtvp/fNojWeSigx2OvH7IoALcbEhkee/bDz/PifqSfCt9n5zJR4L/CeHmG0Gs7JnpMAJSXH3n+WN5qoNzSKx7Ju0JsIuklc3itR6p6jpK0CPyVPfDy2HL898j0nwGZRMZCeSr2IKqvjHmAzx4TN7gCdyQBWX0svSdctpEirAevqPa2BibewisEGvYkzfBHbzGwZ8dg2WPA2SNlgpLll61n8LxDzxvDdmPDjeCNdWbwRxKg5vwx7K/+SZAXA0aESLW/tRlHEhCU1FsGDPzq2cKyrq6u2uXl5a0pAG776BxHAPA4E3v2sghARF45jXee74vAn6NS/Iz16uI5ACOywkPckkCMSg8J2DLiMEIQ2M5GOKTOZ2M2kqwvZ9pq+jsAbBz4PM7tt/ZYWQXW7P2re5ShVUQgCsVnD0ilQZVnjaCcCZfBC9kq9ysQYEDg6YEq8CNxwsGvCEeWZ0SGstBzlCeTIjXfrcpQ5xioOG+lj4oYcLQGF3h69cHnB/vUwvZcL9wauONvt3vs/WPeipxy3Srn8Ff1pLy2za6pvDJh4+w9I3bcS2Yq53r0RcnGSI9tetJkBeivJA4j7VgdTzOEYKWUCUCvIADhMYsK9xsRyEgAglQGSh4hUB6U0vvk5KSdnZ3dMihosPCrg3aPZ4x4Thm9Eq+98F6ss53D7xtwZIX7I4uAIBgxGbDjaAEYn+M5aQQrDE2zvp4o8H/06NH1550VoHuvR3qRG2wLiyggqFr74D8Pcr9YXux9Wn3Vugesu5EAqxvuG/jjeQR+JApcr0roH/VT7eb1d9ZflV8172icRFEFz/PPypwlDLOyIr8RgnJXANUjVR2V/a+CtnKEeD8qr5qG9dtKpggAPkxm5NBg9CjPnj+SAH5oPRIQlYl6qbl8vIbAzXOG/BlgA0qVD+bPxAHDzOj1M2nwztl5tUAsigpkHgafYy/Q8sB6Z3k8evSonZ2duZ44EgCvnmrf8jZwRgJgojxXrpuNJ/WHSjaurSzUE0nb6elpOz8/v9XmSD4sClCZTjOxOjHQM+irn4p2MPh73+ZgXVS7KX094X73jrPysufcI9zRWFVlcJ3YxtwlCVglVfB7NoE/S2/feMBfzX+kvC2lTACqilRIQJQXgruKBKh03oMZkQGVJ86787w1A7YCIhWN8P5TnueVOQLgiQfwCiS9cxUSYG3PRsKMdjTFos4x4DP4I7lgvZHgqDKs/e0tDFubocDEtkpnIwHKKzSCgX+8ZH1nnr/3sJv+TC4xHeuG5aK3zyDvEQGeCsE2t/6IiIDqR29f1VnVrwL+GfB7Eo15T7zxEZWh0mQgv5oEVPLqAUS2ZSN5HJqMRDlWyyz470M2mQKIwszqoWbvPyIBOCj5PvYOIm8B72XwRS8fQ/RZXlYmkggENAX4TCy8MpSwscNoiVogiIYIiZrqE7uXjSNGZaogYGnRC0bP3cBAERlVB8wTiYT68xl1HIEUjkH02JkcYJvjK4lRvS0fu88DRARpz7v3CAGvGWit3SIBiggoEI7aK7qujj2wjwhApeyI+Hpby1eN7yrA94L6LCD13hfZvkieRNCPdO7pp+pYY5vknfPyPiSStYwAqAGeEQEGTgR6D/SVeETA7q0+DMozx58XHsV9q4etF8C8MQqAq8u90H2kJ+bprQy3NLwwUT0UnvfF0zB2TunoPUA8B62Aj/Xv6Xvz/C0KU/1qJQoTCzvmKQa1tgQX+FnbYr3sr6ejf9RDAmP3XV5eXhOICPAxHUdVmOR54M990iuegeMxxWTHIwB8byb8TPB51pWfgYwgYn6jII769ORRJdqYP6a5a5DZt3B9q1HPTHqAv5d0zPbR6JhcHgFQFWHw9MDHzjMJsCiA+g4/ijLObJg9HRl4eXU3koBoYZSRCBXSRq+f/6/em17wvBgEPDXgvfOmsydodC09TgVYnzBZi8R05YV0agrAI3FcN257/AiTGifeug8bW9ZXGDnhLepueVr5uECUCYC1lepj1B/v8Tx7FQHg6Ql+A4Lb3PpMEQDbemOH97GvFGArApBFA/he71g9Gx6BrpDVqDy2H4pE9Ej13oqefO1pAvysnyMZJboqMlktJyMi++676TUAnsJ8nkmAmn+0+xj40bD2NBBGBvBez8Dxh19sfpf/oOjk5OaqcTS0dh3BDMvA/L3/rfeEV/ezwYv2vbwrBhiNFRIdD/g9Q8ogwKQA66keCNznvFSfYP2RxGA+3P5WNx6Hli8CJPan9TcSBQRzJnpcj9Zuhvyvrq7axcXFLTKgyAGXh89Udg7HLtYP28l79pDscD9H/a7GHEcqovGkhMd5xU70AkAE2rORgapkYDJiJ59G6emrKjgrUhjte5GDffZdmQDcv3/fvZYxUvYgW4v/m9zSmddvhstbRKXCxegp4z18bKF4BGV1jHO2V1fv+R94b+4U8zg/P7+Vn4EFvj6Gv/Pz8+t9fOULf9ZGZtiVZ60MLrYPTh1wXzJIcn9iGs9DV/2jPDHLE1fic1okVcqDxpA5RiiYjPE4wIhD5oXyu/f8Tr5du7i4aA8fPmwXFxftwYMH7fLysv3mb/7m9bmLi4tbK/qtHzFvfMffvHpMq7bc5wz+agzYVtWf71F9x0CP9yiw90hn1VNib1zVKxMeQ6q+kTFXes3KCCHB+7znUd2zhT5b5eHJTN1mysExqCJDlobvqepaIRyr2rVMAPCPa5QSuI/eHAI/go4nGFpGr04takOPi8+hINjzvgJ6b59Bh703E7zHvvWvPH48h+D/zDPPtLOzs3b//v328OHDW54jgjC2myIADAjcLhylUKI8VuVpRMCPbY+C+mHfezpEJIKBzsgAjh3MB69lXioC/cXFheuRG0EzoLffgwcP2sOHD6+vqXl9zuvi4uJWf0aevQf+CqBVuyrwzrYK6NU1JPhVEoD9y8c8Jj0jrerqnfOA/66kqkMV+HoBsuLxzlx/NkhlzIy2wz7ar0wAvPl3BYBoVKO5YvSqUewefIgVyGMEgcO2rd0EC7Xy3s4xSCvw9xYCYhuYILGwMvgYyzOP//79+9cEwPZPT0/bw4cPrweYhc3xlTfP6GeG1dqFJfN8MF/2sLmP2GtXAI55st5WBuaJ5xhkMIrg/dsi94GRUw6lo/eNXjkCuHolz0Df9i8vL9vDhw/bw4cPr89F4Xye5+d5e2yvzNtXRIDHsPIcI2DnMeGNtwjkVT+rcRYJjkE7Zs8sA/0oDItbVe6sgd6aaGwdSt4C9HrKvktRJLS1wyGPVZmKALR20/CyMTZjb/PWGJpVwI/iRQmYGODrVa35A4OBn+fhOUSvPHcrLxIGOTXPjwBk0wDn5+fXPyMAzzzzjAy/c9uwlxgRAmwj9og9z5qPmYzZNW5/zp8F9cIxZFM/3K6enq3d/JiPpbm8vLxenMeEAscC1zF69c4IAE/J8FQNH/M9lYV9Dx8+DNuez1UIAor3zCAZsrZjL577r0oA+DrvY/48VlA/ZYAroK/GYwT2kU53IRnAePZvK8BcBXgV/ZSN6bl/tSh9DmWcVGV6CgANNwM/GnNe6IdbzjMS/NKb5cskAAEEvVP2vNEr94gApkPB4wj0GLAY/O2H4f/79++35zznOe2ZZ5654d0YSKB+DP6esbV24egI64htiFEW9h45Tza8SHYyzx3rED3Iqj1xvKi1CTj1xCCCpNTuR68fPX0EcPTmFcgzoCvg98L/vAZAtT0Kk24F1hn4c9/jMZIKRRCVRODPY1Kdy8rwwL8qnv3BfA7ZkHug60U29g2OKmKSPdcVuWuv35NsrFT1HiF2s1ImAN7crAr3o9Fgrx9DtCYKFHDL53a73XU+SAYsf/YElNcdzdHzPgJuBu5YHyX8YJoO5v0b+NuvtXYDlOz/BtgAKiKAC8M8g8FRCfxZ+3K0BgEFQ+jYDl7EQ0nkNWZtzver+kXgj+TE2hpD9ziPb8cPHjyQ59n7R9LG3n4l/B/9BbfXjhH4RySNiQCSP2sX5SmrPquQ0ehZV8d4nu0FHqNuKrLBdVf5Y5qKXvxsrDDWPaCi+nWfUomcZJGZ2fIPWXhMRddH8xiVMgGw75yjINC0dnM1vwEIemEmZnSYCGCeuO8ZGwRciwQoUUBkwKtC/kgALArAYIGEwAMm01ltmYQYCbDQvxEAM6gGSrwoEYE/8gDRi8ToCAMhAyKG1DEP7GfPa1LAzYaLI0gZC2ZdPJLY2s01Jh4BYP2xLXFFv/1wRT8SAo4AYF4M8Lvd7hZB8KIB3JYmimyquX9sGwZG7PvWbi6S9cYytlXvT/WRd47LVccKBDMA5nEYEYZoLFaM9r5khXe9D1lFjlDuqn6V/s+eoZmyV9W7TACiAtELNKOCXj+G6jEvNOZsWBSAIfCb8UYQV2F7A1c7toV1+Hqe8vwVKfDC59gOJgiQFa8hqq9HhLx+irxtzztXuuEW56ZtH/vS9rne3rhRIOx59xEhVGlsywDBAG9j08CdwV6Bv22NIHCUxdNVCRMz1NHIgPUZ1oe9c14n4pWDQMdTPEbI7RlCEqPGZySKEHL0IPIavfwsTzVOegxiBPiV+tm9mI+XZ494efbmofY93VYQmZF+XCVbkIoVEtk979woqZiRaQJgHaBCwXjeSID9K5wNcAvd2x+qVOYx1YI+9QlfA3AmAbZvJCACfm8NgIlaC5B5Mh6AqQVn6BWquX7V1kgA2NtD46nqhIDkLSo0cLB0lj8vGlPAiMJEhPVjvXB8eSQFBSNMDKw2lXJ6enrjvX37IeDbPq7K57UQ2MZ2nj1Nu25TK1XjheOe2w+vc109YQDmqJ2l4W8MRHkqiTx0b4vpvTy5TdU1Ljc6VlIlArPCQN9DJvg+zjc69spfLZU6rPCIK2WxXjP1jsZQD/j3XN9Cpj8FzAbZGhanA2zfQB6vMbijcWVDa+l4Xl556rzADvfv3bvX7t+/H04D8OuAFS9LCZ9ngGWg5bAxk4AMTJmIoYHFNROep8CkhPW00DX/7S578RgRYrDGqAOCP0dZUCePAKgwt/LCzbu9d+/eNfhbefh6njf3//DhwxteP45NVX8mA0gIPJKj+gDbIiMC/CxhHkrsWWrt8VSP5W9jTUU4IuCpSCUC0GMsqzog2LC98p6rHu92FZBW86oCzZbA4tmifZAnTxdFApX0eN6R3DWwz+Q/RQCYrXpRgNbeM7+IRlsBKgOOpeV9DvmraQAEfSYB+AU+BfbedwCUYUXjXjUieKxAlsFfXVfGXrU16hh5/KoflG54DacBlGcWRQAQ+DkPHhsM5Kx/BPxIGvF1VIw4RK/r4Xv/HI3heuFiQyQsPEXG/aX6w2uz1nwi4IG/6mMTNZWA7YxtWPWKKwZJgXFvvjzmespj0oTp9i0KMEfASbVBpS9GADtL35PnqjHVk5/Ke4u+H+2TfcnUFID3ELMnwQ+pF05Hw8NGFvcN6L1pALvOoI/n1BqA7Jj14ZA3tokiDAqUMT/13jl/EAYjIgr8TR/2vqvAwDqxfjw/HQG/Aa8XOrb03JcMlIpERICvQFgRDNtiO/P0i+oDjMZg+Nzz/rl9kCgoUf3D7YZ9amVlYX9v3/LDKIBqU/6xkVcAyzqoaJPdq/KK6l/1gJUOVpayXxFh53K8+veKB5gzYLEaaO4SWFe3jZLVUZwnQZb/HbBaEMhpogfYDKzts7eJUwAe8DOAR0QApwH4h+F/W8PAwMagnA0iBCgPUHg1OHv9DP7clkgCTDgcHUUzFNFh/TAqY2Wyp41twYaSwTICf8uHpwAY8E1HLE+NNSZL3od/bFoA258jIlwntQbAxiW2C4/9jDAqYSLA/cn7PWkUwYry4zEXkQDWPzrvnfP6syL8nEaEeERYj2peXnvMlo/nR/KdBcXR9siEn/EV4rWRN569PHrO96ZZ1X6tLZgCqF5Ho6dWfqORV6BjiwWtIzDkjwv+1BoAfgOAIwAeCfCmAXARnAlGAyqiwIujAN4UQORRZ32D3hsvkjM9GOi9PsF689bKefToUTs/P79FOlTkQM3/o264X/FQTbz2QpKj3sW3+tq6ByZIioTZGDEvnxf78XPA00vczhXJvNiqd5vteyQAwb/HUGZeXUYEsrSsk9KthwR4+laI2qj3nEkVBJn0VmUl2KAuK/PNyGOkh5fHCAkYuTZCXlYRxdYWfQqYjaEt9kOwYc9HkQADDAU6CLwI/ObNn5z4i/jwPAM9nvMiARhhQKBr7XZnsNfNhpw9bAR7K8M+Abvb7a7/RAYXpWHEwER5lHgeQcIWA1o9EHyikL2lQW/c7kFhz9f0MdLGbaSIovKS7Xrk1fJ4jAiCel8/OkaSpPSy9si8fWzLiNgpAGJAs7Kj+/h85Nl7IJ/p5d0TGThFJHr2R+5RbefVPSIP6tmL2qySZkRWer8sma49ZG9fUiEDFbui7MwIiK8kBdHzNTqupgkASmRE1APZE+4w7wrBC8PGCuSRKHgAxGWx94jCXhx6rvYw2L6an8cHhoHIVqffu3evPXjw4DoNvpPO89LKS1SL6rDOphe+EaDE2gvvQQ8X6+5FXfADR16I34AP81VvCXBbq589tOZ5W95I2LbyaCxvBcY4pnq9e8vDysFna+bhZ1KqSEF2n5eXuqbyVW21Euw9Q+/pjmkUCVB6VjxHL+99SkYKq+dVuh4SsK+6r/S4t8ivtf6222LslAnA/fv3hwroGUhsLM2QI6AqEEaQRy8ewcmbX8ayUZRny+XiMb5O1drtTyCz52FloLfJeV1dXd16R53XBnjeKEdYTCc8d3l56Xqp1u5GFOzNAi+9lanAX0258Ep/BH8EdEU0lHePUw/Y3icnNz9pvMIT86IkmbeL0QQO9WfkU+lc9bg9z9V75mYIQHZc8ZKjfe9a5FSMGGmP1DH483jqiQZUZEvAnAX/0fR3JVm7V6IAK8sbuWc1CVhGAKKHtDXfy0BDasCGnid7nZg3AzyH8hV4RB6AB/qeIMijeF/JU4aRwd/SGjjgu+i4Oh1D1GiIlOevCJBt+X1+rNtut7vVF0wovPUWigTgVApHAZRurD+SBwRUqz8TLRxbamGi9UEVAPHeaOU91w2BX5EA7EfTgcurAC97rp5eDPxc95XeYsVYeWAb1aGXBFREPaNeXkzoFXhYuhlZlQ/KbH8duvR61a3pZ260nJmogMpryz6ZngLgkLPt4zk21ujBoQdk5eA/3lk6M/qWL08DKBBi4GMP24SNXuSxqLw4JN5auwXqLFameaf43nVrj8lQ9G9zrLeqK7YFnrd2ty8zqn41coPvz3O/MwkzIoY/z/PHMYC6sSHlfrb2sXGBoX4cU1gG91Mm1YeOiYDKGwEWozdMhL2pATUeFTFQdbM2yQxJFoXI2mPUSHmkJXMo+DzbnFH9orGB7Vht11UGvJrPTFlbAI0iRVtKDyh7DlpE7EbKGRUc0ysjEyhTEQB+2BhkeKGZAZ7nEbV2889qLL1n2FRZuOKf07FE3o4SfOhV3U1/BEue38Z7rGwEc37V0HsvnUGEB7MCf2tXS+tFOwwwTW8L/5tOHJGxvPgVS14DgOWy16e+K4DHmD/2hd0fzflz32AbZBJ52SiqDM6HAV+ROCYGrIeKVKCxQhLFBgTbLPtFbdAr3v3K0FaAPwJ93jK5yMi9p6eqU5UMqLJHJDL8W/XRaPqIRO6DCGQyo8NK8Fdjfp8y9W+ADL6ttVuhdxu0au6aX7Vq7SYYIvjwQ66AgT/yg4KRChYM42cDm0mA1ZkX1bFRZsE64tbysH/+U++m84eBPI8Zt7ZIksFRtQMSACYvinhZn3Mkhv+DwQNfyx+nf7guHAHw1lZwPgiSGM3gfuiRXvLAnj+T36oODNB8jGO4AqSchyIAqzyNipfMxE+l431lF1Ses31cJQFZnlt42SOylR7VcbwF6FWBOUqXRQFWgn8k+yIFUwSgtXbDuKO3icCA4Wzbx9C3eX/2jXYzQspzRiDn0DODTySRsfO2JgrITG9Lb0DqrV2wdFg/9IZPTk7k1+eiT9GyIUTwt3ZR7/6b4PSL+jH4W12wr1UUwBs73MYI6lgnXgOA19jjx2PsY9abpXdlvic4nYN1RM+f+09NB/C9VY89qmNvflF7VLy5ihHzPP8oj8jz5/Omay9Qq7IwL5U3p4vqOyrq/irorpKeKISyT3b+LjxfjwxU2mcV+Ht1z56lLUhbmQCocDF7mnh+tajKsyel5qpZvPl/9ELVNTbS7IWhcBTk6urmvx3yfHG0RY+V2xWBzatTa+36Qza86IzD0IrosKfPxIpJFxMFzi865kWC/HCifgjYvd4zT0mplfnqh3l5otZuMGlTbYDtjETMHvwKYGPbKcKGeanFkxwZqoL7zPO+tSda2TK4s+eH7WbplONQrc+oMc8ANiuzJ30lL85PlXFoHrMicDP5j9TDu0eNRby2hUwTAPYGldLq4VGAg1K5blu1qhp1xK23apv1ZrBgrw7zxGOMBODCxap3pc5HA8YzClxPNGRm8BUxYB2YAGC+GF1QUQJVB4/McLTBqyuClAeE6j4Gfh4vKkTP01WYJ5eB+/j5YF6vgenxucFpqNYeL7qtgD+ON48E2L4RPivTxAgwGx7uPz43CmQKaCtlenlF56pkoKKTRwR626Gn7XpsRaXcVXlhfhkRqOgwKlWimslWIFspVwF/lfDN6L2EAHjXTSID7XnWeG+UHxpoD3jYy8J9tWgL87aQrhcCt7pz3rwGwc579WBwsy1GAU5OTm59lhb15HutbTBKwwCIhIDbG8HDruEUjBEA/GdFBiFVfyaMduxFALA+qAvqzuPEI3Q8ZrxPAKtzVoYikdh+6lPCXgTA2kEJLr5U9cAfgrxak4PtajoyCCEwex6+InCRAVL5q32WXpDwiEDPfUon1Uac9xYkoNqmq2QUlJnMRkQgK2OEUI7o7ZHcQxHVXluRkykCgNcUyHoPS7bwKaosLlRDY85l8zGDDQIZG1kGTVxFzx4VrpTnctjwMrAxACtwjoya6YlRB6wDGzb1h0IKYFCQAGDedg9GADgSoATbX7WVut8jSayv0t8D/4wE8HoVXlOAfcHTAyrSgNMuVn/rP+wrfs7UeFf14jFp+SABwCkFI79YFyuHQV5tI+PEIJA95z1AkRluJDGYp7fFezKdojxWisp3q7JmJWs3PFfJp4cEVAiFJytIwEoSMUJgV4yJaQKgPAIUNJIe6Eesmve9vM2gYRibvR70itCbVOBveap7cKU8to0CMv4UMd6PQITh+Ogrf2j0+VO93JaqT7APFPBzH3EUwL4bgG2hpgDsXhQF/gxaXgSBAVDprepqguNPkQAG/EePHt0K5XMbcfkKnO2c159MItmQMvh7ZEARKCStSApQD8yPwT/a9wiAAlPVJ979K8Cf862SACxHHav0q8lARKYq6e/Ks1Vt1lqtXTw7Ed07A/4mTBbvWirPwWpdywRAhbQzUQ+JMqKYRoGZ2ufQPRt3D2RUBMC2mCd3wL17N/9NkN9Jt60t4sIV8Lwq3gy9esXPgAfflMBP9nL7GhFhb04BZdWzsHMMTAos1Pf/eR4fDTMDPYOWAjEkeErPzLDj2EJP3z6uxN9awO8t4HkF7Oq4RxBQGeTZEEbltvbY2/e2NjatTuzV4nNV+VX7gQkT641tEbWTJx7wV3XjMrw+jOyRuq8XjL38o3MqjSq3qosiaNX7VB/MEJIRkthb5iigbk209kVKpiMAGWP1vKUqm44aAvPlBWyeMcWOi8KYUZko3C5maJEAnJ+fX+/bFkGIV4xbvorgYL3whyCHXicTI09v1TZILtDo48PNn//15vAxXxUpUYSN290DjoqXxO3HUwDW9ub1q37hto3AmKNCeB7rj9NXrd2c98d/1bQ+8CICEfDjlhez2hjhfo5+amxiO9jYYe8qM+JeP/Ya9Mx78gDbA/AM+Ed0ye6rlrFaRoFN2QY83pdeq4A50jsjqivqPEsmq1ImAPahnhHhOXo0Suj9mNHEV6DQ4HhepPrinZpfRkHS4JEbEysXgcPy5A/LsMG3uvEcs51jAIo+9qMMqLflunp9EtUdQUkJt3k0FYD9iH3m3YfTK6ofI88NASjzYDnKgdEORbAYtBH47RoCJJaj+gfzszpEazLUORYGYfswkvqGBBMq7rOs/bhMLl/l7UkG3F66KuCr8jIHY8RJiPK4C9lX+ap9VgHivqQaZWmtj8TO6rDVOCoTgIuLC/da9kCi0TKwQK/FPB18j9+M1unpafhxmogEsD4MFGggVeMiOOK97LVhHRWoWx0fPnx4Y+qA5/u91ei4CE0ZbMwPPcuZhy8jGEgOohA+e8LcZ/z/DdbuGfBkIVLr2+qYQfDnvsU2xQgCgih75VFbomDkisFffZOitXyaDK+zPjxGLU3knav290hXJipvrJsHIupaBPzqGpKinojfVgBaISY9IOPV+Si5jJK71ta3sRrvW/VjmQA8fPhQnldz6bb1DElr7drgohgQG+hXgN8MuTL2Vg5ubZ9JiTJuSvBei4ogKNhiQfuqoW1RT3vHm4GEwYUJAEcC1PQGAi2GdNUAVwTHaw8EfDzHYXv2/jFvBn78QqGtHcjKjzwy7mP++JL68RsUqi1Mb0UAMo+6Kniv6uts6oPJB66FwWvqrQaWyNOv9IU33hCA+dh7Tkclu5d1ifKp6uHVO4pWefpGJKUCBvsE/ifJw0fp8fZRlIOrzs/KPvpwegrAMxbKi8P0Kp0tTFKeofIsbZ/fQbfzDKxsUBUBQD3RoFp+uFDw3r171wCPXjzqcXFxIXXzPB8+p0AL01tbWIg3AvxeYeBngI88de5b7jf1nwEqdI773oPnHWNExPvZePPqb1sjAIqgWf8rAuABmkcUMH/1SWEWNj44HWFj2ATrgFEABjmvTzNyH+npAS6f5+hcj6deEcxz5jmpeO89943kFd0Xnc/yXA3o1XJXlRPJivHkAf5WRGBLmYoAKIBAAELj21q7BQLsNRoIIPArA27lqVAu5ovvXttxazfDrainba1uWE8UvJe9cG4HDyyjMtiYIijYOUyHZdj1yFhHovJk4Ob6sM5eG6rIDf9jYKQTS0YArAy1aBJ1UOVh/REomegh+UPCyCTO8vVAHAmEgX9PNIEBXC1IZHKhvG7WMSICdp3z8ITBl/PAfOwZjdqM857RYyU4rcyzOvajtHwtIhZbgvQqx2RURj1+PK/GauSYHDoZmCIACLZo/HDVsRkiBA5eNW6Ab0DNgM5TAWaEvA/QoGeHc51emBU9Vl5ZzYJ5cJgdSUYG8na/IgcqSuAtDGMdrBwEr0yUV4Z5eX2m2sc7hzop7x+nAFg8IPT6x8Tz+HHLBODk5HEkytrP7kWvH485KsCRAPS8cax5Hj5/NCgTRTqwPlgOzvurqQa7RxFHPmf16hGVJwoDvwf+VZDNwuhbEoEtpQosXrq7AuOt2jlrj1Hw95wMJgIZUTtUIjA1BaA8RDbiSArsmL0/20eyEBltBnkO59q+GfLW/EVW5sWjvmiEsK48GNR/Dlje0ZbbjuvA79KzV8Rlos5MXhQR8cTz2Jmo2U/V2TtWkQQ1BaDu986rYwZe5fHjWg2MVuD3FhDobYtevremAIkBjjmrP0cEsA4Y5bFFpFh/ry8rIKwiEqaf8qYjrx91Yn0yQ+sRYn5OvagEg38EKNVoAKbdFzBuXcY+ACcCvkz2ESUxGQH/CrGsRAMOXabeAkDwMsOCr1Ghp4wNxAQA3423e9kbRjDn6QEvAuCBvzqHxjnqRDZOauAwACjPUAEhtqURgYp4xnp2MGJeauEeti+3rdrnfsX6GwHIyFP0oO52jxeW2jiKQv8G7CZGQrEd7ThaSKh+PJ74OxXK87WtR2qYXGdeBxILrxwGXARAjwhYP5pOmH8EoB4pVVEBbLsoCuCV1QssWwC/yjMqo/d5VcRta8nq06vDKBGolrMC/JXTZefVc6x0myFLW0qZAFRBkefZvbCuytMeevSELJ0Z7vPz8xvHSEJaazf27Zp5YLhYi6cT2MtREQNlsNgTYqOP9cDpB+UloseJBEB5SrzlP7HB/d3u5pyv3ZNNd3gGH8+phwXrhVEWz/uzPNjTZV1w6wGWeuCxHjgG8LPG+EYH1wUXzWGd1LoAa1cmfZjO8magjZ6VHrF2wD4zvbznmNsO29uLAjAJYE8df1GfsigSlInSvycP714PoDwjP6LXrBe9Sipe76HIPnXh5ymTiARYfociZQKgxAvN8hwpigcCeC8aSjOMZrCtXDUlgPutPf6qGpMAO4dgbfdg2B3DvXYtMoxoCL05e6yblWUrybEepr/n3TN5YeBncLKyuf154Zoy8kwEMAKDZI3BEPvfeyA4ZO/VUY2dDPhRf/b+mXixt8zXsX2NLLDXr8gPtwsTS6y70tvu53ZDUVMAqr15zFv/eaAUkQXuExz7OJ48MB89h8ZYRQGq4yIrl0U5K14aT2dPx0OQqA16idRInXoJ25aykqQpuYvIjSfTfweMwiTA8xi849b0R0nMuChA9EL/aNx4/hdBAHXgOioAUySASYiKGjBI4r4BuAL5jOhg+2AUAEFHRVWwTjhHjeezeipmzB4yEpBIjJQxCWrt9rcHsG0jY6/GCfa91R31xrogmVFfZsS2RvDnKJiK9uCYwP7GumCdUF9sA4uuRG3MxMnyxQiQuicinip/JBh4HkmAR2a86z3ijYEq2eD7orQe2EdlevnfhawiRocoT5reKvK2L1nyd8CtxXOYaAjt4yzqIy0GhJifGe/z8/PrPJRxQiOF88BKv9YeG35vlbyqB4bkEVjQI8a82cCzd1xpT37d0TxwXpXPwK8IAHp+CrxRGOzth4s2uZ04AmBfQrR+5QiFpTk/P7/x5Ucrx+pn7WBg57WVEquDEQzsP8zr6urxt/exXvZBqouLC5dUKe+fgV4ds56oK7Yn5+ERicp0G0cA+NsR6hnjMcFlISnhdo3qr8A/IgKe9x952Ep6AUI9I8qDj3Q4JA83k1k9I7sSyUgb3WWbRnWs6uU50dX2m63/9BoA9RBXPD6Vr2LV7I3ieeWZ4DkEaDQ6BgZsQBWYoahwKZZpoMivLWI+EVCgDmjUeaGggagBFn+Ihuej8aembSxaEn0Qh39qvh7rhgBvYq+Scntjn+DbAGdnZzfACfVh/b0HgXXmdFZvWxSo6sJ/BqRIltVBfb7XIwImHnAjIVYkGevOa1E4Hy7P8uJpAW43vIfPsecfCUe6rD1MZg1ZFTyiMj0bp0A+slWVcZmJBwxbyMp+wHy29GarDtSoDlnfrarbaDut6qclBCBi+Mrb8fLw5nwV2Hjz8ZgOvUYDAPRqMVKAOmLYmgGK68Kesd3DYVAGDpxHxvZjYOFXJXHVvJWFZaq5Zs4X52hRRx6M3KbchugpYlvhXDm/Pvrw4cNbJMjSW5QHIypWFk4BoX5YD5bIK7XzVr6tW8G03F8I8lwH75v+3jkcP9zWdp7JjwEovsHAeXqE2fJE7x91wmt8v7c2A8usGDHrQ++LlcqZYKl6/ys8blUnBfKsK/dZLyGIyuWyDlm2IgFR/fmaImizEuVT6WNv7HAfq3JW9/0UAVAPmvKO7P6sA9jws/fG51CvyHAx2FtZtm8GiefJuQ5odPHTtUwoDGRPT09vvD6JQIB5I6DwgjN8VdK8fvybWNSXV6ErDxX1Y0Oq+pv7AKcd2PO0OmIdmACwcVeE5fz8/MZ6ACQtniH0HjzUnc9bHRD8VV+pRZUK+Nn7ty2TAa+NW2s3SI7tW//wOOT6euDPoXvl7XvXIs9flcNpbN9e40UCwyRgn8CGZSoCrOqL93nEY1YqIDVblnfvk0AsZnRXQBvJqj7l8vG4Avre/Stk6i0ABg/01MyQYChcAXhrN+clLR87b+VwiLpiNNQrcQzyqDfWC/fVQODQOoY2eTGeB0xem6IwEHkeNx4juPJ5lb8CPv5xPa2PuD1PTk5uTFOgV8+vaGKZWLd79+7dKAfPKe+c91ln/uG1i4uL9uDBg/bw4cN2cXFxPd9v0Qv78R/oqHbnNsQ+8ITJDb4Rol435PpiGd7CTNXPJgz6EeHCvFAsjTe1ocgSnsf2ijw4te+lrxrLCOgVMVC6RHr2iiKIWwLzlnmPeNwZ6EZEv1KXXp0U0RuVLK8s72wMjsgUAWjtpjeAHiUKz2Mr8GcQ5sVQKn/1sGMeOA/NJMAzzJi/MqYMAPiBIi6XDbXliUZ2t9uFXhm3Eb6vbvXhufvMOBmhQnLDJMv05q/hqZXyqn62cJMjJriYEdvTI1Q8fYP3RdMnXp587vLysj148OCaBOCPiYBHrFS4v0cUCbD6qjcqFAnAfDwSwOIZpAj8sf4I8GrsqsgHE7FeEoDHFdD1zo94d5UyMt1XlNeTbgvQyGQGJPH+lX23Qp8t8+olA9U0mSwjALZvHYPhQI4CqPlYnCowcOJQtYnysNiIsNHHsDQbPQX4CMrqoUaPlT0bXOWuAEGRAGxL9sJMD/yLYSRN3NaqX7i+7N3glg0slsVRCGxPq9dut7sB+EZyGMyxPQ2MjWQw4eDIkfLmsc+tHyIC8OjRo3ZxcXEjCmDAbz+MAGC7MIFUbcYSGS0e6ziuFXFhL9raH0kA560Ex6IdqzSezije2hJL6xEYfna9tvKuRw6Bd3+1jpXyVN6Z/r0yem90X4VAVWQlQHK+PSSgEj3YWkbacQT8V8k0AWgtBhsTnNNFEsBeFIZ7efU+AjIaSPb8lBeIYKwMDuqsBpYJkwwEJJub53l8LguBDMPeTAhQkFxgW7B3rMCSF5R54M/lWTkI/kZAsN4IjkhAGNSUblwXXI/B4I/eLQOi5+F700C2j4DP3r8RAH6bITL2XmRJCbc7R8DsXPbjscURBRY15ZWRAK++nv7qHs/r957HDMhHSABKNVJSLbtabiX/rWW2nH2BVK+370UP9gmqPVIB/y11n14DwMKGxzP8KOxpsjfKnWmGxgwKz5UyQDAp8N7957qpVdamL4c3MTzP0QbOg0FfEQJuXwYHTqM8bDvHgBCRACRZuOiRox0XFxfu2gksPwIFJoGWv7UljxkmDSrKU90iAbB5/wcPHrTLy8trEsDrAbYQj4TiGOexrLattVtTQRXBvkfSkenKQOgZKRxLlj4iAlm5FV1GAMMrl8l/RY8oTVRWRVbU7RDB3wNuu9Zz3sv70OSuwb+1RREABJcM8Jkg4EPLYXf0sBGo7NjS2Pxs5u1z5IAFjWHF+0AjbWBrxwg4eJ8X+jcDzOmUYVRghNMsuEp/t3v8nQD8+qHpz+e4X7APkABEbaiiCd5WkSO1UhyjAwYoDOq81sPOWXret7GDIX+LBDD4Kz2jY5bIUHmeL5MAJrt8L44nJn3ZNAD2fYUIVIgd61cF/mpbRSQguq9HItBfFQVYrXPv/asIU694gLeCBBwK6Ff1GAH/FXVcNgWgfgiKkTDY4C+KAiDYMyB43rfKDxtShQXZE2eigoBqaZCQqLIY9NnLZc+DIw5MZvALepYffrmQ36DwIgDcRkjE+O+VORLB4M8he2wb7gMGOzX3j0TA+hx/Fq5HD5/T8DU13++9DaD6pjK+I2Gw52s4jpgQ8vjKQv8oXvQGxwOmiUgbi7ruRS9WE4HKvTMSgf9ImaO6e2l6QeGQwB+vrSABdy1bgP9qYrOEAJigkcZP2EYPdsR+8cFiY4j77P2h563K4PK5HBS1Ql/loQgLemnKSHigb2sgVJuo986tPTCkzn9tyxEH0xnrxuSGDbnpZWXhtAOGkG2fy0XSxKQAgQzvV+3O4G99f3FxIcEev+PP40S98ocL/9R4QuLD51GqUQFF7rBfGTCZ3DJhNbH+9K4piaJgXGaPZKCvnj0vH+/4LkBgdZk9JCi6/1A8YCUV3Z50EjAD/iNpR/u7TABU2BmNPm45XOt50yYecJig0TdgUqFfFQGw+1u7bfQUwcBjNswKmNg7tXLM+OKiPdzPjrG9cGBn8+qoL041GPh60QskHxgyxgWZdh7/k0DVn/NCfbi9sf6Wn308ydrEPoJkb0EoIPciAJjGxpA6H/14zKKnjderYXHMB/uL+9705OsMlhWioQidXeP9iJDwuapweh7Xqg69YIh5em1ySCDRmt8OFSD3gHAr2Se5iBzDfcrWdfXaNBoTWfoeKRMA/KIdKoGevs0/73a7Gyv40UNUIK+mCrhC6BFXCAB73wzy3kLASkMi4Jne+NU2zAfBn8GJIwU8XaDKVWQg8v6YCBiJYuF1HGpNwcnJyfXniLEfUT/c8j4L19XaCf+1EXWw8YYgjkQAP9jDizCVB81TCSrM7kmFhPEcvNcGihypcD9eZxkJ/TLh4PxVFI2JclR2plMG0hWvLiMSGfGoiJoemckvyj865903Woad94hWlUSNjL1eYhOd30L2HUGJnukVY9iTMgFQgImej/1xC3rpKiTKhAF/lhd7h2wQGezVIkAVbkQj6oEtd7wXpkeQxH2lO5MAAyoTdU9rMcB7wl4rExFVR2t3rDP2lYGy1c888Z75b68drZ62RVLERAMjGDzdowiAIn8MaiptBdyxbXlfRQTwnwjxHjVO7JpacKnAuTrVgGOCy7KtB/reVhmjCngp4WiUl7+6T4l6DqI0PXmPGmHuf3Wth9BUy8Jz1TwyItCbTt0zotfW4rVbJFvo7o2Dkfb2ZHoKoLV249O/uI/C3hwSAfMqlTdmpEIBPHpsfA5/rd2eg8QIAYORAik85nC3mgtXoVwjK/jHMnadhQcUk4HKA2N1RmC182zMUVd+fRBJgJ1DXVReDBIcMcDpA8wT8+aFgNgO2VsA3tsKHpghEbDjzBPJyAKOiUePHn/G2PpOgb/a5/6JymNhIq7AXx2rukbnTHBc9kYAqoBfFdZllARwfivAP9IpIi0VQlBp92xsR+cqhKtXKrZsHzIC/l6alTorMhARxapMRQDu3bt3gxgoQ83AiASA/+Vut9u1i4uLdnJycuPTq1ZZNbeL4M/XWvNXHyM5QJDBQYzAznXkaMbJycn1CnzMFw0sRgA877FHPKKCoG86GKgqL08BmkV0sI6Xl5c3pgBQ0IPmYyZJ+G92dmzpmOQowfbkSBAeVwXB3usLJnUeaOKYt+tMqLBczIvB35umGhHVx0yEuQ/xPpUPiwe4XpTAM2ozJIA9pSrYKfBa4WFlUgV7rw6jOlbJkZIIeGZIQKW8mTSZrO7/rF17dM4iAKP1n4oAmPeO//SFQIqCJMBA337n5+fXq9YtLXsm6EH3LKbD83iMYV+ex1cG3M6bflgnA38EXfa6UDckAGqQZaH1ykJANm7Ks4w8QfbKcYrDpgCsnzwQsTpz1If37d5oQDP4MtnzCACvbcB9O1ZjJmtb1W5IAlp7PJ6M1GC0g/PiNmOCihIZJnUNCSGWq8iaV3+PCGC5DCgRuLG+nN6713tuvGMkARWD7LXtbGSiJxoySgYq+a8ASpTIjq0oe7W+oxI5I9l9lefJEzVuuT1niMpUBMCUQyPHIWdUkhdzGfjbT4E0lqUWa6nQf5UcWFpcg8BvM6DnjIKkgF95RHBBw8oRAOw4jJQo8PIGTLYQkPuG6+55nGoagMP0Vj8vumJ54h9BWQTB9i2d+oMgRSisXgz+SADsh/2AUw5YP8sPt1wej3nlQSNgW19ilIMfVmz/qB0ZTPkY+yuSSr9VCZDdH3n2qs4ZEfCAvwd8sV0q5UagH+m5pVTJQAV81Lmt9e9t0yifuxI1jrJ0JhUHouea5xytIHVlAqCMIRo5XPzHBtrmju0YF3IxcFu+RhIUicC87BUxLtPKwTljPmaPEIEOgUKRHGx8rKd5yPgdeTU1EXm4Vi6Cit3DwKSiDdYvGGpn46oMP+qlyIPnwaL+2eBGYLa2sOgSRn4Y8PE8v1qJBACnhbDv7I+GmASYHpivemUQ+wL3VZ9cXd3+h0YW698RT0CRACTeHklg8Ef9+VfVqbWboKLAn4kO3+9tOV2miwI3D0BV+0SGXumm+mMV+CmdPLKV6TwbPZiVnjJH9FtVJ7aRqzxt5cF7Os+QuxGZfguAvX42mB4AK5KAlTbPmsGfCcDV1Xs+AIOAYPcq0oHAYNf5fXaOAqAoEGK98HOyvDLd8mAvPyMEHgGzgcoPOQIsAh97nHgPbiNjZm1QHYTYTuyJWh4G0MobZTKgxg8SP+WNe9EW04/BX41lK1+1IYIcArEiA8o79ry1rF09EhDlg/rPEACui9KrAuoeKYjAW4lnZHtIQK+sBH0vDx4rVTDh+6s69ALqXXn7W5OZqN1RVhK+LfNUMvUlQDM4KgqAgI/G3fP82SM3Q2aL0SwiYMCORt/KZsKBJMR0wJC5lY3gb4IgwUbWdEQjjwBrX6TjL8q1dtuwKRDG4wwYlJeHIIBEgMXTg/PNvCveKrKC+Vh77Xa764WFdh+DL5MBnsJh4Ld9bjuPCHjlZkQkqr+l4/K89u29HnknSHyUV6pIi6pnVa8KGEfnq2Mq0iEqp1KXqocXAUCURwWoorKVnluCX7WPVdpeuWvgZzuh+jEbH5zHvvtnRqamAOw8RgHQW7LwPIIyeuZowNHzRsDHfWX01X/I26JEjkRgmpOTkxsLG9UCP9SlNR/g8F4rw6YALDTN3qrl5+XJLJ/L4vNRX2WDMcoHARvz80hBVC4CjeVn/WVeMs+pG+jbuShMr9YAcP3UokAsI9rPvFY8Vp6hjXEGDI6MeIs8I+DnspAIoi7sYasf9zfq32PYRj1TBd69RMMTVYeMbFXyiUCz14P0SASPmxmQ6Y0KrJZDAH7c9/pPEQE+7+URydYkoSpTUwCt3Y4CIGDg1ow5EgGMEqAHghEAA382UOZZn56eXv81LS7M43Cw6cLh56hTvUHBHYdtY/XDb8qjZ4l5KW/M8uABiG2r1ihwXrbl/BUoWj52ngEDvUs1/6/aCAXHgZWFwIp5ehEiL3pkYwHJABI9rmvE4iPvuPKweqTI82I9oK+UwXkrwqFIAN+nwJ/HCuaPx179KsBdqedoGq+91X503yhxVkStKkpPj8RhulkwWQlII4RqVfrR/DwAj8b8LOBHz5CXx2opEwDP2CO4RlsV8udpAQSCaFUzEgjz9m2LEQCcGjBdEBjMi6yKAmsEDUtjemGUwrxTvk8BD4IjRkYwZI3zyoqoWH4czkYCgACJ4Gz3eQOew9tMPHgf72cSYACF7YDREmsPbBcEfAX8HAFQ7aQiGrivzqm29trf6hKN49EH2vMuPRLQ2u3pDtSzl+xEJMcjGTPGq/qMRuk8HVZ61ZgnllnN0xufipD35o2yGlRXlbu1XpXyK+TFi7rNyBbgXpEpAsBAj2sA8BhD/xgpMBC3a6016d3aD0P3BrDo9SP4sz4YAcDFcQxeXugV68wA64GXgT/eozwtFerGaIi1j31rAA2AB/4MkEi6DAzw1TsvwhARAQbJyhhCEoD14AWSOJdfWZ3P4X9cU+IJe2mqPgrEsi2mj1g/nxsxApE3qKIBeF9GAJSBY5IRtVdECFcbvGgcZqStAtg9BJDzyrx3L79qBKBHontHoxZ8f2+5dw381bRbAP9dy/RrgHaN/29e3W9G2X4PHz68NhRGBBD0eb+1x54j/pR37emvvB8Vmo/SIXjzNQZ3JVYfpTMDG4I1/hueLZyzNolAH7ecLwK/HaPgWwq8uh3ri23lRUqQbPCxGTYP0JXXz/ViYlCVCKjwGA2z8rbxHh4bqI9NaXGfrTCEUR5qSkURUgS7TKeMNNlWEdUqQYvqqPa5zxhAuYxKHT29Z4FgFExY7yoxmAX5SEby3Br8W+sPtVdEjakKgTw0mXoLgA24nUPPlBvfDI+9utfaY3KA3inmyz/08hgsMByswsIIJHZeAT6DWObRYIgVAc4L23M+ivXjD6c9mAx4r8+hV+0JkgEEdtTZ0qhFaoo84XkF9BztUVMoHEmx+jBBwjGlQCyTLTwTRQyxv3Csqb7CCEmPLhUgU+RVAacdZ4BRAX/Oi++tAH10LXou1X3Km57p6y2iGQwkXruieGRUidevhwpUq6SnjaoSPSfZc+PptC8pEwBvLhPBnokAfzMePTUECvT8sSxFJAww0Giyd4v7ighg1ECF5xl4TXfuKLUin9/rty0uesT2wGgAnsd9O8b7mWREXrgndr8CZOsXqz8SAW/qgfexTuz1q2kfHB+8sI/Jm+XP/R4Bmqr/jGQhT+wLm+ZQYXgVMekpy+5lUVEQNda9+/G8MnC9IOwB/kg/qHu8c1G0ppJH5l1z3qOkgoHEm2bp0S0DvNkphRk5FLIxCsCqjypjpXJuhBSPyFQEAAU9dA7d40IvDh3jO/os6hwChYnyZjICgCCDurGBxH2OSDCAKY8CAZqnSeyapcX1CZgHeukYwleLA7lN8HzmgXF9cK0EDnYka0p4kKq2YmJhgn0SveKn+oePPX2y86MhWcwXxyle4/qqfop0i8rnsafaQJHcSlkVw5Ud8/kRUtOjlzftoLazEtWpQrIi4I/uHZHROvcSjadRem1Nbz6rpUwAvA5WIfrIS2SvKMpbCbPXSHCdAJMABhQGfxVNUP+Qx/OBCKb37t27EbZHD5CnCvh+NszWXvbD7wkwUVKeHwuWj8IheSMv3J8eOVOCY0IRAYwAGPB7Uzg8beOB/wg4KcM74x3wPhKfyn29UwCYDttA7Ue/ajmzxm7rdAz0M3lXJQP76D7lTaq8KnlnBB1JQEQIetu++rzMEJBKGSuiTD06Ybn7Au8VMhUB4PesGcgMAE2Up4OiPCC1ZcJhunD5HgFQ3+g3AFHTCWi0GfjwY0V4TYX8+T6sM3v/qh1UO2MePOizB0URCAYg1MnLT02FMFkw/bNFh9z+ak1HFcQiw5k9uMojqwqXY+2o2kblXT2nyrNjrz2i4yjPSrmrZJUX5eXhkYJZYJ0V1qkK/BnJidLPtLXXhqvbyCN2nlSen32P3UOVZVMAJvhanvJoeb4z8uJUOgx/4+uEXC6+LYDePv5lLHuWCDwqOtBau0FomEVb/U3vaIsAaKvCs0GqQIv3sc2ZJHlSiRio8lkHFflh8PeIAEcAVJQGFwRG3i3q6oF+ZEzt+owhM108I+v1l0qTCbZdLznK2gzrUzmX6dxjIHuJiRd+jwB/xsv2pDLOKvf2SBUQo/yj/vfuZ/tn52ZJwBbtEKXbErh7x+w+ZXoKwMSbF0bjlIXZ+Zy671rx//9O/L17927sG6B68/4MLvylPgYaBBwGfAyje+DsbXFtRNa+FePEUREFJrzYMMtfGTLccnn44DPA86I/E54G8aIy+Mv08nT3rmMbVbwLz4NX90XkSvWXIgYoVUPlEWvOIzP60dirkNYRGQXjiCDbddXHlfyrhnpLIOmVyB5H3r8nh1Q3JTNg2jseWEbbpmL/t5Tp/wLAd5rVj1dsY0MhKPHiKDRYWL7NR9trVZaGPX8DH/UaGYOJ5+3j1q6Z3nze/qgIw+ZYFh4z0UHxpk14n48VAUAQwWgJkqmqJ+iBRnUtABMn3jdRZC1b2BeBuddennjRk2hfbSvlRP1lY7m1m88e14v7z/up9GrL+9lxBrq90lNWtTyPqHggWD13l96bN5Y9IONIR0aAo/pmfa6O1T3R89jbtnftSfeUnzkZ+5TpDwF5wI+/1totQ2T3t9ZuADk2DkYPTAcjAAb06J3zNIB6b1zNLaOXFNXBgBxXqtt1A24v4oEERgF/a489YyRFVa8tA34ecOrVQQaMCoBa3blPTX91PwM/Ap0RNSRKFUDz9FPC9VMGKwLmaMsSnc8Im0VHmLThGBv5YTtk40od8zkFOisMXKVve8vLjG91DFXy2koiHb326KkX3t9DfCIioPKLyhjR1Ts3m/9qORTwb23BfwFkwImLn1TnI+tEw6ZeibOy8B4EIPWangfwuJrcS8MAZILn8OM4qC+DKwIelsnendXj7OzsBnHgfsCt6REBP79r7/VjRAC8PkSjUzGwnAd/BAf7hfsj0m2VVLxzTMvnVH5KeLzyOZ6yUd+LqIK8artsi9ILOivBUREBz6PvzXcWhLjcyLPNvN5qedE59UxW8vCk0j4ZAPN5zmu0XXqISK9z8LTI9H8B4Dy4B/7KYOI+ArbyVlEHnkfG+7g8BA2eimAPE6/zOSQeuLLf9u04+tIftpm6xt8KQECwtJbedMHzCBqVCIDS0yM80T24jsH0UMbYm0Li/Hi6JgI3u6dHIpBjkOc2xXTZPufrlRX1W0bacD8jAl79I2KgxGs3uzZDAhTQq3O4Xy2Pwb4H+GdAYQXoe3p4/VuNyHh9GfVxlq831pmkzJKAnmetmv+hgb8idqtlegrAjJOBoSIB0fvyyugh4CIoYejcwLkKbAxu2T4TAisT9TOx+l1eXt4qn+fI0fB4bWrteHZ2dsMQYggYz3neoyIC2E+qfVTUwRPrHwT+itFXdUJdsijMyIMagaFnxLwIAKcbPaciV1EEgM8x2OPzERECD/x72hfbjve3MFaeTlXQ77lWKXdryQhKRIY8crSFft4xn1O6KRKwSp8e6W2bkbIOjVyYTE8BmNeNH4wx4OdPAXtEQIGTYpwKnDKwQuOI9eBwPc/R8z7eFw0AjEww+Np5JdiGSISsXIy0IPCj0fW8fv7XP+VJMPgq/ZTgvVUyZvXh+1kHj7z1SAT8SjzP3CNyXh7eMY8DjCCpfUXauC4eSfLAPwL93jbGfkci6EUFonx4XxES3B8poxIxuEtjrcZOpE8vEVD3RTpU2qJCBvBaRAJGpBJ1WFHeSoKS6aFs9BbEukwAvC+YGeAb6Nu51tq1R7zb7W4AO/74q3rs5Zoob5DBWXmUaj+aA7fr3hw+GyVVngEG/lp7DMTRK5Pq/xOUbkwGqmsALA/++A+vjUCdlJ7qWhYFUP2n9r0ftrEn0UPijQcvHyQB6m2HrHxvv7XY68fxYkTaq0PUdpgG96tkoFcQ/FeBqyIDCvi9civH+xQPhHqMe0SQGGDxehZV8PQdTeuBXqRjj0TOFJfjyQjBWSEj9d6CBExFANgbVmCI4IRfx1PHu92uPXz4sD169KhdXFy4X+3LFtixrtWQtqpnFfy9vJDQ4BRCrz4RIcH8jEDgegJFBoyU4Xa328l1DL264rE30KtgrIx31SNSeXkPEQK+yrPaZx5AcVn4XGBfcTpeXBqVy/dGunh902uImQx6W07vlRXVg+sQEaxIqoZ01NjyGK145JX8MsCbkVlS5D03kc6qjfj+QxA1JrfINzvvXZvRZyoCwO/ut9baxcXFtSeJ3imGt+1eRQYuLy9v/PhjPl4EoArKKBiVyIxRBfyZDHFUgz96o8pROihixectf5x6wbIY/A1cOJrggV0E4Hwe+weNHxMpLx82+qh/j2eZ5Y3nMuCfNUYMuBwRG2X3lfbz8p2pkwLfDPx75C6N/xYen+Xr1SuLXHlEcot2yuq/ChAz0jETHdhSMuKyKm877u2PHpmOAHAafHe5tZtAiCFxNH4G/ldXV7eA34sCWHlZBMDzEvide0/U3HOVZPB0RnSfB4revC+nM/FIBl/D+lteCvAQgPGcB5qoIwJQFfxNMg82uj97IDyvNCIWPQ9ZJQqAxMvrK0/fisyQgMhTzdouIgFZG1b6bcSL9sZOpX7qfGUseOA12peVaxWSXgWv7NkckSoB8qJASsetyFpVVpIBr/967VmPTEcAcLW8RQR2u/csDjw7O7vl5TMRMK/VjCGCPX63Hz/Z2xsBqBjTzKvsiSygePqodQi43+NxoxjYesbN2l+RNI8AsG6RIbb0lgajPlmUQenrgSnrkbVTZkQzcuGtTekRNljcPp5ulXy9e7OISY8XOQP+WVmjOnjnKlIBkKy8HuO8wpBHOiuSjuX2kKcq2e6VSnso8rRVtGOlzBDDqh0bLdeT6QgAepLscdgWP5GrogFogPEPYDAqYKSiJwJg+WII3s7jlgVfp/LqPtNuuDiStwqEUaKH39r47Ozsuh7qDQRLa/2A0zGZTnbOAxUF1qPkyau3N868PquAf9Ub6vGgIuLC9fBIm9I3u57pWCFSnM7TowL+vcZ7C0M/AvZcB6Wbd76S/4h4tmuWWHH+fG9vBITT9hC3EXL6pEhlHGbYszLqMRUBMEDFef7WHlfSztt3+xXw8wdPos/38uthUQTAdGCC0SP85kFvHgzmFcDnnzJCvG/HRrbUvWrKQ00JeJ6/qlt0jaMEqm784/p4wKnKqOrmtZu6lhmfKhnIhMlS1FcVqQLdqIfVC/6YvyqnYvAyb3FUvOc6e+62BKbRqAS3bw+QRm3gPZsrRdmLFWWt0HX12KuO/1WkLpLlXwK0tNY4as5fef9m9NQf9Bgx8IBfRQBwSsJbbY06eiutPW+8wuKqoJddjwwtAoe1o9WfQ8sIIvgXxLwC3dqKdfFeseR6Z+AfSWQIMH+lAz88FY/O20YEw6s3l+GBy253882LfYiql40f1Y5R2+GxR574WqWeGXGbJVxef6iyeF+V30OgZohKpS+wXxVZruav7psljJVyuZyeMbPSI+a8R66v0GdfdmH6Q0AGFq21WxEAO+e9B49kAPM0sMn2W8u/uY9p2Ivi63hOpWNgqnR0BHwe6GMdFdirc3ivIgJIprh+JipfVe9IMs/JK9u7xsbHa/tofKr8Is9fnauCjzK+ishgnrwgsOfhx3Hj6cX9MFKOyiu6HrWtkn0ZvB7xgPaupBqV6NHTy1PlUyFhI+Vy/rNjtCo9dmgk362ICZYxK2UCEIkiAnjOPG/zsvFjN+ilZ++689y89y48XsdpCtS1tccdpKYYcKvqWxWPdETkxgY+zwt7D721s4HaycnNzxJfXT3+rLDlG02vKO+ffyhYLpI6jC54bRoREi4DxSMwbKAY8NW5rKzsWk8ekcFFUX1iUbDW9Jj32hDHvOpbT8cqwa0Ybu7nSr9Xrm1hZLkuSp9svzJeUSqkEvXh/YpsCUg9ZfQ+cz15zdZxBbCuaOesb1f15RIC0NptI2OCnzO1Y7xm9ymgtm10DoWBxYCR8+bQOAMwTjeo+uE5TzKg4TINwJlM2f2RoDHH+2zxJBMdVV/Op/Jj4amds7OzG21v48DIXgRgI0YieliiX49kHtPovdYfHAngiJfXD5nhUvdXdeV8PDBi8FfpqlIhM+q4l7xFeeM5j8R7+kbEyis70jkjAZlUvOmI8KySked6i4iAymc27y2AfybKUpFpApA94Pi1QF40iPciKHuvyNnWm/NX6ZEE4DETAwZFj3hUBAcs1o8BB708I0GVFfPe4FXt5hkOrt/Ijw2v1cHA//T09DoCYK92WiQIAVhNeeB+ZuC9hyUD/hkCoHTqycsrG8kg/2Ml70fjMgLQjNBViU1EAvhcBKAV8FT39wBhxcPOzmW6V0B8S908WQmcq0WNNY9QVu6NJHomZmQW+FUde+o9I8umAFAYiHARngf+FSPgAVwE/gj6qA+njaYfsvriOfb6o/UOKgTP9yuDozwSrw78FUbMxzNmFZBggMafAb/9z4PJycl7piaiD+BExg3LU4AVPcgK+PEVSdYhyifb9hgUz7jb65wM/JYmA9HonOpP1CUiAyo/Bfh2rweQVWMctWUGhCOGMgLc6HlhfSNPWuUf6Z+Rq1FAyIjHaukF7J68RuWuwR/zycaJycq+KROAyFBGHrsZL/Z4lEccfbBHPTSesUDww/MmrG80z58ZMN4ysGBY3NY+2Ap8A331lUMkAJ7BxvPeFMKot+sRAOWBYr1PT0/b2dnZdQTAvklgH3Nq7fG3HthIMgHiLbaJipYwgEWgj9sMdDxyp/Yr+fB9KDhNheMDx4tHzHrHqhpTqh4sXA8F+B4Ritqk51rmFa8wzKou1a0nGUFUxEF5xXa9kl9PH0eEYgR4VF7ROa9OGdnptW2HKFVCdnARABM2LPZTxpI7k18VRFEeI5MP9QBG4fSqp+EZscgAKP3RIzbPzkDR6swLvbAsFeVQOikwyrxWdc4jAKptFNAauBoBwDyNELExw3SsGx979+L1SDckAYo4REZTkarMqGWCZdtzgIQw6o9sPHIZI4AR6R21X9QGUTkRmfEAcUYUsHo6Re2udG6tHl2JgC+rc5V89BC8UekB6ijtqC6Vew+VCChZScpQpgmAMlB2jKvaW6uFTe0cGmf05nt0Muk1glVRhEeBP3qb5hl7RMWMP36m1/LxSEDkKbEgaOGXERlkPcDhuqp+M7KDiwAxEqJC7zh2IoPgeUF2nYGf68fAjxEAvl8ZYw/4sU5MTlVdFdFFwcWSkeevyCLqEBEB77hXeNxH5Ky3PO/ZXekFVXRQfaj0QlEOizqn0nPZ2bYqW7dbb/4r9NnnWMjKnSEtXhkZYZ+RpRGAHo+HBT1Dz1AjABjBQCNpwmDJ3mOkY9SgmQH27sf5dwXirLt9mIi9U96velBePZXh9uqAaRTZw7p4beOd79U/yof7WhEBlQ73vXaIyBOeQ+DHdsFj9gSR6Fl+2eua+FNrViISwGm84y2kx0hG/cHp1H6UbuS6d496JjPiwGV61yokAPOP8pmRXlvh3Rud8+7t0V09t5W265Vq/85INb/RcpcRgJXMxwAff63d/H4AGkIsX71e5pVhwtEFbwBh/sr4KkHwR9LCujIgIPHBufFo4M4QAqy3R3SUoVHXGKSi8iuEoApSCvyROCrw9+5VgtEMPMfePJLSqoG2chWRrfxUO1f2o3M90uuJZqKAn58R3GZ5Vc713F+VivcWjYcK+PfkU9GrIjNEKrvWA86VvLaU1eN+pPwZWRoBYBll0wz+BvwWUmbj19rN/ypgj8zTKdJPLUg0r9y2XnhesUIDfLsvesuA88HIBxtGD2ArRn6kfxQRwPNMBNT1yIP39FT1U4CA6RH4q9GA1nTfYxqbnsFxhvlhBABfg/XqqPrV8sk8f27LaBxUxsSMpxWlq/Qpn/OOuU9Gid2M4R4FY5SMyFYBMAN+lS4qowfUettwRZvP5L86CtBafzRkRVmrZFMCgNIzoJAEGOjj/DmumMcv3uG8aWbEW7v974CenpiXvZ5lRl6Fe5WoaQA06kwgkFQgeHkPNEpm9LNrHoGp/DhfrmsmnqeiPOlI7wrw8z0qrO+dZ9DndQ0G/vhPi7xehuvt1ZPHiUcIvLZZDfx4z9ZGzwOuXs+/st/aOgPrkdbsHk6Xef9ReT35s45R3/b0+QxJjM73lJ8BvbI3I5LZpJX5rpJpAlD9eE2PGADiqnnbnp2dXXvR5vXba2Xqla6KMcfzdg23nJ96jZDzQ7EByGQhigIgCVBgloF/hQRkgzPz0rmsiofPkZus/F4DUCEBSrxQfgX08djEA3+rVzX64REAy4OnWlQe0fktjUtrN5+lUY+WDbQC8KhvVRo+p7y43rYZJeVVj79KBrK8q32hSEB23CvcJ7NgX8krarcVEQGUaCxH6fYle4sAmGQDhkP/6P2fn59fTwdgaPXq6urGv9thWWycIwOOOqCutsVogwkDtGfAjQCY7nhdtY8HZJFE4J8Z/8gTijx9/kWeaVS+ulYxcEp3PJ/9OG1rN8dFLwlAMfD3vKmsfVq7/ZfUvEUiiflm0kMGeo38ll6fAvGesvn58vqlR79sfHrPZQT8eC0CKrxWIUEqzx5ypvZ7ZJYwjOTVC/irSQBK1u/7lr0TACXYKGh40es/Pz+/3ue5fZsS8AaEMtpqIZeVj+fxHHeYEQ9ese8ZFR5Yts+RAPT81fqCChmw/DwCgA8FXvd0xPzsh2lV2+BroB7Yeec8AxcZOw/QPdA34bHAry62dnMBakQCsE+971dE/aLaMQL+ComI8vfOeddnDHiPYY0IKV+rAJ8aD145VXAcAY8oEoD6VADfu6dCgiJ75BFWLm8lmCv9tsgnsyurdVCyRb6jeU59CdAaCb9sx0YwGkyj5xUwVgXB3gN+uxbpYmnQm1di9ccoAL8uZulsi4RAvdWgjD4DigIZHvAKUD3AjoCDiQGmZXLjGa8Rb26lsB7eOMkiAHieiS2L1z+47wF+NcqSSUTA9iEj3mflvAmTXG9/VBSRngEPr+2ZFPM100UdrxAex/t8Nq28URJYyXMFCeghYJh+hYz2R5kA4BfdUBRw2TGfi+7nc/xDoLVP59rPAx78mI7a5zKxEZXe/EnWaFU2e8dRB3Fb4Ry5WvzlAW4EJNk5JCYRoCvduR4MUFgPFANOXBw5auhZFzuOiIVnuI2oqXGC7YSETo0f1TeZ7nyPAvuo77F+mUSkTklkdBUwRE7DVpIBvhoj3nFGgE0UkHiRBZVXj7ftjVcug8tR56tj09NhBHQqtiQDZU+/nrK2kEp7ZM9HJFvUZwkBQCNfOW9bNvgMQCq0fnFx0Xa7Xbu8vLxe/IdEQL0T7T2Uqi7RedMJy1GeGJIABBLUAT1j/jteFfb1FoF5BiwDfPVwZSQgah8Gf+sXBnjOx/rX0qH0PCBV8Ff5M9hnxlWRgNZuvrdv6bz6ev1U+SlC4LXFKuMYGa7MKGegv5oURGBbubdyLvNIPV16QSLK2ytP3ZfZCa+O3jm0yz16ef1SGR8z9qAiK6IAUd6HkAdLmQDcv3//1jlv8REDPxouPlbXzIiacbX/td/tHv8JDP6BDhIBzlN5cSbKGEd1qkQALF8kAWwEGPy5PbAeXEaPN6jOYd+p7ySokH2UD7aT6YeAj3Xi9mXgrz5onvHibUQuMK/I88c6od4I+nbOiBwTtsi4RgCvoghRv3Pe2BZcZtSu2C6ReKRgJAowamg9PflZ9K7NyBYGOcq/QuYi0PfuqZzHZwmPeyUjWN64qNarWmaPzJKAnqhFr8zWbSoCEK0+ZmPPYMCeML9HbelUmXYNiYG3KrrKwNV9fC4y8GyoVTkKXLBs9YuMfvQwqYeKDYV3P5OiCvhjWuxjFf1BQcPS47Wxnng+MzJYthofERnge7B+Rk4j4Mdyld6Vn0pv+WJdI2Csnud8VPi3EtZUHvMqEhBJRARGZNaYq3E7EhWI8o/u9chQVK4iIhUCoPqbtxVdeqItmVTqu3IM9oyXSh9HZH9EygRAeVDqnAILBjUGBm+hG3tVOHDMo+S/0lUgbAYZjbnnEVp6LyyP+1ko3s5ZnflB9EL9XB9l+HGfy6+SAFVvBpHoPq6P0tXqbvuYF4IJfsNhxItRQIl97IENAnkE9hjZUIJj2hsnWT1Qd+5/vM77nI9HeEfAn+uI22hfHfeU4UmV3HF+0X2jBjmqLz9L3rVMonTVfKr9nrWj+kX3qzp7ZVaAOdO/h1RE93jnKvllOlefEa9tszbvlek1ACwKdBDYWrtdCVwLwATBSAADNnvJUcjcmwZAPbw5eeX1808Z6urDj22kSIAHxBHIR9erAznLn9NyezC4M/ij4H8lcFmZvhEJ4DUNJvyAK7BXZIC9fU+PDPDNeGYExut/bwyoMZeBxIwB6QX/ShSgp8zKvdU0Sn/WNUqrjtXzNuuxKd3vKp/euq3S1St/6/KszNF8s0hZ9Mx4435vEYBoLr212wawNc0A+RO3rd1+nQ5BEV+Zs2OeV+Yt/rzQE3rlnnHFffbu8Oe1hwIZ9IgR8JnEcERDtXN1IKo81IDitoik+rBz26l8KiDVw8Cjvu+pQyQ8/cXXcIxy+sq44fEVEb+7kMyYHapEY9D2LV1Ur8iARwQMx+OhSEWXyPvv9Uq9+mdEoof89bRvr8df0SOyNVWy7Ok3Eo3wZOpDQGjc8RwCuG2vrh4v5mPARqAzkLQ1AUgC0AurAiOCPW/VZ1pNkJxcXV3d+P4/grdXJoI8tgWSHWXss4GYGSgF5lWDkxknNXA9w8DbTA9FmHDL56Kf0tl0s3HFfzjF13k/ajPej9ZwMOFTaVj/iMTwuYqhmTEmq8F+32C4Sn8F8hVyHhHeuyIF2RiotFkE6Go/aque9ul1iLy6euV5dVdkxSMwI2MuI6CW7+yYKRMAVZAHiHwcLXDj1eFmcNFDZxIQlaWMKTYUfqP99PRUhllNrAPsQ0dc78wA8Dm8D4mPZ/g9z0Qds84R+K8ygh4BQABtLf6/CK5/z7b68Cu98HPTSPY88Fff87et8u7V+OatmrbCvD3wjwiB3Vc5ZiKg2lARuYp4ZOWQJSN6EfnqMdjVZ3ffwuQxI7+txY4YH/c8sx6YVsvNpELqo7IrwK/O9ZCDKqGZGS9lAhAZcDVnjsaPDaLlx+fsvtZue7AYFWDjq0CB9/F+/qOWqI6eAeR5bo+d8nkso+oBYn7RsZdG6V+RikHzvP+K8WC9q1uvn6t6sudf/d4/Tj9Z2d7CvwzsvX736qLIYFZn7zgih9793rWqIc0I2l2Tg17DrIC/UkePMFTI2CFJRvDUfjbGvXJWpOmRXruVkWd1vMoJm81regrAA3SPAKDRtHssLzuH8/7qe/zZNIC35YWFFgFQUvkUsOWp0mCZCig9MEDJvP4KO868jR5RA9r7mTB4Kl0rBI63Km3UhuzZRxEAvI9fT0W9FdgrcPe8/Yz8oR4R+YvGg3fOI9pbAE8lz7sCvWqbRaLA0M5zvtGzfOigb6JAT4F75dxMnUfuXQm82A7cHvsC/1mZmgJAkFM/fk/f7lHHJuzte4RAASjm57FRzMMiAJHRZzCzPDwwtLIV8Np5TBeBvzLsGfNW6b1rPaLag8HV2/eMWwTgHgGIrnO+Sg+OAtjiVkVc1HkTBeT8yqoaowr0I/LSQ/4qXvtKwFltyCqe9Ir8Z9O0FkfaIv3Vs/wkkYDI/mTb6r5Xbo+OKNU+HRnPigT0RJPuWqbXAKCHwwv9FAHAvNiYYwOqNQC27+njgQKntTwwAqA8fvQYT05Orr84iNMHVfbvseYIBJRB9IxOVLa6t0cY/CNgRYD17vE8Ao/EVYiBV+8I9PlfIe2c0hsFy/Pm+r19te4jIjMZ8PcaHAU4hwZCFR16dNwKADyCXslfAUe1jC1ltA16SIA6zvIfTZvVp0qk2bnD564H/Hva17P7K2X674DR8BlA2r4dm/QwQc/7sfM9npQXhscIgAG7CYM/gocC/yoJUMee3qiLui+LDHj6ZDp7Xr5tMwJg1xS4etMAvK2ApEcklLBup6enN9YBcH0rosA/Wv3P47anDpUx4EnkdfbIoXgyq8F/tl6Zoc7OVfqk8nzPyAqvNSO0GcnJzq8ippU+qrRHRppXgb8de/fPjIupRYCmpH20xtKpFfl8D+/jMf9dLnvqvJDOBI08HzNA4f38jQO+x+aJrWwGfzxWAyEb4JWHROnHhqfqfXAdvXMV0Fcr5/lca7f7ifOKWHRFPG/W08cbDxGwIpgr8FdRACYA2TOh6uRdq+ictZPXbmq7T+l9ljzJxtOMUVb3KzLg9U82Bjz7eChEzCTrk4zYVM732MWRNCN2R/Wv10fqeAWRnR0LUwSAFzchCYi8XW9rjYIhfwYFfCUPF/VZOv5ca+bdWTkG8rhlLxHJguloEQEEmB7PP9pmkhk2BTgV4Ld9D/TtHEZFeFU9kiZLbwsvrT9V/2Uef+Qx8zXrwwjsbbxlgmCPn2q2H/8RVeVXkQg0vDSVPHtJwGyZdykZqduyXEXUVPk9NsCzb7O6sqixp8rrBTOvPO/8iGPTW36lDpk9quqEz1aF4Pdc65XpCACDfTSAueH4WIEM/9QfBJlUPBbvL2fRU0TQwHswAsBEQIHJyAPfSwJUXez+aCBWiEClP9jrx0V1ONdu7cRrLlq73Yamf6VtomusG9fXyua8cF+9tmlrW9TCVw/ovUWvKD1ezqj3oLwVPM4A/y6Bfxase7y8rCyvHyqETV3z9qt69ni/W5KeUZm1d5mjVwV31Ub4rGT2uZeQ9JCnLcj41CJA7yMnWT7eD4EFjzEaoECqtXzxVtRheK8CNC8CYOUq8oLlKu+2uu19sKNBEnl3Fe/f6uu1lWozJAEmHgmIHrQREsBf+fME7/MWq3qv9kUEwO71iI0nVa+/Nx91H48LvvYkSgSK0TNS9T6jdhoB76z8Sj9UyJs6rujbQzK88iOCM0OIUS9lz7yxzWV4wF/VtwfIPf2j+71neVbKBMDzvCseawT6EQlQZIC9TxMGKdWoXqiXSYblwcSDPVgmA3g/An/UXln7RQ+ferDREHhGoUoAFAng9uDQP7cjl89rArwvPKr+6yUHrA/qaWVxuXY/nsPj3e72FAASAgX4vO0FWc9AqPHVYxRwvLCh9MbGIYv3rHmkvHKvyssjUOq4qmt0vTpeVL1G+26WCM4AIpeflRNtMb+IiGTAH9nySK/qeb4Wtf/K53HqLQA2gGqrGo09KUzngY0CH7sHP+bCC/Y8VugtHmSvFdcEqPC/pVOvBEYkIBuIvd4dG/PKAIyIgGpzqyumUZ6+OmfRE+xnI5XYVxFxUw9ItEXAV21m6RTQ8zHue6v+sxX+ngdSfaAjwB/NxyMBnD/v71syByO7NyIBFVDw2sg7jvRaAYyrQNkDxZmx1COV9vLK9c6ZHfHsr6eDB/xVPTPb2yM9BGKmvOlFgOYRtVZntWxYceogAn27boadG5sX8iFJYNDHeWnM1/Y5jI3ergJ+RTi8NskAvxcoqgMvM+x8rkLCKiTA8uU3OXABpV1XuvDCStvn9mbwxT7ltR8mCPb8J00M/Az6mfePuvI+trPXd1WDxO2lRAFWBgaHCvg9aTBtRAI4v+pz2VoMfIr8R1Jtcw+osU7eMz5DQGal59moCuMDHquyKzp4z1lFl5FrI3mveD6X/BeAbdGYmtiAq3hsntigxk5RxnZGlLfGIWIuL1s9zoQnaodof8TLs/vY04mAX22rP0sffQCIX+HEc0jqTNSrgyjquwIVA4fEz9pFgb1HBDyvX/UvlnEXoowGk4BsfG1heJ4UmQHMnme7cs0rY1V/jNTTG/MVh6an3Eq7RGO9Ur5HBu9yvFeevb1EAJQo0M9YsrfFdOpeVTYaZRPl6bFuqDMDCBp0Axj78M/l5WV79OjR9VcO7Zp6BcwDCO+tCXXM7TPjaShvLwN+3FeAPyMYMUEgR8Kl9OdrimTZsRprWL7VxQN+/nnTWth2WHZVvLSZ4eRz1TJ5TFke1SjC1lIlT6u92btoi6isWT0q5K5qT7K8bascnKq969EhI6uVseHpFpGySLK+yp7TEfI9Ow6X/BdA1kAe2HMa3M8qikYZQSP6gx/V2ayPEQgjAK09nlrALx0y+GfgoQCkYuAr4O/lFZ038UJn3j7ft1K8Oiqix+3Iv6xubMCy/DiNpVN1UPor76KnDatjpYcEjOqi7l8lvflVSUAPyerxJPmekfaYJQE95XjHyvGI7uVrCvjVNsqv2nZZm8y21+gzgfpXiZlK7+1Xjntl+r8A7JoCXe/ByaIAmC46tntwAdnMA4MEAj1Ey199AMabE85ApAfMVZSkh0mzeB6/AkqVjvNpTUdevHl35YF6wuCv2tBr34jQ4DkvLzz2yuY6KLDviQ5UvbQRoFEgFZVXeY4qwDdDEnrA3UvbS4qya5FOPLarz+kICaic8+7tAVvLF58D5f1H26jM1SSyV7zxXgX0KE/vXmxDZVOja6M6KVm2BsATD+xHQV/dx4vHlMca6WfgzSv5cQGb1RUBXv37m/fjeeQeqYD/qAenwD8iALiN8lXnuR68oBKjOVYvbK/sPXtFACr1UEYq2nr9USEz1X7qMZZskDNgyLzhEcNS8ZK3lh6i5d1XOc+yqt4z7T9Sjjrm/ahfI5BX19TxllIZk0r3KmHqHR9Z+shZUffvlQAo8bwzb2GW6hDltVcr6hn6nn30FHFFems3Iwt27HmiCug98B99CGaNrGrX6KfuqwzMavmV+z3wr/wiPTMQzI7VOFZ5RXXr9Yg88K+UVZEZL8fuX2nwV4710ft6SB2Oudl6Vz35an6eXtFYy5w1ziMiAiukhyBlujORV+VkZfWSgkh/D/yruDg6NqbXAPR6s63VpgAqD16kG+dT8Wx5P1qIZtvIE43WBvSI8lR77kP9vcFXJQB87IX5PVGePl9DfW0bESx1TUnmGSuZbXPMx/NQe7yUUb0qOvbqsIXXv08PkSUiuh54cgRolf49YGfSO5Z7yIDlz4QzA/277E+TKoGJPP+V3n5mh3G/6sDcCQHwJPoIj/dg9XjxrI838Dw2pRrXq2el3pymEgVAiTpv1KiwYfLSqDaJ5u5Z1Ct1GDGxPLnumffI+xGhmiVZFWKQ9RFL5LEx+EdEYAb8I6Ib6V4RHlszIHgIIGGi2kzZqhE7sYWevF+Viv7sCUf3VPZRRsfdChnx/HvrUSUOFYdMpVvh/bfWQQDOznRSL/xvJACJgDWKgQaCB74GprYmDOxWFkoEeJ6sYrKed8p6VAbIqodEgczJycmt9kewVgNMgZrlg2UZILPBxP7H9Hwfh/25PHUO88pkpM0jA9BrTKP8UAfV3hGxqBDuKO2+xOu/anollTpUyXwF6JWNYH1UXlWCVO2vVX3n6ZV5nap9Rp2WraTHhozmXb2/SsJ72i+yCZlMEQBcOGeGm//VDRtbASp7kChYKQ98vB+Xg/sj294OqXiiKx/eik6qXRD4PeYZDXL26i2CYPscCcL2UFMskWFlctJrZHq8+qpUgT3TNTO+lqbqUVQBowImWblRREP1fa/B2+o5qfSJAu4M/FfoVr22pfSOpRGis5Vk9jci2V5+VQeyh6BHZfVizohMEwAr3D6Wg2TAKoEeHXqcvN9jJNUf0OB36u2789GiPcxTgX0FxD0ds3yqhjyTHuPQ4wF5HiReR9KHkR98WLBPKmVzFCDSu4cIrPKaRgG+mqY1H6gqeveC/b4iAV40wyt7Bjyq48IzsorE9Hr+6hwT2BHJwLhnjFVIV7Zl2Sf4ryCNma7KgezJX6WP2nDfJGqaABiwmbII/ryq3u7Bj+3geS+k5IkBEX6nn7/Zj+QjW40fkYQZErBVJ1a9Mk8/TosDU+17efI0D6ZRf8ST6e09dHgvP4xVY5DpUQX4nnFalYrnMJKPd1whAR5w9xLPLA+vn73rUVp1PiORrBOSrtG+X2HAK2PX2+8t29NXjRev3UbKHZEejzyTXvKEaSMQ98qq2KB9kaglBMC8f5zz95iyEQNeA6DSeuzbGhHB/+zs7Hrf3t833fA+72+NsUzvpyQCkVHw7/X0PIkML+rIngm2L5KDjFCogW0kUIGNIgfo/VeMPo+JCEgiwKsa/Mp+j6wC/d58ez27iijPWaXBctTYiUCoJxoS3V+pQzV9tfyKYa+MhyqZHgG2qEyPAMyUsYWwQ6pE9fEI6FaiAhWijXqrfD1snJUyAfC+9MaDGokAz/+29vhre0gCDMgZcDNjjOB/enp6/a99dvzo0aMb/zhnZV1eXt4ADM/j52hBj8eI10bY6Gwa1iEyatzWCPiZgam8Bsp5Mblo7fH4isB/5qGNAE/VX+Wp+nOkj1EnNa5WgLHKz8vf264wMhEpiAweponqwpIBU2W8RGWu8KpHyUu036tDT9nq2cVnOLMBCgdmpEIuI3LO171nX+UR1aOSJrOp6jnYklyVCcD5+fmtc9b5CK68ml8NDiYBXrqsE+1nXv/Z2dl1JODs7OyGXgb8rTX3/wKU16++PqdklhGvfECUZA8BDzzvx0SQHxYvT/y0MuZl+9H7/0pGjFoPCcjqF22rJK4HYFeTAeXNqfbIRKWrnMuIAes74jV79/eOnRWgP1Ku3dOz3+ts9BAkZQ+4/F4dqmVnMkpWo2ffK8fu6y1HHVccyOj6rF2Y+hKgkl6GzoMpCqlUByb+Lz17mUhQPABgw9QzMKoyOlhXyYzHivsREGakDckZrwvJ8vU8b9YRt5wO03vbqA3Uea+PPB08IM48hRHp8UQjUFHAnT0//HyrsYT5b+n19Epkk3rl0Oq2QrL+88hK5XrV9ipymd2bPftRHiNEQNmjChGI8pqVqf8CMA8ZF9jZnDv/Sx5/pc0z4K3FjaKMI4KChfvNy8cyVR2YHPBrjDgQPO/W09WTqoe4Io3JCqPjeW2VPuUHhtNwBEARCUUCmBBgGbgfkYFIlDHg/BnIqn0Xgf+IrijRc7XKeHh17/EqV0hkjKOxmOWXXfPacUVde59tr41HPMysbLaD0VjzpFo/RUQr90Z16wX7fUhGBJTjHB1XpUwAvMVz6t/wjATwn+bgOZQqe+S0Sg9eSxB9HpaJRPRNA48UqOMZqXplK/Kd1Xfk/orxjQhAtK+AJ9r2iiI/dj4zTtUIgCICSkY8E9S7py2isR0B/igZGB2XkR2J8l5RXlQmS2bjqmVHURrvXOWapxOTPTtXrXPPec9eV8ZO1i6cX5XI9kjVEVA6YR54LnJsRmUqAqBesTPwtx+Df5QfS+R1sR4R8HtflIuMLH6XIPI4V4G/BxDVe0fK91hnNHg9I8vb7F4ui3VR32/A4yhPrFv0oFS8FNW/M32l9PPAPyK/PX0eGZJKeu+eitG8Kw8rcjIq51eUGcmqKEyvHjNkRwElXvcIeHZOiWebVrSbV499jN8e/SPAX+XUTE8B4F/isseP4I/7FfaIDW9pM4/IyrF0lX/eU6EUz7tkgoFlq32Vf1WHSrroWq8xqhpMxVAr3gf3pRLML/uAU1Yf79gzSviQZw/7rBFSXj4TAUWK1DGPvciD6PVKsvSzBrNqVGc9sS3yPQRR/bM1+FdtBdtvdb2iZy/RzWyMyjd7rjydPdJTec6qelpaBfgrogDTEQAERCYEtvX+L8ATNdjwnOe581fp1BoELNsDf8+zxbp4/1zHUjGi3vFMxyog2EIyb1yBUmREPMLlEYCovarXKpLdP9JXEeifnJzcWsRa9VosrUcglM6jY23E+98yGrA1oTg02Vd9tyABnlQAOSMQVcfLG7Pe9Ux669ubVjkMvfmglAmAvUKHokAe9+0eNNxeaNdEeWMsionZO/88zYCkxBtEypNS+/g9AaxP5vH0MELWq1cy5hp59jPGJCICilR5DJx//BomtuUIM662aQRe0bZHPAKgSK4ipLaNCPMW4hG6CCBW6zRimO9C7pJsjJStbGuPt5rlVxUud6vxrOpr5ysRgX30b4+d6JXpKQD0qnm/IlFDVw0L64kg7XWc+sviin4eC+thqFGaWUa3r0HZKyoS0NpNfSvef0ZwvHNRmh6PIdqqciLCZdvswY5ANnpGep4bT0Y8uFVlV/KvyF0+D3f1PK4sM3p2V5c1K6PjFWVfRLpHZoHekzIBUI2gziGw4h/yWEPy+9/sOVa8iyrzUSDAXx/kDxcpb9WrK+YbkYF9Sla2p18PYWNwivLN8vKO2chEejCYenl61yIikBGODPyjMeqN4ah/esZlT5/2iIrweGmyiJNHXPBeD2iqAHTXQLWi/C2M/6xs1Z6MCT0y0k6z/bJPHVV5M6RnigC0djsywCCLoMjArzzwqnfDov4REK9hWfzvddmahMiYIYhE/2iYEYjouCJ3adxWepyYb3adwZ/vzTz0Fe3u3Rs9lHxNkV485n01HiuEYFSyuqh9T9TYwHGD+XBab1z1EoEefVeK169PgqzwrCtleMdbk40VpKPnvirxV9fZQZ2xt1NTAJ6g92/3mrHGVfoMvsoLV1tOrxozAn2+nyMB1UHheY4qj8og8QCpOjC2kMzTHh2Aqq4Ry1XpWZ9sbETEQB2r85V6esaSx0JkUL2xt8JgoVSNugfakY6VslWfR2MhGmu9hvguAblCqLK0Wf4jddoa6Ks6jY4n21bGQiWShXlXCSbbTGVDo/u9iNoKx4pl6aeAPYOKHj9OC7R2E3w9T1IZgdFByqAfEQTTyX7VeivZKsy0NfhH5yLCNlKOR6jsnErrAb+XNtpG+yy9BsozrB5RqALsLAiPyiodRklAlP8sIb1L73zEmzxk6a1HD0GYISozBGMf0c0eEjCjz1QEIDOW/Ec/UeidH0AFKBX2j1sP5HtJAOrFQBTJDDBGHjLmv0+JQLenr1SeI9e9qESVBIwQBPbAK33LxqoyhjISwMc9ns5KmfX8+bhKAuycV+4MoB8CGcBn6lCkqk9Pm/WO20yHit2MyuixWVs7X2xjtihzigCo/3Pn8/bjD/SYIFBjXh6gsAFXf1OspAf0leGthn9YRoHx0CQC116C0/MAK/CsePDeOd6Prnm64niwfat/pK865nyxTCYbnK56vFo8w9yjQ+TVZzYgy0td79FN3XsXz2wV/EfbxZMZ4pGVV42W9ZxXukZ1V89VNn5Wtq/dm5WLUnnmRmRqCsA+vIOCf/Fqx97f/zIYM8h7xiADECQgKtLQ4/mPAr/KozJgGHzu0gNR+3asIgDecU95GSh4ukUevbrOPz7f2m0iawCPb7Xg+Uy8SIBKVz2/T/CvGqFeIpiNnSoJqJY9QghmSMQ+ZF+2wrO/M8Dfe281ClBtE49oV6RaBtuW3vtZVvX1sjUA1ilICuzYrtuWP9FbMWIqAmBbfAOgoqf6MqHy6vCn6qHEM2B8TwRWnqx6yKuG1yQDLgbADBDVA1xl4JGH790bHY+eZ71U2ojMZnmzeG2WRRuwnEq5d+nxsnjAH+m4inxW7zE5hPY6VFkJ/l4a9RzMRBtYovwiUuqBvjqOiO9WsoQAcAfgPL9VQv1ZEH+e1wMO9raqhtMDez5W+qit3Yf5R5IZ3hESMCOZpx6VHxEfRZ54XxnzqlFnfb0IgNqqenkeDJ/nCFdVN1Wn2b7NIiSog5JIB3U+88RXyUx+WTSgN/8Z8jPiFa+SqM+3Kq/axjO6rQD/bNszpqskQIH+aP6VMT4jZQJQ9a5be6xcBWwVWChBA2s/9c5/RUbAv+c1SNRXHVe9V5VP9ZqXt0dKqg8bp8seMEzHgOg9hBkJ5LpVCFQPacR7ou9FRP2C1yMvvaJnBPp2LjPCWxmkGVLgkclZHfl6bxmriM4oEblrqYwVfoa9ND3nq9dZB7xHtfkowPeOg55nrMfr3zLatHQKQO231k8EPPEMfQYAWJYd94J/pdGVF8jnsY69IFaVSh6e9x8ZZcWsOU2FaUfgr/JknTMC1duW2GdetKkC/hVj1OOFe/nauV5jNWI4RsBwi0hBlG+v514xqKvrsFWbeLKPslaD/wqdPbu0Kv/ZKJHCrpHna5WUCUBUqFXAM5IMvurYfpFBx+Ne75//rAj/KbAC/p4BjzpUebwReFUiA9XIQpYP6+LlwYQm8iajh60C+BWJIgBK/55oC+qJx70PnNcPGbPPdMw85iqRrorXZyujAKq8SLKIWE9efF/FG5uRfZGAFc/XvsvvvYcdKs/5UnnvkwgY6Gc2quqMqftnZJoAKPC3c/YvfHZOAb/a7zXuRgg8UUSkF/zVZ4sVqPM1TqfSb+X1Z+SkasS9B0ul84497zjzjKP68LkesPe8wBGGn5VVJWhVnUfA1yN8WXmriJvSZ1Qquqi2rNzzbCEBdyW9Hv4M8OOxsq8j5fWS2ygqlUX1essZuZbJ0i8BtnYb6HnLoM8eSwaSvK1+B4DLtm0V/JmgZKCOenuDM7qnRyqEAtstA2GlWy/4e9crINZTH3U8Q7A8o9EbSaiW711T45q/lYF5ZOTN9is6RZ7HVuDVm++It18Z0/sgAVvKoeq5ZYQoiwCs1EHJiDNj6TI7GDmYK6SOngOiogM90gP6WEYG6vgmgiIhFZ2UXtl5k6y8Ckv1BoXSJQPEXsDkttvS6GT1iZj2CMhF6b06j9a/B/xH8xwhLpV7ZsdQVaqRoZHyeu5ZVZ9ns/TasxnS16PT1jbKpHccHgJZWx4BQJCu/Ptfa9rD8sCfhf9oyNYG8Dy/TUdwBIJ1VywODXKFAGC9VNTBC6uq0JZKp9JH57z6VQfgaGgqSruClIwy48xT8IQjJCMPsPJcWecewsw6ZMZORQP2IRVvx9Or2ta9fdIb6aiOrUyepIhCVbYGf5OKc9Lbvln6LfpLPbdeGmUnVukzRQCiB6i125/dxT8C8sJxPeCv7uXXthD8eeGfYocMUp5BjQDK69yIjSrywSRgREbvGyUHFY+xSqJ6PfuIiHnhtJ6wXUTcsmeB84juzSJH3jm1v9pwRSRy9tg7F50fTbdlOLg3krhKlxX5eCHnkXLviuSM1GGfkpGUfbZnmQBkhXt/7sP//odpI6NfAT5rSP7wUGs3V/vjcRYSYq97FfvzCAeWheVXZDTseRfeH26zc1k+1fNKuE+rHrFnsDNvMSOPVQCMdBwB+55xkBGcLUhAa31t05OuB6BHozy9fTFa1l3KaBuvqOchAzxKD5m9i/6fngJApaN/+Mv+iQ8lAn8LxyuvTpEMA1zP8+/17rnOLJGRrpCPKApQ0a2qJ5dXva8CaFWgH/H+R9OhoI5e9Efdo9JVH/DKPd616D4+7+0ruatQdE8EJbt3Nl0lH5OtCNbMPVvIrA53Af5sdyp2Pcp/y2iKZ3+yvLaQZREAE2+B3snJ7X8FrJCATCevs2yhn/e9AQZj0y/SIfIa8RqfZ/2U8WMyowaPRwQi7zQqk/OeYfS9gN0T6fHy6EnjGYgRozFr2Efz7OmfWYMRgfQqL1+1SXYuOl+RmXbpJQP7BPRDIA6tbRe+XuHxV8n+lhJhlpe+53yvbLYIEAWB3v4VUJGACEi8ldHcEOpjRAz2mSfO9WCDUwFDZZDxpwzqLIhGLHil0fTy9QhLtB0hAJFkXnwWzemJ9lT1iYhjVWYJgiejIDUC+pWye8jpXXrMM32Z5XsoYN4rdw3+itTflUQORyVa4eVZOdcjZQLgrUzGf/4z8YCgQgKiMqo6MdDjviIDWXgaH3b21hWgZ/pUjFkPmHqDKjJSo4ZGkYEejzwC/5GHgu/LpAfwew1JNA4UEVD6RHmPyiEASg+IryIBlTHeQ7xHyniSAb1H7hr8vTK9+2f7vVefWccC06+M9k39GZBqwEp4M/PaWXCRn3ePaiDPY2evtTcsHUUTdjt/vQHrxABd8V5569U9apcsXSQeURl9ULlOI7LVwxz1S2TwFBHLCFk1/63uq0iv1++Nleh59O7t0au3DltL79h+NpGGmbrMErNMekjLij6p3J/ZmpXg39rifwOsyEwFKh4/58nnlLccRS84Dw/U+ae+KOiBfzZYPfCvDmDveJXRjCIonkSEZkS2ZPSzBAXzaW3tNMM+jBLKLAnwzo3m1Ztnls+IVPJ72kmASY/NGS1jKxmN3CmbHTmXUV6rZQkBiDx4BEROHzGbCoBEW5Un510tA48VyPf+MG81qKKBUgEjdS0iBT1t5klGqDxPeDYC4E179NxXkR7dWA/uy5F6rnz4V3vWmafvefhKn1kSwPn1lj8qVRKwssze8reU6tiuRDlHyp2VESJcvXeFnVN5rpApAmBK2LXsL1MRADPx2Dxew23Vq60OGA9EI/Dn/wyIfhlAeMDP6UcYYy/4RxJFAyK9FAkYKfMujUYkXh/ehewDbCrnIoCugvzM9ei80qtXevKppL1rUB+Rmbbc53O8sl29flrh7Gw9BqbeAuAO4O8AtNaugZEFQbMqCvijLetZDfV7ZXu/aM5f/fshl1VlxZ5HVXnovAFaqTuKp6s6P1qvTEZAv6LTaumt1+pyt5TIq66c6yEBI2H8EbC/KyLwpIF8Re6S/Gbe+Ra69JIALw91/5ZSJgCnp6e3zhn4IbNRJMDSZoDfU9nI+8/A9eTk9jv/3Dm4HwF+NtefkZNqXash00oZvemtnMq56JpXj5HwoXqwMtk3EJtEYLNlGfuQldGAzDiuIgFe+aulZ1w/G0kAypbTH145dlyxh9nzWJ3iqZAAT9dsLG8hZQLgKcDv8aNUPXz2jivp+T4Ftgzo3jYCRHXNA3+eAlBb2+/tUM+brLabl24E/HuiAKq8rA5ePoow7AP4q9Ga0TyVZG2wLxk1fDPEIPL8e/XLQLiq58wY2Fe4/0khEluRgar98fYzu1btx6zckXy2sEGtTX4JEAGePfzsWpUceHpEII0Sea5RI3vefOTJ9wCTRSFGicAKiUhBFeR79F8N1pU2XiEY4dqXeF7DvmWm7NWAFIX1Z4hCj54zY+AQ+vPQZJQM9NoJzym8i77wnDmVRqWr3F+VMgGwf9RjycB9BuyVoDFmI8nX8J5qYyHQ8w/D/KyTdxwRFS8q4aVXaXolGvC9D0NVl96pgsp1PK/abzVYH9L0wep8ZqINK8bTbBSgJ92IDna8SrYEniclCqBkBbm6q/u3FM/5WEEEygTg8vIyvK6APjrHsuoBxi0Df4UIRASgAvxRWCkD9N4Q1ioZyXPG+56ZQqhEIEYjDYdmOPcB/ny9x0tdSSarMmMneu/dN1BXz1XyNjmEMb01KRmZkukBz62icT1RxSjtjE7TUwCt+a//KfA3WRURQPFCteo4A4CK58/5qYhEVEYkUVmrJDPgI2X1Av9odGBkKqKXtKw2Wj3tuS/wH0nfQyieJJkFqq0iBjNyF2Sg8pyv0uVQ2nkfsjL0b7JkCkDtV0kByihDj+Z4MDxcmXPxwv6RzrxfAU+uZzRVEN13SNLj2Y947pV7RiMCUXmzbT5KpGbLvYto0UrD7k0DeG1TabOtogDe85yR2H1Mb2A+vdLbVlukXTEVWh1DPTqskBFHa6Uuy6YAlChQyzz/VSSA06h9T1+PBHj3j3ijWBaft7ocikdRGaRV8F9BBmaJhroWjblR7+Wu+2zfea6YwtsqffXeVWH4UdlnWRWpjP2tx/lWBPrQ2vouZGoKoCdNT8g/65jIA0A9PODPSID68b8VqsjCCJNTUwvRdMuo9MwfZZGMSluOEKVVoD+rW8VwoCjAuEvZJ/g/qcA4QgJa6382M/K87yjArEQ29tDlrsmdJ3fZltNTAFtJT8dkwD8C0Ab69lPeuJpi6C1DRRmq96L0TjlkaWcGYy9pWBUBWHEvphnx9O/amGwhqwjp6raZNd69JGBFmTNyCGBlshqsVk23VcrJbOddtXFGBLbQa+pTwBXxvgzYWn3eW8nIXK8KuyMAqw/6VPLLAMA75005cGRA1WvVvzOiRG2qSNSoEWCCoQhHNP2RTY1E7ebdWx1/vZGw2bnOlfeO6HUogLNaVk5nzADzjN17NvXN6rrcRdusIhL71H0zAoAAFZGA1ubnDr1zHuDzVn3a1wvPR2JAFoX0FfnA/azMGQCuevYzZWwRxqqQgV4iwPlWyh6RyNvYl4GISGk2HbZKVuR1SB4wS6Sb99ytnNY71HY5ynpZaWOXE4CqZ6qAGKUnzFuZ62VwRS8/+lvfSH/lxVZIB+oTXffq422z6EN1zn1k/n5WquTEA67o/urY2ocR7SWUW5cVtedWem2ZZ4UkrADe6PlUZW0dUeh5do6yXvY1f7+6nGUEQAE/AlMWBWCphivxmumA5aoyMdzfA/qRroqNRyCfRSU88dYfVPWqTp3MzqNnEoX9R4lAL4k4RFmh2+gYNtmC3G0lhxwVODQ5RgzeI/saM0/C2FxCACLwt/3IO0Wg9Fi08vhti8DvgZkC+so/+I1MAXDdVL64VW3C+XH9FQHoCUP2ePT7YrcmWZtHoF8lASv06JUtDPAhe+PVvA7NSFb0qRr3URDYelHcoSx865GVz09vXj3OyZMk0wRgFPxN+Fo1xKsAjAnB1dXVrcgDgr/9uOzME2egV1MN3n6FVHjXEfhVJCDTcYYEVGRfD0cG+lF04S5lHyH9rWWfUxhbyEqd9uHhbU0EuJzVZa3Sf2S9U/X+Hoxa6WAcgkwRAAb/UUBREYBqQ9+7d+8W+Nsxv7vP3j8TAEuj9KvUIVpzoCIQKwDXIwCsVxRNUPteXitlpg2y8XKI4NMjT4v+W9Rzn6HXEYDrAaeZckZlBXlWWHCXY/rZBtyrpEwATk9P0zReAyvPvBIl8AhFzzyvF4qveOMeGagwxlHvH0V5/KNyqA/g6pD9k/qQHzrgb+H5r6pzz9i+6+dASc+4PUT9lawm5D1ttCLa8CS08QopE4BRw2oheAOx3W4nz6kQdVa+mn6wsH9rjxcBKkDGLUoG7Kyvly4DfG+tQiQZGdjqIesx6CPjpFfvfa0BYN22yndfwlGTavre/FekfVoMcGuHPa880w9bRAxHpWJbI1s9YldW13+LcVImADMfnsF5eKvE6enpdQPxtR591D2Wn+f94zmTCMxN1CDhcyr/Sh7e8Yj332uIPQDd6gGeHcgZ6Fce1pG6zep/l6C/pR5bEoVRqRj0VfJsJSvP1npVhMfIIZO0GVlOALxBo8L/1shIBqrizVPh+WyVf6RvFP6PrvN+FG1gfWcW6D1JBm0VEeA897UGYGtPeoXso8ytgP/ZDjxPQoj50PXbh/T00z7tz0pZ/iGgzCiy55/N648aGQZ8BfzVKIBd631ws7QZ+Htb3vcIzdah+9m8Zhj26lD/iGRE4NkI/KP5H5pBXAXCs3mMjOEZ3Q+tH1aLqt+MnRhp6yepjZcsAvQqjCvsVSew568+2tPj+XJeDP6KCET6R+mqYfIezz8Ceo8orQrZ3zWgjjy4Huvedz1U2z1JRsCTuwDIle126J72XYzTo/gSLUavtN2W7bvVWFmyCNADIJw28MgA3sskQzUokwTrHIwq4P0ZCRidI53p7Blvf1afKK+7JgEslQiBB75Po3E9JK9wJM99t+FdGvzZ8bk6GvlskBXefzQmqmU+SbJ0CoCJADYmryFQQB4J5uN92IfPjXr+UfkVqQy6GRJQHdR3tZBlCwCOvHt1bXUo8NkmWxmuuwL+WTA/ypMldzG9qeRJH19LCEAErD3f/1f3K88ezyP44zkP+CthfHV+dBBVIie43wP+lTUBESg+iYA480AfWoRjpfQYxLss/y5kKyN9l8b/kNt7SxklmEcSoKVMAKrz5K2NgT7n1wP8dsyhffzHv6iDIiJQmcMfkcp8f+9+5gnvE/w8jz17UKrTHV4koBpJOrT1Dk9Smav1X2VAVxrial6VdKsBYiSvJxmkVq5F2eq537p9tyIxUwRgBugrZUXf6Uevnz1/3PciAarDIs8/64DR1bzV+zOiwMfVsPjW0ltmdaDPkIBqupXTCHdpfFca0KPclicZXA9J9tGG2XM/u67jSRsHZQIw+le+SipG1AP/aK5fnVNz/0qPbGogAtueemX3VCMCWfg/O7eFrBr8s2x3hATMhNCjdQl3LbN6HEo9qtKzFmCfnvshgMMh6KBk3zqNRiefjTI9BVBNX52j9kC+Nf2Fvx4SEBGCzPtnXZX+PZIRiqgsLwLA5/Y90PdtYCKgr5KeZ7N3/LSBv8mhTgUcghyank96ZIyl16HokS2mATYjAK09Bux79+6FoM/n8Frk9fNxdM4TD+Qj75/PzXRKNe9si5KF/w/ZYzXpAfAspPdsXfgXydMK/iarSUBrT36bmBwCCbjr8reWQ2jjimwyBRDdi2RAAVRUTtXj53OYPwp2EndYFErM9kelNw8kAT0EqxLGHh28Wyx4OpKA7WVLY/WkGMNMZuvxbGmHWXla2mCL/l5ty/byZ0Ct5WBp7/fb1wHxM8H87j/mUfXw+ZxHDFR+njdaWYTXI5WwP+7bYIjKqkQ0qvPaLF65W3hfFV2OJOA9Mjv27mpOdt+y2kAfAT6Xp619Dn1M7I0AqLwY1E5OTtqjR49u7WMakwr4MFDi9YhAVDssApReg+rlVVkbUJEI9Ee9/6gNV4RNVwP2k0QCsimbyn2jcuhGqyKHSipWtO2zoX+eJrkLh6gqmxAA9tYZ8LkS+E+BGAE4PT29JgFZFKACRuo46piKZx1JtK6gkl+1jJFB0UMI+LqX12gkYZ9ySCSgahSq7XqIoHAXbX2I7bBaZkDlaWifQ5NDXUeyjABgxdQfB6Eh8AjBvXv32uXl5fX+1dXV9VaRB2/+ntMp6fV6q4vSIr0q6wpGdMx0885n6wa8PPYR+mepeMRVcN+CBDzbwub78jJ7yqik7dV5i3ruq+2etEjAk6TrVjLTZ1uQ6SUEAAE6y0MBuZ3f7XbXXj+Xi2QApdKg1YV7KwYoRyN69VPnqgv5FLBxfSugn7XL1qH/TFYAeA+h8+49yrNDjiTgKPuUQ4oGLCEAeC3yDjG9zfPjOQP3k5OTa1JxeXl5izQwcHnhUHWf2q9INULAx95WSeTB8/18LiIRFdJTnRKoRg1610D0SqXfq/kcRcvW4LJP779Cwp/UsfAk6H4I+h3aPHwlMruyPCVL1wBEkQAM+2PIn0GZ87GIAE8JVEWBPv56peJ5Vz1/patXpuXn5ctpsvyzqEJ2fiQqUJFDMBRHefLkEMfNPoG5WtZdtNMh9M1KHWaihxXZ57qZpQQgigQg6NuxFwFAsMfpAJVfVFbk+Y7IyCBi4O5dm9BTDt8fRU4iXVGyBZZ3KYe0oO/ZKIfU3xnArQDbJ8GTnpWnoY5HqUuZAJyd6aTZwjQTD4R4QaD31cDI0FfD10rHygNRfWCyxXEMpJU6ZR69murw9nvyVHWrrmcYNTCrIiZHGZOtpmo86R0rh0pEe2UrEK7m+zSSgKexzhXZ7DsA3quArd023Aj+3or/qkTAZ6Lm0fE8y4qBE4FvLxFAvVVkIdqvRiG4XQ5pPvgoa+VpaPtDBoDMSdmqzENtjydFng0RyM0IwMiHg3h9gIX/s6mAqncdRQq8c1usDu697pEGVdeMXIwO2J6pgF7jsioCc5R+eRLb1htf+wC1njJGFvzOlDeS/mmSY9vclukpgEx6VubyIsKRh6QS5ubrURSgAnZVHUelsqhvdZlKnsZw7bNZDqFvjkY5l7ueMjjKs1fKqF4FE+X5e6v2PeDldQBe+TyAPa/YE6/8yrSAKl+VW4lErJTZRYSt3XxlsRI1qeR7NDRH8WQEiPZ1z7NdnrY2edrqm8kmEQBvoR8Ci3pl8N69e9fg7y0KjMrsmZOJwv8VAqDIB6bPgH8FCVhFJLzphaurq2UPy/HBOyypROb2Ob+5anwcyjjbYuqwmuehtMFRDl+m1wBUF7AhuPKiMiMDM94r5hk9AL3AX5lrrEQeVi1sjM6tFNUf+1gMeJS7FfUM7IsI9EaLnrax+KTW90nV+2mQdX/xd5SjHOUoRznKUZ4YORKAoxzlKEc5ylGeQjkSgKMc5ShHOcpRnkI52R0nZ45ylKMc5ShHeerkGAE4ylGOcpSjHOUplCMBOMpRjnKUoxzlKZQjATjKUY5ylKMc5SmUIwE4ylGOcpSjHOUplCMBOMpRjnKUoxzlKZQjATjKUY5ylKMc5SmUIwE4ylGOcpSjHOUplCMBOMpRjnKUoxzlKZQjATjKUY5ylKMc5SmU/wfSqPCmmJuOzgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_sal_map, gt_sal_map = get_sal_maps(j, test_preds_dict, test_ground_truth_dict)\n",
    "\n",
    "visualise_sal_map(pred_sal_map)\n",
    "visualise_sal_map(gt_sal_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
